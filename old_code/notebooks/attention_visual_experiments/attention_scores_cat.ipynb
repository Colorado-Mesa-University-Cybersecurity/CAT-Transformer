{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "sys.path.append('../../model/')\n",
    "import importlib\n",
    "import modelAdjustments\n",
    "from modelAdjustments import Combined_Dataset, train, test, categorize_columns \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU instead\n",
      "Target: class\n",
      "Categorical:  ['jet1b-tag', 'jet2b-tag', 'jet3b-tag', 'jet4b-tag'] 4\n",
      "Continous:  ['lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude', 'missing_energy_phi', 'jet1pt', 'jet1eta', 'jet1phi', 'jet2pt', 'jet2eta', 'jet2phi', 'jet3pt', 'jet3eta', 'jet3phi', 'jet4pt', 'jet4eta', 'jet4phi', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb'] 24\n",
      "Unique Classes per Column:  [3, 3, 3, 3]\n",
      "target classes:  [2]\n"
     ]
    }
   ],
   "source": [
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")\n",
    "\n",
    "device_in_use='cpu'\n",
    "\n",
    "df_train = pd.read_csv('../../datasets/higgs/train.csv')\n",
    "df_test = pd.read_csv('../../datasets/higgs/test.csv')\n",
    "df_val = pd.read_csv('../../datasets/higgs/validation.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "target = 'class'\n",
    "cat_columns, cont_columns, unique_classes_per_column = categorize_columns(df_train, target)\n",
    "\n",
    "if target in cont_columns:\n",
    "    print(\"Warning: CONT \")\n",
    "    cont_columns.remove(target)\n",
    "elif target in cat_columns:\n",
    "    print(\"Warning: CAT \")\n",
    "    cat_columns.remove(target)\n",
    "\n",
    "print(\"Target:\", target)\n",
    "print(\"Categorical: \", cat_columns, len(cat_columns))\n",
    "print(\"Continous: \", cont_columns, len(cont_columns))\n",
    "print(\"Unique Classes per Column: \", unique_classes_per_column)\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cat_columns + cont_columns + [target]\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\"\n",
    "\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]\n",
    "print('target classes: ', target_classes)\n",
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])\n",
    "\n",
    "# label encode target...\n",
    "le = LabelEncoder()\n",
    "df_train[target] = le.fit_transform(df_train[target])\n",
    "df_test[target] = le.fit_transform(df_test[target])\n",
    "df_val[target] = le.fit_transform(df_val[target])\n",
    "\n",
    "# ...and categorical features\n",
    "for feature in cat_columns:\n",
    "    # print(feature)\n",
    "    df_train[feature] = le.fit_transform(df_train[feature])\n",
    "    df_test[feature] = le.fit_transform(df_test[feature])\n",
    "    df_val[feature] = le.fit_transform(df_val[feature])\n",
    "\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = Combined_Dataset(df_train, cat_columns, cont_columns, target)\n",
    "val_dataset = Combined_Dataset(df_val, cat_columns, cont_columns, target)\n",
    "test_dataset = Combined_Dataset(df_test, cat_columns, cont_columns, target)\n",
    "\n",
    "#This is a hyperparameter that is not tuned. Maybe mess with what makes sense here\n",
    "#Also try looking to see what other papers have done\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x, self.avg_attention \n",
    "\n",
    "class ExpFF(nn.Module):\n",
    "    def __init__(self, alpha, embed_size, n_cont, cat_feat, num_target_labels):\n",
    "        super(ExpFF, self).__init__()\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.embed_size = embed_size\n",
    "        self.n_cont = n_cont\n",
    "        self.cat_feat_on = False\n",
    "        if len(cat_feat)!=0:\n",
    "            self.cat_feat_on=True\n",
    "        else:\n",
    "            self.cat_feat_on = False\n",
    "\n",
    "        coefficients = self.alpha ** (torch.arange(self.embed_size//2) / self.embed_size//2) #Each feature shares the same set of scaling factors\n",
    "        coefficients = coefficients.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('embedding_coefficients', coefficients)\n",
    "\n",
    "        self.lin_embed = nn.ModuleList([nn.Linear(in_features=self.embed_size, out_features=self.embed_size) for _ in range(n_cont)]) # each feature gets its own linear layer\n",
    "\n",
    "        if self.cat_feat_on:\n",
    "            self.cat_embeddings = nn.ModuleList([nn.Embedding(num_classes, embed_size) for num_classes in cat_feat])\n",
    "            \n",
    "        #CLS Token\n",
    "        self.target_label_embed = nn.ModuleList([nn.Embedding(1, self.embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = x_cont.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "\n",
    "        temp = []\n",
    "        for i in range(self.n_cont):\n",
    "            input = x[:,i,:]\n",
    "            # print('x: ', x.shape)\n",
    "            #(1,80)x(256,1)\n",
    "            out = torch.cat([torch.cos(2* torch.pi * self.embedding_coefficients * input), torch.sin(2 * torch.pi * self.embedding_coefficients * input)], dim=-1)\n",
    "            temp.append(out)\n",
    "        \n",
    "        embeddings = []\n",
    "        x = torch.stack(temp, dim=1)\n",
    "        for i, e in enumerate(self.lin_embed):\n",
    "            goin_in = x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        if self.cat_feat_on:\n",
    "            cat_x = x_cat.unsqueeze(2)\n",
    "            for i, e in enumerate(self.cat_embeddings):\n",
    "                goin_in = cat_x[:,i,:]\n",
    "                goin_out = e(goin_in)\n",
    "                goin_out=goin_out.squeeze(1)\n",
    "                embeddings.append(goin_out)\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embed:\n",
    "            input = torch.tensor([0], device=x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(x.size(0), 1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "        return class_embeddings, context\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, num_target_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification):\n",
    "        super(RegressionHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class CATTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 alpha=0.5, # Used to initialize the coefficients for the Exponential FF \n",
    "                 embed_size=160,\n",
    "                 n_cont = 0,\n",
    "                 cat_feat:list = [], # ex: [10,4] - 10 categories in the first column, 4 categories in the second column\n",
    "                 num_layers=1, #Transformer layers\n",
    "                 heads=5, \n",
    "                 forward_expansion=8, # Determines how wide the Linear Layers are the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0.1,\n",
    "                 classification_dropout = 0.1,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 8, #Scaling factor for linear layers in head\n",
    "                 regression_on = False,\n",
    "                 targets_classes : list=  [3]\n",
    "                 ):\n",
    "        super(CATTransformer, self).__init__()\n",
    "\n",
    "        self.regression_on = regression_on\n",
    "\n",
    "        self.embeddings = ExpFF(alpha=alpha, embed_size=embed_size, n_cont=n_cont, cat_feat=cat_feat,\n",
    "                                num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, \n",
    "                               decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        if not regression_on:\n",
    "            self.out_head = ClassificationHead(embed_size=embed_size, dropout=classification_dropout, \n",
    "                                                                   mlp_scale_classification=mlp_scale_classification, \n",
    "                                                                   num_target_classes=targets_classes[0])\n",
    "        else:\n",
    "            self.out_head = RegressionHead(embed_size=embed_size, dropout=classification_dropout, mlp_scale_classification=mlp_scale_classification)\n",
    "\n",
    "    def forward(self, cat_x, cont_x):\n",
    "        class_embed, context = self.embeddings(cat_x, cont_x)\n",
    "\n",
    "        x, avg_attention = self.decoder(class_embed, context)\n",
    "        \n",
    "        # for i, e in enumerate(self.heads):\n",
    "        #     input = x[:, i,:]\n",
    "        #     output = e(input)\n",
    "           \n",
    "        output = self.out_head(x)\n",
    "\n",
    "        return output, avg_attention\n",
    "\n",
    "\n",
    "# Dataset loaders for different cases\n",
    "class Cont_Dataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.int64).values\n",
    "\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return num_features, labels_task1\n",
    "    \n",
    "class Cat_Cont_Dataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cat_columns, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        self.cate = df[cat_columns].astype(np.int64).values\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "    \n",
    "class Combined_Dataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, cat_columns, num_columns, task1_column):\n",
    "        self.n = df.shape[0]\n",
    "\n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        # If categorical columns exist, load them; otherwise, initialize as an empty tensor\n",
    "        if len(cat_columns) > 0:\n",
    "            self.cate = df[cat_columns].astype(np.int64).values\n",
    "        else:\n",
    "            self.cate = torch.empty((self.n, 0))  # Empty tensor when no categorical features\n",
    "\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "    \n",
    "def rmse(y_true, y_pred):\n",
    "    # Calculate the squared differences\n",
    "    squared_diff = (y_true - y_pred)**2\n",
    "\n",
    "    # Calculate the mean of the squared differences\n",
    "    mean_squared_diff = torch.mean(squared_diff)\n",
    "\n",
    "    # Calculate the square root to obtain RMSE\n",
    "    rmse = torch.sqrt(mean_squared_diff)\n",
    "\n",
    "    return rmse.item()  # Convert to a Python float\n",
    "\n",
    "#Training and Testing Loops for Different Cases\n",
    "def train(regression_on, dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss=0\n",
    "    total_correct_1 = 0\n",
    "    total_samples_1 = 0\n",
    "    all_targets_1 = []\n",
    "    all_predictions_1 = []\n",
    "\n",
    "    total_rmse = 0\n",
    "\n",
    "    if not regression_on:\n",
    "        for (cat_x, cont_x, labels) in dataloader:\n",
    "            cat_x,cont_x,labels=cat_x.to(device_in_use),cont_x.to(device_in_use),labels.to(device_in_use)\n",
    "            # print(cont_x.shape)\n",
    "\n",
    "            predictions, attention = model(cat_x, cont_x)\n",
    "\n",
    "            loss = loss_function(predictions, labels.long())\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "            #computing accuracy\n",
    "            y_pred_softmax_1 = torch.softmax(predictions, dim=1)\n",
    "            _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "            total_correct_1 += (y_pred_labels_1 == labels).sum().item()\n",
    "            total_samples_1 += labels.size(0)\n",
    "            all_targets_1.extend(labels.cpu().numpy())\n",
    "            all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        accuracy = total_correct_1 / total_samples_1\n",
    "\n",
    "        return avg_loss, accuracy, attention\n",
    "    \n",
    "    else:\n",
    "        for (cat_x, cont_x, labels) in dataloader:\n",
    "            cat_x,cont_x,labels=cat_x.to(device_in_use),cont_x.to(device_in_use),labels.to(device_in_use)\n",
    "\n",
    "            predictions, attention = model(cat_x, cont_x)\n",
    "\n",
    "            loss = loss_function(predictions, labels.unsqueeze(1))\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "            rmse_value = rmse(labels.unsqueeze(1), predictions)\n",
    "            total_rmse+=rmse_value\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        avg_rmse = total_rmse/len(dataloader)\n",
    "\n",
    "        return avg_loss, avg_rmse, attention\n",
    "\n",
    "def test(regression_on, dataloader, model, loss_function, device_in_use):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss=0\n",
    "    total_correct_1 = 0\n",
    "    total_samples_1 = 0\n",
    "    all_targets_1 = []\n",
    "    all_predictions_1 = []\n",
    "\n",
    "    total_rmse = 0\n",
    "\n",
    "    if not regression_on:\n",
    "        with torch.no_grad():\n",
    "            for (cat_x, cont_x, labels) in dataloader:\n",
    "                cat_x,cont_x,labels=cat_x.to(device_in_use),cont_x.to(device_in_use),labels.to(device_in_use)\n",
    "                # print(cont_x.shape)\n",
    "\n",
    "                predictions, attention = model(cat_x, cont_x)\n",
    "\n",
    "                loss = loss_function(predictions, labels.long())\n",
    "                total_loss+=loss.item()\n",
    "\n",
    "                #computing accuracy\n",
    "                y_pred_softmax_1 = torch.softmax(predictions, dim=1)\n",
    "                _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "                total_correct_1 += (y_pred_labels_1 == labels).sum().item()\n",
    "                total_samples_1 += labels.size(0)\n",
    "                all_targets_1.extend(labels.cpu().numpy())\n",
    "                all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "            avg_loss = total_loss/len(dataloader)\n",
    "            accuracy = total_correct_1 / total_samples_1\n",
    "\n",
    "            return avg_loss, accuracy, attention\n",
    "    \n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for (cat_x, cont_x, labels) in dataloader:\n",
    "                cat_x,cont_x,labels=cat_x.to(device_in_use),cont_x.to(device_in_use),labels.to(device_in_use)\n",
    "\n",
    "                predictions, attention = model(cat_x, cont_x)\n",
    "\n",
    "                loss = loss_function(predictions, labels.unsqueeze(1))\n",
    "                total_loss+=loss.item()\n",
    "\n",
    "                rmse_value = rmse(labels.unsqueeze(1), predictions)\n",
    "                total_rmse+=rmse_value\n",
    "\n",
    "            avg_loss = total_loss/len(dataloader)\n",
    "            avg_rmse = total_rmse/len(dataloader)\n",
    "\n",
    "            return avg_loss, avg_rmse, attention\n",
    "        \n",
    "# helpers \n",
    "\n",
    "def categorize_columns(dataframe, target):\n",
    "    categorical_columns = []\n",
    "    continuous_columns = []\n",
    "    unique_classes_per_column = []  # To hold the number of unique classes for each categorical column\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].dtype == 'object' or len(dataframe[column].unique()) <= 10:\n",
    "            # If the column's data type is 'object' or it has 10 or fewer unique values, consider it categorical.\n",
    "            if column != target:\n",
    "                categorical_columns.append(column)\n",
    "                unique_classes_per_column.append(dataframe[column].nunique())  # Store the number of unique classes\n",
    "        else:\n",
    "            # Otherwise, consider it continuous.\n",
    "            continuous_columns.append(column)\n",
    "\n",
    "    return categorical_columns, continuous_columns, unique_classes_per_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/5]         | Train: Loss 0.6842926696330641, Accuracy 0.552918378646152       \n",
      "Epoch [ 2/5]         | Train: Loss 0.6688173561734337, Accuracy 0.5822478654894075      \n",
      "Epoch [ 3/5]         | Train: Loss 0.6678865015728322, Accuracy 0.5831512078561646      \n",
      "Epoch [ 4/5]         | Train: Loss 0.6654893434623803, Accuracy 0.5865023166360696      \n",
      "Epoch [ 5/5]         | Train: Loss 0.6618527918500084, Accuracy 0.588906372934697       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2e9997580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_on = False\n",
    "\n",
    "model = CATTransformer(alpha = 0.5,\n",
    "                       embed_size=160,\n",
    "                       n_cont=len(cont_columns),\n",
    "                       cat_feat=unique_classes_per_column,\n",
    "                       targets_classes=target_classes,\n",
    "                       regression_on=regression_on\n",
    "                       ).to(device_in_use)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "epochs = 5 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = [] \n",
    "test_f1_scores = [] \n",
    "\n",
    "train_attentions = []\n",
    "test_attentions = []\n",
    "\n",
    "#Time will be recorded for all 100 epochs - This means the results will not be comparable to Xgboost but that is ok, we will only compare between transformer models who will also train for 100 epochs\n",
    "start_time = time.process_time()\n",
    "\n",
    "for t in range(epochs):\n",
    "    train_loss, train_acc, attention_train = train(regression_on=False, \n",
    "                                   dataloader=train_dataloader, \n",
    "                                   model=model, \n",
    "                                   loss_function=loss_function, \n",
    "                                   optimizer=optimizer, \n",
    "                                   device_in_use=device_in_use)\n",
    "    train_attentions.append(attention_train)\n",
    "\n",
    "    test_loss, test_acc, attention_test = test(regression_on=False, dataloader=test_dataloader, model=model, loss_function=loss_function, device_in_use=device_in_use)\n",
    "    test_attentions.append(attention_test)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies_1.append(train_acc)\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies_1.append(test_acc)\n",
    "\n",
    "    epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "    train_metrics = f\"Train: Loss {(train_loss)}, Accuracy {(train_acc)}\"\n",
    "    print(f\"{epoch_str:20} | {train_metrics:65}\")\n",
    "\n",
    "total_time = time.process_time() - start_time\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0349, 0.0358, 0.0350, 0.0352, 0.0347, 0.0356, 0.0353, 0.0360, 0.0358,\n",
       "        0.0361, 0.0356, 0.0354, 0.0361, 0.0356, 0.0355, 0.0356, 0.0355, 0.0317,\n",
       "        0.0392, 0.0275, 0.0360, 0.0409, 0.0366, 0.0368, 0.0378, 0.0400, 0.0360,\n",
       "        0.0338], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
