{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU instead\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# sys.path.append('../../model/')\n",
    "# from updatedModel import CATTransformer, train, test\n",
    "import time\n",
    "\n",
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")\n",
    "\n",
    "df_train = pd.read_csv('../../datasets/insurance/train.csv')\n",
    "df_test = pd.read_csv('../../datasets/insurance/test.csv')\n",
    "df_val = pd.read_csv('../../datasets/insurance/validation.csv') #READ FROM RIGHT SPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_columns(dataframe, target):\n",
    "    categorical_columns = []\n",
    "    continuous_columns = []\n",
    "    unique_classes_per_column = []  # To hold the number of unique classes for each categorical column\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].dtype == 'object' or len(dataframe[column].unique()) <= 10:\n",
    "            # If the column's data type is 'object' or it has 10 or fewer unique values, consider it categorical.\n",
    "            if column != target:\n",
    "                categorical_columns.append(column)\n",
    "                unique_classes_per_column.append(dataframe[column].nunique())  # Store the number of unique classes\n",
    "        else:\n",
    "            # Otherwise, consider it continuous.\n",
    "            continuous_columns.append(column)\n",
    "\n",
    "    return categorical_columns, continuous_columns, unique_classes_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8349, 86)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is a class that is not seen in the training data so the embedding fails on the test \n",
    "# I will recombine test and train to get the proper amount of classes (this may be a potential flaw in our model)\n",
    "combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "combined_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: MOSTYPE\n",
      "Categorical:  ['MAANTHUI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD', 'MGODRK', 'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA', 'MRELOV', 'MFALLEEN', 'MFGEKIND', 'MFWEKIND', 'MOPLHOOG', 'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG', 'MBERZELF', 'MBERBOER', 'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA', 'MSKB1', 'MSKB2', 'MSKC', 'MSKD', 'MHHUUR', 'MHKOOP', 'MAUT1', 'MAUT2', 'MAUT0', 'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045', 'MINK4575', 'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART', 'PWABEDR', 'PWALAND', 'PPERSAUT', 'PBESAUT', 'PMOTSCO', 'PVRAAUT', 'PAANHANG', 'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG', 'PGEZONG', 'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS', 'PINBOED', 'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND', 'APERSAUT', 'ABESAUT', 'AMOTSCO', 'AVRAAUT', 'AAANHANG', 'ATRACTOR', 'AWERKT', 'ABROM', 'ALEVEN', 'APERSONG', 'AGEZONG', 'AWAOREG', 'ABRAND', 'AZEILPL', 'APLEZIER', 'AFIETS', 'AINBOED', 'ABYSTAND', 'CARAVAN']\n",
      "Continous:  []\n",
      "Unique Classes per Column:  [9, 6, 6, 10, 10, 10, 6, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 6, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 8, 10, 8, 4, 7, 5, 7, 4, 6, 3, 6, 6, 6, 6, 10, 7, 3, 5, 9, 4, 7, 2, 7, 5, 3, 3, 2, 9, 6, 5, 4, 4, 7, 6, 3, 7, 2, 2, 3, 8, 2, 3, 5, 3, 2, 2]\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "target = 'MOSTYPE'\n",
    "cat_columns, cont_columns, unique_classes_per_column = categorize_columns(combined_df, target)\n",
    "\n",
    "if target in cont_columns:\n",
    "    cont_columns.remove(target)\n",
    "elif target in cat_columns:\n",
    "    print(\"in here\")\n",
    "    cat_columns.remove(target)\n",
    "\n",
    "print(\"Target:\", target)\n",
    "print(\"Categorical: \", cat_columns)\n",
    "print(\"Continous: \", cont_columns)\n",
    "print(\"Unique Classes per Column: \", unique_classes_per_column)\n",
    "\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cat_columns + cont_columns + [target]\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\"\n",
    "\n",
    "le = LabelEncoder()\n",
    "# label encode categorical features\n",
    "for feature in cat_columns:\n",
    "    df_train[feature] = le.fit_transform(df_train[feature])\n",
    "    df_test[feature] = le.fit_transform(df_test[feature])\n",
    "    df_val[feature] = le.fit_transform(df_val[feature])\n",
    "\n",
    "\n",
    "\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]\n",
    "print(target_classes)\n",
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns]) if cont_columns else None\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns]) if cont_columns else None\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns]) if cont_columns else None\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns]) if cont_columns else None \n",
    "\n",
    "class SingleTaskDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cat_columns, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        self.cate = df[cat_columns].astype(np.int64).values\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = SingleTaskDataset(df_train, cat_columns, cont_columns, 'MOSTYPE')\n",
    "val_dataset = SingleTaskDataset(df_val, cat_columns, cont_columns, 'MOSTYPE')\n",
    "test_dataset = SingleTaskDataset(df_test, cat_columns, cont_columns, 'MOSTYPE')\n",
    "\n",
    "#This is a hyperparameter that is not tuned. Maybe mess with what makes sense here\n",
    "#Also try looking to see what other papers have done\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from rff.layers import GaussianEncoding\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_cont, cat_feat, num_target_labels, rff_on):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.rff_on = rff_on\n",
    "\n",
    "        if self.rff_on:\n",
    "            self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_cont)])\n",
    "            self.dropout = nn.Dropout(embedding_dropout)\n",
    "            self.mlp_in = embed_size\n",
    "        else:\n",
    "            self.mlp_in = input_size\n",
    "\n",
    "        self.cont_embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_cont)])\n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(num_classes, embed_size) for num_classes in cat_feat])\n",
    "\n",
    "        # Classifcation Embeddings for each target label\n",
    "        self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "    def forward(self, cat_x, cont_x):\n",
    "        embeddings = []\n",
    "        if cont_x.nelement() != 0:\n",
    "            x = cont_x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "            rff_vectors = []\n",
    "            if self.rff_on:\n",
    "                for i, r in enumerate(self.rffs):\n",
    "                    input = x[:,i,:]\n",
    "                    out = r(input)\n",
    "                    rff_vectors.append(out)\n",
    "            \n",
    "                x = torch.stack(rff_vectors, dim=1)\n",
    "            \n",
    "            for i, e in enumerate(self.cont_embeddings):\n",
    "                goin_in = x[:,i,:]\n",
    "                goin_out = e(goin_in)\n",
    "                embeddings.append(goin_out)\n",
    "\n",
    "        #embedding cat features\n",
    "        cat_x = cat_x.unsqueeze(2)\n",
    "        for i, e in enumerate(self.cat_embeddings):\n",
    "            goin_in = cat_x[:,i,:]\n",
    "  \n",
    "            goin_out = e(goin_in)\n",
    "            goin_out=goin_out.squeeze(1)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embeddings:\n",
    "            input = torch.tensor([0], device=cat_x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(cat_x.size(0), 1)\n",
    "            tmep = temp.unsqueeze(1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "\n",
    "        return class_embeddings, context\n",
    "\n",
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(classificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, num_target_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class CATTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rff_on = False,\n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 embedding_dropout = 0,\n",
    "                 n_cont = 0,\n",
    "                 cat_feat:list = [],\n",
    "                 num_layers=1,\n",
    "                 heads=1,\n",
    "                 forward_expansion=4, # Determines how wide the MLP is in the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0,\n",
    "                 classification_dropout = 0,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 4,\n",
    "                 targets_classes : list=  [3,8]\n",
    "                 ):\n",
    "        super(CATTransformer, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(rff_on=rff_on, sigma=sigma, embed_size=embed_size, input_size=input_size, \n",
    "                                     embedding_dropout=embedding_dropout,n_cont=n_cont, cat_feat=cat_feat, num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, \n",
    "                               decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        self.classifying_heads = nn.ModuleList([classificationHead(embed_size=embed_size, dropout=classification_dropout, \n",
    "                                                                   mlp_scale_classification=mlp_scale_classification, \n",
    "                                                                   num_target_classes=x) for x in targets_classes])\n",
    "        \n",
    "    def forward(self, cat_x, cont_x):\n",
    "        class_embed, context = self.embeddings(cat_x, cont_x)\n",
    "\n",
    "        x = self.decoder(class_embed, context)\n",
    "        \n",
    "        probability_dist_raw = []\n",
    "        for i, e in enumerate(self.classifying_heads):\n",
    "            input = x[:, i,:]\n",
    "            output = e(input)\n",
    "            probability_dist_raw.append(output)\n",
    "        \n",
    "        return probability_dist_raw\n",
    "\n",
    "# Training and Testing Loops\n",
    "# Training and Testing Loops\n",
    "def train(dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_r2_score = 0\n",
    "    root_mean_squared_error_total = 0\n",
    "\n",
    "    for (x_cat, x_cont, labels_task1) in dataloader:\n",
    "        x_cat, x_cont, labels_task1 = x_cat.to(device_in_use), x_cont.to(device_in_use), labels_task1.to(device_in_use)\n",
    "\n",
    "        task_predictions = model(x_cat, x_cont)\n",
    "        \n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate R^2 score for the regression task\n",
    "        r2 = r2_score_manual(labels_task1, task_predictions[0].squeeze(1))\n",
    "        total_r2_score += r2\n",
    "\n",
    "        # Calculate RMSE score for the regression task\n",
    "        rmse_value = rmse(labels_task1, task_predictions[0].squeeze(1))\n",
    "        root_mean_squared_error_total+=rmse_value\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_r2_score = total_r2_score / len(dataloader)\n",
    "    avg_rmse_score = root_mean_squared_error_total / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_r2_score, avg_rmse_score\n",
    "\n",
    "def test(dataloader, model, loss_function, device_in_use):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_loss = 0\n",
    "  total_r2_score = 0\n",
    "  root_mean_squared_error_total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (x_cat, x_cont, labels_task1) in dataloader:\n",
    "        x_cat, x_cont, labels_task1 = x_cat.to(device_in_use), x_cont.to(device_in_use), labels_task1.to(device_in_use)\n",
    "\n",
    "        task_predictions = model(x_cat, x_cont)\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate R^2 score for the regression task\n",
    "        r2 = r2_score_manual(labels_task1, task_predictions[0].squeeze(1))\n",
    "        total_r2_score += r2\n",
    "        \n",
    "        # Calculate RMSE score for the regression task\n",
    "        rmse_value = rmse(labels_task1, task_predictions[0].squeeze(1))\n",
    "        root_mean_squared_error_total+=rmse_value\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_r2_score = total_r2_score / len(dataloader)\n",
    "    avg_rmse_score = root_mean_squared_error_total / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_r2_score, avg_rmse_score\n",
    "\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.4f}\"\n",
    "\n",
    "def r2_score_manual(y_true, y_pred):\n",
    "    # Calculate the mean of true labels\n",
    "    y_mean = torch.mean(y_true)\n",
    "\n",
    "    # Calculate the total sum of squares\n",
    "    total_ss = torch.sum((y_true - y_mean)**2)\n",
    "\n",
    "    # Calculate the residual sum of squares\n",
    "    residual_ss = torch.sum((y_true - y_pred)**2)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r2 = 1 - (residual_ss / total_ss)\n",
    "\n",
    "    return r2.item()  # Convert to a Python float\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    # Calculate the squared differences\n",
    "    squared_diff = (y_true - y_pred)**2\n",
    "\n",
    "    # Calculate the mean of the squared differences\n",
    "    mean_squared_diff = torch.mean(squared_diff)\n",
    "\n",
    "    # Calculate the square root to obtain RMSE\n",
    "    rmse = torch.sqrt(mean_squared_diff)\n",
    "\n",
    "    return rmse.item()  # Convert to a Python float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/100]       | Train: Loss 421.83174, R2 -1.52699, RMSE 19.94488                 | Test: Loss 176.36352, R2 -0.06163, RMSE 13.27526\n",
      "Epoch [ 2/100]       | Train: Loss 177.70127, R2 -0.06867, RMSE 13.32131                 | Test: Loss 166.30539, R2 -0.00133, RMSE 12.89441\n",
      "Epoch [ 3/100]       | Train: Loss 169.51975, R2 -0.01632, RMSE 13.01393                 | Test: Loss 165.79384, R2 -0.00062, RMSE 12.87292\n",
      "Epoch [ 4/100]       | Train: Loss 169.34337, R2 -0.01754, RMSE 13.00941                 | Test: Loss 165.50567, R2 0.00125, RMSE 12.86357\n",
      "Epoch [ 5/100]       | Train: Loss 168.25112, R2 -0.00911, RMSE 12.96591                 | Test: Loss 164.44023, R2 0.00328, RMSE 12.81661\n",
      "Epoch [ 6/100]       | Train: Loss 167.48585, R2 -0.00626, RMSE 12.93754                 | Test: Loss 163.01393, R2 0.01547, RMSE 12.76342\n",
      "Epoch [ 7/100]       | Train: Loss 161.81111, R2 0.02788, RMSE 12.71668                  | Test: Loss 154.08205, R2 0.06772, RMSE 12.40780\n",
      "Epoch [ 8/100]       | Train: Loss 133.61905, R2 0.19675, RMSE 11.53118                  | Test: Loss 100.42291, R2 0.39601, RMSE 10.01198\n",
      "Epoch [ 9/100]       | Train: Loss 96.47784, R2 0.42164, RMSE 9.80804                    | Test: Loss 86.45661, R2 0.47720, RMSE 9.28583\n",
      "Epoch [10/100]       | Train: Loss 83.35424, R2 0.49999, RMSE 9.11969                    | Test: Loss 77.95911, R2 0.52760, RMSE 8.81684\n",
      "Epoch [11/100]       | Train: Loss 72.87418, R2 0.56321, RMSE 8.51616                    | Test: Loss 65.14049, R2 0.60754, RMSE 8.05618\n",
      "Epoch [12/100]       | Train: Loss 61.44862, R2 0.63168, RMSE 7.82206                    | Test: Loss 55.52233, R2 0.66600, RMSE 7.44784\n",
      "Epoch [13/100]       | Train: Loss 53.93740, R2 0.67567, RMSE 7.33078                    | Test: Loss 44.93522, R2 0.72900, RMSE 6.68395\n",
      "Epoch [14/100]       | Train: Loss 43.19295, R2 0.73989, RMSE 6.55708                    | Test: Loss 41.12095, R2 0.75168, RMSE 6.38973\n",
      "Epoch [15/100]       | Train: Loss 37.21719, R2 0.77614, RMSE 6.09023                    | Test: Loss 32.69291, R2 0.79993, RMSE 5.70899\n",
      "Epoch [16/100]       | Train: Loss 32.80747, R2 0.80310, RMSE 5.71316                    | Test: Loss 28.27580, R2 0.82731, RMSE 5.31262\n",
      "Epoch [17/100]       | Train: Loss 28.98627, R2 0.82557, RMSE 5.37398                    | Test: Loss 23.20103, R2 0.85982, RMSE 4.80364\n",
      "Epoch [18/100]       | Train: Loss 26.34920, R2 0.84116, RMSE 5.12161                    | Test: Loss 20.37526, R2 0.87671, RMSE 4.50897\n",
      "Epoch [19/100]       | Train: Loss 22.32036, R2 0.86581, RMSE 4.70722                    | Test: Loss 17.60486, R2 0.89360, RMSE 4.19523\n",
      "Epoch [20/100]       | Train: Loss 19.15536, R2 0.88497, RMSE 4.36692                    | Test: Loss 15.81072, R2 0.90479, RMSE 3.96507\n",
      "Epoch [21/100]       | Train: Loss 18.18925, R2 0.89034, RMSE 4.25383                    | Test: Loss 15.93251, R2 0.90373, RMSE 3.95410\n",
      "Epoch [22/100]       | Train: Loss 16.37204, R2 0.90171, RMSE 4.02391                    | Test: Loss 12.50331, R2 0.92457, RMSE 3.51099\n",
      "Epoch [23/100]       | Train: Loss 13.54444, R2 0.91857, RMSE 3.66891                    | Test: Loss 11.60299, R2 0.92971, RMSE 3.39279\n",
      "Epoch [24/100]       | Train: Loss 13.27952, R2 0.92002, RMSE 3.63047                    | Test: Loss 14.33146, R2 0.91279, RMSE 3.77732\n",
      "Epoch [25/100]       | Train: Loss 12.97843, R2 0.92199, RMSE 3.58802                    | Test: Loss 9.99859, R2 0.93941, RMSE 3.15836\n",
      "Epoch [26/100]       | Train: Loss 11.31508, R2 0.93161, RMSE 3.35331                    | Test: Loss 10.40535, R2 0.93723, RMSE 3.22314\n",
      "Epoch [27/100]       | Train: Loss 10.51168, R2 0.93688, RMSE 3.23067                    | Test: Loss 10.50903, R2 0.93578, RMSE 3.23206\n",
      "Epoch [28/100]       | Train: Loss 10.39152, R2 0.93762, RMSE 3.21051                    | Test: Loss 9.77184, R2 0.94037, RMSE 3.10964\n",
      "Epoch [29/100]       | Train: Loss 9.47112, R2 0.94307, RMSE 3.06606                     | Test: Loss 7.71060, R2 0.95346, RMSE 2.76988\n",
      "Epoch [30/100]       | Train: Loss 9.08527, R2 0.94533, RMSE 3.00598                     | Test: Loss 7.32959, R2 0.95558, RMSE 2.69904\n",
      "Epoch [31/100]       | Train: Loss 8.12223, R2 0.95111, RMSE 2.84065                     | Test: Loss 6.75512, R2 0.95927, RMSE 2.58819\n",
      "Epoch [32/100]       | Train: Loss 7.33398, R2 0.95573, RMSE 2.70187                     | Test: Loss 6.47641, R2 0.96089, RMSE 2.53786\n",
      "Epoch [33/100]       | Train: Loss 7.14034, R2 0.95714, RMSE 2.66236                     | Test: Loss 6.15078, R2 0.96276, RMSE 2.47263\n",
      "Epoch [34/100]       | Train: Loss 6.68942, R2 0.95973, RMSE 2.57672                     | Test: Loss 6.76261, R2 0.95872, RMSE 2.58310\n",
      "Epoch [35/100]       | Train: Loss 6.99640, R2 0.95774, RMSE 2.63728                     | Test: Loss 6.58158, R2 0.96005, RMSE 2.55842\n",
      "Epoch [36/100]       | Train: Loss 6.49586, R2 0.96068, RMSE 2.53713                     | Test: Loss 5.55631, R2 0.96607, RMSE 2.32750\n",
      "Epoch [37/100]       | Train: Loss 6.77386, R2 0.95921, RMSE 2.59184                     | Test: Loss 5.95210, R2 0.96399, RMSE 2.42202\n",
      "Epoch [38/100]       | Train: Loss 5.80599, R2 0.96516, RMSE 2.39989                     | Test: Loss 5.51463, R2 0.96652, RMSE 2.32907\n",
      "Epoch [39/100]       | Train: Loss 5.76540, R2 0.96517, RMSE 2.39077                     | Test: Loss 5.26694, R2 0.96794, RMSE 2.24588\n",
      "Epoch [40/100]       | Train: Loss 5.55085, R2 0.96658, RMSE 2.34961                     | Test: Loss 5.50234, R2 0.96694, RMSE 2.33521\n",
      "Epoch [41/100]       | Train: Loss 5.22106, R2 0.96854, RMSE 2.27935                     | Test: Loss 5.06711, R2 0.96935, RMSE 2.22589\n",
      "Epoch [42/100]       | Train: Loss 5.29168, R2 0.96825, RMSE 2.29413                     | Test: Loss 5.14182, R2 0.96894, RMSE 2.22598\n",
      "Epoch [43/100]       | Train: Loss 5.10521, R2 0.96929, RMSE 2.25488                     | Test: Loss 4.78392, R2 0.97121, RMSE 2.17129\n",
      "Epoch [44/100]       | Train: Loss 4.75694, R2 0.97139, RMSE 2.17622                     | Test: Loss 4.38225, R2 0.97357, RMSE 2.08236\n",
      "Epoch [45/100]       | Train: Loss 4.73437, R2 0.97142, RMSE 2.17236                     | Test: Loss 4.78888, R2 0.97109, RMSE 2.17019\n",
      "Epoch [46/100]       | Train: Loss 4.57368, R2 0.97247, RMSE 2.13315                     | Test: Loss 4.68609, R2 0.97149, RMSE 2.15308\n",
      "Epoch [47/100]       | Train: Loss 4.41768, R2 0.97342, RMSE 2.09389                     | Test: Loss 4.41708, R2 0.97336, RMSE 2.09086\n",
      "Epoch [48/100]       | Train: Loss 4.40037, R2 0.97346, RMSE 2.09272                     | Test: Loss 3.77521, R2 0.97724, RMSE 1.92817\n",
      "Epoch [49/100]       | Train: Loss 4.16670, R2 0.97491, RMSE 2.03744                     | Test: Loss 4.16915, R2 0.97485, RMSE 2.00579\n",
      "Epoch [50/100]       | Train: Loss 4.21875, R2 0.97465, RMSE 2.04972                     | Test: Loss 3.76034, R2 0.97735, RMSE 1.92674\n",
      "Epoch [51/100]       | Train: Loss 3.96844, R2 0.97617, RMSE 1.98715                     | Test: Loss 3.58273, R2 0.97836, RMSE 1.88419\n",
      "Epoch [52/100]       | Train: Loss 3.86884, R2 0.97675, RMSE 1.96456                     | Test: Loss 3.56819, R2 0.97838, RMSE 1.88486\n",
      "Epoch [53/100]       | Train: Loss 3.94937, R2 0.97624, RMSE 1.98239                     | Test: Loss 3.53971, R2 0.97870, RMSE 1.86719\n",
      "Epoch [54/100]       | Train: Loss 3.82935, R2 0.97699, RMSE 1.95363                     | Test: Loss 3.37644, R2 0.97946, RMSE 1.81977\n",
      "Epoch [55/100]       | Train: Loss 3.98189, R2 0.97600, RMSE 1.99031                     | Test: Loss 3.50398, R2 0.97861, RMSE 1.85959\n",
      "Epoch [56/100]       | Train: Loss 3.90172, R2 0.97646, RMSE 1.96749                     | Test: Loss 3.47201, R2 0.97899, RMSE 1.85719\n",
      "Epoch [57/100]       | Train: Loss 4.06259, R2 0.97559, RMSE 2.01121                     | Test: Loss 3.43675, R2 0.97895, RMSE 1.84267\n",
      "Epoch [58/100]       | Train: Loss 3.59827, R2 0.97838, RMSE 1.89276                     | Test: Loss 3.17282, R2 0.98064, RMSE 1.75675\n",
      "Epoch [59/100]       | Train: Loss 3.42765, R2 0.97933, RMSE 1.84827                     | Test: Loss 2.92881, R2 0.98228, RMSE 1.68641\n",
      "Epoch [60/100]       | Train: Loss 3.45358, R2 0.97919, RMSE 1.85568                     | Test: Loss 3.11809, R2 0.98122, RMSE 1.73005\n",
      "Epoch [61/100]       | Train: Loss 3.30283, R2 0.98007, RMSE 1.81450                     | Test: Loss 3.36173, R2 0.97959, RMSE 1.82243\n",
      "Epoch [62/100]       | Train: Loss 3.47600, R2 0.97911, RMSE 1.86111                     | Test: Loss 2.79707, R2 0.98305, RMSE 1.65821\n",
      "Epoch [63/100]       | Train: Loss 3.35990, R2 0.97983, RMSE 1.82732                     | Test: Loss 3.11572, R2 0.98112, RMSE 1.75475\n",
      "Epoch [64/100]       | Train: Loss 3.41444, R2 0.97945, RMSE 1.84372                     | Test: Loss 2.93909, R2 0.98210, RMSE 1.67477\n",
      "Epoch [65/100]       | Train: Loss 3.25057, R2 0.98036, RMSE 1.79905                     | Test: Loss 3.20494, R2 0.98071, RMSE 1.76864\n",
      "Epoch [66/100]       | Train: Loss 3.17044, R2 0.98091, RMSE 1.77616                     | Test: Loss 2.93707, R2 0.98203, RMSE 1.67823\n",
      "Epoch [67/100]       | Train: Loss 3.09448, R2 0.98136, RMSE 1.75587                     | Test: Loss 2.83941, R2 0.98291, RMSE 1.67385\n",
      "Epoch [68/100]       | Train: Loss 3.16494, R2 0.98093, RMSE 1.77451                     | Test: Loss 2.71509, R2 0.98344, RMSE 1.63239\n",
      "Epoch [69/100]       | Train: Loss 2.97837, R2 0.98204, RMSE 1.72159                     | Test: Loss 2.51446, R2 0.98487, RMSE 1.57012\n",
      "Epoch [70/100]       | Train: Loss 2.91846, R2 0.98241, RMSE 1.70416                     | Test: Loss 2.75504, R2 0.98334, RMSE 1.64543\n",
      "Epoch [71/100]       | Train: Loss 2.92102, R2 0.98235, RMSE 1.70423                     | Test: Loss 2.53748, R2 0.98477, RMSE 1.56900\n",
      "Epoch [72/100]       | Train: Loss 3.05096, R2 0.98159, RMSE 1.74263                     | Test: Loss 2.53552, R2 0.98460, RMSE 1.57548\n",
      "Epoch [73/100]       | Train: Loss 2.83962, R2 0.98288, RMSE 1.68312                     | Test: Loss 2.52477, R2 0.98489, RMSE 1.57586\n",
      "Epoch [74/100]       | Train: Loss 2.89455, R2 0.98259, RMSE 1.69916                     | Test: Loss 2.48852, R2 0.98493, RMSE 1.55018\n",
      "Epoch [75/100]       | Train: Loss 2.96646, R2 0.98214, RMSE 1.71945                     | Test: Loss 2.35244, R2 0.98565, RMSE 1.51668\n",
      "Epoch [76/100]       | Train: Loss 2.88947, R2 0.98261, RMSE 1.69797                     | Test: Loss 2.25479, R2 0.98649, RMSE 1.48014\n",
      "Epoch [77/100]       | Train: Loss 2.83599, R2 0.98293, RMSE 1.68162                     | Test: Loss 2.29293, R2 0.98608, RMSE 1.49806\n",
      "Epoch [78/100]       | Train: Loss 2.81346, R2 0.98302, RMSE 1.67535                     | Test: Loss 2.50157, R2 0.98500, RMSE 1.55995\n",
      "Epoch [79/100]       | Train: Loss 2.82112, R2 0.98306, RMSE 1.67554                     | Test: Loss 2.45204, R2 0.98518, RMSE 1.55554\n",
      "Epoch [80/100]       | Train: Loss 2.69809, R2 0.98376, RMSE 1.64020                     | Test: Loss 2.15971, R2 0.98670, RMSE 1.46527\n",
      "Epoch [81/100]       | Train: Loss 2.71516, R2 0.98362, RMSE 1.64527                     | Test: Loss 2.11769, R2 0.98719, RMSE 1.44605\n",
      "Epoch [82/100]       | Train: Loss 2.75021, R2 0.98342, RMSE 1.65577                     | Test: Loss 2.44602, R2 0.98533, RMSE 1.55008\n",
      "Epoch [83/100]       | Train: Loss 2.85039, R2 0.98286, RMSE 1.68538                     | Test: Loss 2.17606, R2 0.98663, RMSE 1.44056\n",
      "Epoch [84/100]       | Train: Loss 2.66366, R2 0.98398, RMSE 1.62883                     | Test: Loss 2.20844, R2 0.98664, RMSE 1.47693\n",
      "Epoch [85/100]       | Train: Loss 2.62918, R2 0.98421, RMSE 1.61866                     | Test: Loss 2.20181, R2 0.98666, RMSE 1.47036\n",
      "Epoch [86/100]       | Train: Loss 2.61349, R2 0.98424, RMSE 1.61401                     | Test: Loss 1.98387, R2 0.98791, RMSE 1.38312\n",
      "Epoch [87/100]       | Train: Loss 2.48671, R2 0.98501, RMSE 1.57425                     | Test: Loss 2.03977, R2 0.98767, RMSE 1.42093\n",
      "Epoch [88/100]       | Train: Loss 2.78177, R2 0.98323, RMSE 1.66521                     | Test: Loss 2.47567, R2 0.98500, RMSE 1.56476\n",
      "Epoch [89/100]       | Train: Loss 2.68650, R2 0.98374, RMSE 1.63666                     | Test: Loss 2.10032, R2 0.98702, RMSE 1.43716\n",
      "Epoch [90/100]       | Train: Loss 2.61842, R2 0.98426, RMSE 1.61569                     | Test: Loss 2.18597, R2 0.98681, RMSE 1.47736\n",
      "Epoch [91/100]       | Train: Loss 2.71513, R2 0.98362, RMSE 1.64429                     | Test: Loss 2.16561, R2 0.98665, RMSE 1.44366\n",
      "Epoch [92/100]       | Train: Loss 2.48739, R2 0.98502, RMSE 1.57272                     | Test: Loss 2.01837, R2 0.98784, RMSE 1.41248\n",
      "Epoch [93/100]       | Train: Loss 2.49598, R2 0.98495, RMSE 1.57719                     | Test: Loss 2.18323, R2 0.98682, RMSE 1.47320\n",
      "Epoch [94/100]       | Train: Loss 2.56525, R2 0.98453, RMSE 1.59877                     | Test: Loss 1.91439, R2 0.98840, RMSE 1.37613\n",
      "Epoch [95/100]       | Train: Loss 2.37431, R2 0.98566, RMSE 1.53775                     | Test: Loss 2.10249, R2 0.98722, RMSE 1.44328\n",
      "Epoch [96/100]       | Train: Loss 2.48049, R2 0.98505, RMSE 1.57294                     | Test: Loss 1.92710, R2 0.98838, RMSE 1.37280\n",
      "Epoch [97/100]       | Train: Loss 2.43241, R2 0.98537, RMSE 1.55696                     | Test: Loss 1.82366, R2 0.98894, RMSE 1.32602\n",
      "Epoch [98/100]       | Train: Loss 2.39273, R2 0.98562, RMSE 1.54533                     | Test: Loss 1.81156, R2 0.98901, RMSE 1.31748\n",
      "Epoch [99/100]       | Train: Loss 2.38712, R2 0.98562, RMSE 1.54185                     | Test: Loss 1.89011, R2 0.98850, RMSE 1.36762\n",
      "Epoch [100/100]      | Train: Loss 2.49191, R2 0.98495, RMSE 1.57571                     | Test: Loss 1.74890, R2 0.98942, RMSE 1.30151\n",
      "Lowest MSE:  1.748899797598521\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CATTransformer(rff_on=True,\n",
    "                       sigma=2,\n",
    "                       embed_size=160,\n",
    "                       heads=5,\n",
    "                       forward_expansion=8,\n",
    "                       pre_norm_on=False,\n",
    "                       mlp_scale_classification=8,\n",
    "                       embedding_dropout=0.1,\n",
    "                       decoder_dropout=0,\n",
    "                       classification_dropout=0.1,\n",
    "                       targets_classes=[1],\n",
    "                       n_cont=len(cont_columns),\n",
    "                       cat_feat=unique_classes_per_column).to(device_in_use)\n",
    "class UncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks):\n",
    "        super(UncertaintyLoss, self).__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        self.loss_fns = [nn.MSELoss() for x in range(num_tasks)] \n",
    "\n",
    "    def forward(self, predictions, labels_task1):\n",
    "\n",
    "        #task 1\n",
    "        target = labels_task1\n",
    "        prediction = predictions[0].squeeze(1)\n",
    "        loss_fn = self.loss_fns[0]\n",
    "\n",
    "        task_loss = loss_fn(prediction, target)\n",
    "        \n",
    "        return task_loss\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.5f}\"\n",
    "\n",
    "loss_functions = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 0.0001) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "epochs = 100 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = [] \n",
    "test_f1_scores = []\n",
    "lowest_mse = float('inf') \n",
    "\n",
    "\n",
    "#Time will be recorded for all 100 epochs - This means the results will not be comparable to Xgboost but that is ok, we will only compare between transformer models who will also train for 100 epochs\n",
    "start_time = time.process_time()\n",
    "\n",
    "for t in range(epochs):\n",
    "  train_loss, r2_train, rmse_train = train(train_dataloader, model, loss_functions, optimizer, device_in_use=device_in_use)\n",
    "  test_loss, r2_test, rmse_test = test(test_dataloader, model, loss_functions, device_in_use=device_in_use)\n",
    "  train_losses.append(train_loss)\n",
    "\n",
    "  # train_accuracies_2.append(train_accuracy_2)\n",
    "  # train_recalls.append(train_recall) \n",
    "  # train_f1_scores.append(train_f1)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  if test_loss < lowest_mse:\n",
    "    lowest_mse = test_loss\n",
    "\n",
    "  epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "  train_metrics = f\"Train: Loss {format_metric(train_loss)}, R2 {format_metric(r2_train)}, RMSE {format_metric(rmse_train)}\"\n",
    "  test_metrics = f\"Test: Loss {format_metric(test_loss)}, R2 {format_metric(r2_test)}, RMSE {format_metric(rmse_test)}\"\n",
    "  print(f\"{epoch_str:20} | {train_metrics:65} | {test_metrics}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'final_model_trained.pth')\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Lowest MSE: \", lowest_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
