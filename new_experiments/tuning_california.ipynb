{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/wdwatson2/projects/CAT-Transformer/model')\n",
    "# sys.path.insert(0, r'C:\\Users\\smbm2\\projects\\CAT-Transformer\\model')\n",
    "# sys.path.insert(0, '/home/warin/projects/CAT-Transformer/model')\n",
    "from testingModel import CATTransformer, MyFTTransformer, Combined_Dataset, train, test, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "device_in_use = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9851]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/train.csv')\n",
    "df_test = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/test.csv')\n",
    "df_val = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/validation.csv')\n",
    "\n",
    "cont_columns = [ 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
    "       'Latitude', 'Longitude']\n",
    "target = ['MedInc']\n",
    "cat_columns=[]\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cont_columns + target\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "cat_features=()\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\"\n",
    "\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]\n",
    "print(target_classes)\n",
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = Combined_Dataset(df_train, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "val_dataset = Combined_Dataset(df_val, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "test_dataset = Combined_Dataset(df_test, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    alpha = trial.suggest_float('sigma', 0.001, 5, log=True)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 350, 500])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    pre_norm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "    decoder_dropout = trial.suggest_categorical('decoder_dropout', [0,.1,.2,.5])\n",
    "    classification_dropout = trial.suggest_categorical('class_drop', [0,.1,.2,.5])\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00001, 0.001, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.000001, 0.001, log=True)\n",
    "\n",
    "    epochs = 400\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = CATTransformer(alpha = alpha,\n",
    "                           embed_size= embed_size,\n",
    "                           n_cont = len(cont_columns),\n",
    "                           cat_feat=cat_columns,\n",
    "                           num_layers=num_layers,\n",
    "                           heads=heads,\n",
    "                           forward_expansion=forward_expansion,\n",
    "                           decoder_dropout=decoder_dropout,\n",
    "                           classification_dropout=classification_dropout,\n",
    "                           pre_norm_on=pre_norm_on,\n",
    "                           mlp_scale_classification=mlp_scale_classification,\n",
    "                           targets_classes=target_classes,\n",
    "                           regression_on=True\n",
    "                           ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=20, mode='min', verbose=False)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for t in range(epochs):\n",
    "        train_loss, train_rmse = train(regression_on=True, \n",
    "                                    get_attn=False,\n",
    "                                    dataloader=train_dataloader, \n",
    "                                    model=model, \n",
    "                                    loss_function=loss_function, \n",
    "                                    optimizer=optimizer, \n",
    "                                    device_in_use=device_in_use)\n",
    "        val_loss, val_rmse = test(regression_on=True, \n",
    "                                  get_attn=False,\n",
    "                                   dataloader=val_dataloader, \n",
    "                                   model=model, \n",
    "                                   loss_function=loss_function, \n",
    "                                   device_in_use=device_in_use)\n",
    "        # Check if we should early stop based on validation rmse\n",
    "        early_stopping(val_rmse)\n",
    "    \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Log the final test rmse for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation RMSE = {val_rmse:.4f}\"\n",
    "\n",
    "    # Return the test rmse as the objective to optimize\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 15:46:54,615] A new study created in memory with name: no-name-377a34eb-ed99-47e0-a8ad-52699356170a\n",
      "Best trial: 0. Best value: 0.944113:   1%|          | 1/100 [00:06<10:15,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:00,835] Trial 0 finished with value: 0.9441127502001249 and parameters: {'sigma': 5, 'num_layers': 2, 'embed_size': 200, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 7, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.00017877835206345802, 'weight_decay': 0.00032184106357890674}. Best is trial 0 with value: 0.9441127502001249.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   2%|▏         | 2/100 [00:14<12:20,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:09,328] Trial 1 finished with value: 0.8354114981798025 and parameters: {'sigma': 1.5, 'num_layers': 2, 'embed_size': 200, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.00011427919398924068, 'weight_decay': 4.170626692543791e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   3%|▎         | 3/100 [00:25<14:56,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:20,570] Trial 2 finished with value: 0.9838140331781827 and parameters: {'sigma': 1, 'num_layers': 2, 'embed_size': 90, 'heads': 5, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 9.801491910477277e-05, 'weight_decay': 4.8136222423471674e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   4%|▍         | 4/100 [00:36<15:27,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:30,879] Trial 3 finished with value: 0.8818699946770301 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 1, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 0.0005656440801888712, 'weight_decay': 8.264462139093583e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   5%|▌         | 5/100 [00:46<15:47,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:41,398] Trial 4 finished with value: 1.008298479593717 and parameters: {'sigma': 0.1, 'num_layers': 1, 'embed_size': 350, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 1, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 0.00033812146661804237, 'weight_decay': 1.4826048915235332e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   6%|▌         | 6/100 [01:03<18:58, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:47:57,655] Trial 5 finished with value: 2.049694675665635 and parameters: {'sigma': 2, 'num_layers': 2, 'embed_size': 500, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0.5, 'class_drop': 0.1, 'learning_rate': 4.6176678378892705e-05, 'weight_decay': 6.699805149429496e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   7%|▋         | 7/100 [01:16<19:22, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:48:10,962] Trial 6 finished with value: 0.8638921059094943 and parameters: {'sigma': 1.5, 'num_layers': 1, 'embed_size': 60, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 3, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 0.0002043562186881004, 'weight_decay': 0.0009112040194628541}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   8%|▊         | 8/100 [01:25<17:44, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:48:20,528] Trial 7 finished with value: 1.1236858459619374 and parameters: {'sigma': 5, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.0007454078455488071, 'weight_decay': 2.0644149689118215e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:   9%|▉         | 9/100 [01:41<19:20, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:48:35,896] Trial 8 finished with value: 1.0585916867622962 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 100, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 8, 'decoder_dropout': 0.1, 'class_drop': 0, 'learning_rate': 0.00035446565874941443, 'weight_decay': 2.7355143661714135e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  10%|█         | 10/100 [01:51<17:47, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:48:45,747] Trial 9 finished with value: 1.4076829781899085 and parameters: {'sigma': 0.001, 'num_layers': 2, 'embed_size': 160, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 1, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 5.8767756837626887e-05, 'weight_decay': 3.31668063444782e-05}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  11%|█         | 11/100 [02:07<19:36, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:49:02,068] Trial 10 finished with value: 0.8488559906299298 and parameters: {'sigma': 3, 'num_layers': 2, 'embed_size': 200, 'heads': 5, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 1.3967027913184602e-05, 'weight_decay': 1.0727651164457411e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  12%|█▏        | 12/100 [02:24<21:02, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:49:18,980] Trial 11 finished with value: 0.8852759141188401 and parameters: {'sigma': 3, 'num_layers': 2, 'embed_size': 200, 'heads': 5, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 1.1692226936423669e-05, 'weight_decay': 1.1130471991899249e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  13%|█▎        | 13/100 [02:46<24:13, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:49:41,128] Trial 12 finished with value: 0.8429606602742121 and parameters: {'sigma': 4, 'num_layers': 2, 'embed_size': 180, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 1.012525103100322e-05, 'weight_decay': 1.0611785198711922e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  14%|█▍        | 14/100 [03:11<27:25, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:50:05,880] Trial 13 finished with value: 0.8455723478243902 and parameters: {'sigma': 4, 'num_layers': 2, 'embed_size': 120, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 2.5744126186095003e-05, 'weight_decay': 4.049400073724855e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  15%|█▌        | 15/100 [03:37<30:04, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:50:31,937] Trial 14 finished with value: 0.8724183761156522 and parameters: {'sigma': 0.5, 'num_layers': 2, 'embed_size': 180, 'heads': 10, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 3.174120543975353e-05, 'weight_decay': 3.3870847116262672e-06}. Best is trial 1 with value: 0.8354114981798025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.835411:  15%|█▌        | 15/100 [03:44<21:13, 14.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-01-06 15:50:39,350] Trial 15 failed with parameters: {'sigma': 4, 'num_layers': 2, 'embed_size': 140, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 9.633500006839301e-05, 'weight_decay': 2.2411469185416494e-06} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wdwatson2/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_122358/1535139487.py\", line 46, in objective\n",
      "    train_loss, train_rmse = train(regression_on=True,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wdwatson2/projects/CAT-Transformer/model/testingModel.py\", line 748, in train\n",
      "    loss = loss_function(predictions, labels.unsqueeze(1))\n",
      "    ^^^^^^^^^^^^^^^\n",
      "  File \"/home/wdwatson2/miniconda3/envs/ml-env/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/wdwatson2/miniconda3/envs/ml-env/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-06 15:50:39,351] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Start the optimization process\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters and the validation accuracy at the point of early stopping\u001b[39;00m\n\u001b[1;32m     11\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Training loop with a large number of epochs\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 46\u001b[0m     train_loss, train_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregression_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mget_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice_in_use\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_in_use\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     val_loss, val_rmse \u001b[38;5;241m=\u001b[39m test(regression_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     54\u001b[0m                               get_attn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m                                dataloader\u001b[38;5;241m=\u001b[39mval_dataloader, \n\u001b[1;32m     56\u001b[0m                                model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m     57\u001b[0m                                loss_function\u001b[38;5;241m=\u001b[39mloss_function, \n\u001b[1;32m     58\u001b[0m                                device_in_use\u001b[38;5;241m=\u001b[39mdevice_in_use)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Check if we should early stop based on validation rmse\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/CAT-Transformer/model/testingModel.py:748\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(get_attn, regression_on, dataloader, model, loss_function, optimizer, device_in_use)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(cat_x, cont_x)\n\u001b[0;32m--> 748\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(predictions, labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    749\u001b[0m total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    751\u001b[0m rmse_value \u001b[38;5;241m=\u001b[39m rmse(labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 100\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='minimize')  \n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_rmse = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation RMSE (at Early Stopping):\", best_val_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
