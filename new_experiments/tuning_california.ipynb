{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '/home/wdwatson2/projects/CAT-Transformer/model')\n",
    "sys.path.insert(0, r'C:\\Users\\smbm2\\projects\\CAT-Transformer\\model')\n",
    "# sys.path.insert(0, '/home/warin/projects/CAT-Transformer/model')\n",
    "from testingModel import CATTransformer, MyFTTransformer, Combined_Dataset, train, test, EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "device_in_use = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9851]\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/train.csv')\n",
    "# df_test = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/test.csv')\n",
    "# df_val = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/california/validation.csv')\n",
    "\n",
    "df_train = pd.read_csv(r'C:\\Users\\smbm2\\projects\\CAT-Transformer\\datasets\\california\\train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\smbm2\\projects\\CAT-Transformer\\datasets\\california\\test.csv')\n",
    "df_val = pd.read_csv(r'C:\\Users\\smbm2\\projects\\CAT-Transformer\\datasets\\california\\validation.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "cont_columns = [ 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
    "       'Latitude', 'Longitude']\n",
    "target = ['MedInc']\n",
    "cat_columns=[]\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cont_columns + target\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "cat_features=()\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\"\n",
    "\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]\n",
    "print(target_classes)\n",
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = Combined_Dataset(df_train, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "val_dataset = Combined_Dataset(df_val, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "test_dataset = Combined_Dataset(df_test, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    alpha = trial.suggest_float('sigma', 0.001, 5, log=True)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 250, 350, 500])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    pre_norm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "    decoder_dropout = trial.suggest_categorical('decoder_dropout', [0,.1,.2,.5])\n",
    "    classification_dropout = trial.suggest_categorical('class_drop', [0,.1,.2,.5])\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.00001, 0.001, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.000001, 0.001, log=True)\n",
    "\n",
    "    epochs = 400\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = CATTransformer(alpha = alpha,\n",
    "                           embed_size= embed_size,\n",
    "                           n_cont = len(cont_columns),\n",
    "                           cat_feat=cat_columns,\n",
    "                           num_layers=num_layers,\n",
    "                           heads=heads,\n",
    "                           forward_expansion=forward_expansion,\n",
    "                           decoder_dropout=decoder_dropout,\n",
    "                           classification_dropout=classification_dropout,\n",
    "                           pre_norm_on=pre_norm_on,\n",
    "                           mlp_scale_classification=mlp_scale_classification,\n",
    "                           targets_classes=target_classes,\n",
    "                           regression_on=True\n",
    "                           ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=20, mode='min', verbose=False)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for t in range(epochs):\n",
    "        train_loss, train_rmse = train(regression_on=True, \n",
    "                                    get_attn=False,\n",
    "                                    dataloader=train_dataloader, \n",
    "                                    model=model, \n",
    "                                    loss_function=loss_function, \n",
    "                                    optimizer=optimizer, \n",
    "                                    device_in_use=device_in_use)\n",
    "        val_loss, val_rmse = test(regression_on=True, \n",
    "                                  get_attn=False,\n",
    "                                   dataloader=val_dataloader, \n",
    "                                   model=model, \n",
    "                                   loss_function=loss_function, \n",
    "                                   device_in_use=device_in_use)\n",
    "        # Check if we should early stop based on validation rmse\n",
    "        early_stopping(val_rmse)\n",
    "    \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Log the final test rmse for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation RMSE = {val_rmse:.4f}\"\n",
    "\n",
    "    # Return the test rmse as the objective to optimize\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 15:58:16,669] A new study created in memory with name: no-name-ae8aed08-80df-451a-851c-f0bbd78f683d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fbb13301b445acb66635ecf44b68d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "[I 2024-01-06 15:59:14,323] Trial 0 finished with value: 1.8552341277782733 and parameters: {'sigma': 0.07238185835822583, 'num_layers': 2, 'embed_size': 140, 'heads': 10, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 3, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 1.676847038341081e-05, 'weight_decay': 0.0002899079579516983}. Best is trial 0 with value: 1.8552341277782733.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:02:52,310] Trial 1 finished with value: 0.9835986907665546 and parameters: {'sigma': 0.0174490961493367, 'num_layers': 4, 'embed_size': 60, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 2.5461021227494194e-05, 'weight_decay': 0.00019337611397390493}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:03:28,859] Trial 2 finished with value: 1.9012051362257738 and parameters: {'sigma': 0.07978026647801911, 'num_layers': 4, 'embed_size': 60, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 1.8394860515523804e-05, 'weight_decay': 0.0004047444126774552}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:03:58,116] Trial 3 finished with value: 1.9246076162044818 and parameters: {'sigma': 0.002854954968517516, 'num_layers': 2, 'embed_size': 100, 'heads': 10, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 2.025557157339213e-05, 'weight_decay': 5.731453409760849e-05}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:05:06,752] Trial 4 finished with value: 1.233402939943167 and parameters: {'sigma': 3.2464721071173033, 'num_layers': 4, 'embed_size': 120, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 1, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0002226206359576738, 'weight_decay': 0.0002439052283437544}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:05:54,990] Trial 5 finished with value: 1.0315151122900157 and parameters: {'sigma': 0.07200272045298106, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 7.200392410601404e-05, 'weight_decay': 4.805247891073639e-06}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:07:52,940] Trial 6 finished with value: 1.1565371064039378 and parameters: {'sigma': 0.05925992584395274, 'num_layers': 5, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.0006291340787338628, 'weight_decay': 4.9928875180291455e-06}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:09:50,840] Trial 7 finished with value: 1.2052007638491118 and parameters: {'sigma': 0.09685514106470229, 'num_layers': 5, 'embed_size': 200, 'heads': 1, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0.5, 'class_drop': 0.1, 'learning_rate': 0.00031028431191116733, 'weight_decay': 6.4704101494114575e-06}. Best is trial 1 with value: 0.9835986907665546.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:10:41,955] Trial 8 finished with value: 0.8970486980218154 and parameters: {'sigma': 1.0888937230426785, 'num_layers': 1, 'embed_size': 250, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.0004465181189827505, 'weight_decay': 0.000650551938598664}. Best is trial 8 with value: 0.8970486980218154.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:11:52,242] Trial 9 finished with value: 0.8510246689503009 and parameters: {'sigma': 1.721795410600313, 'num_layers': 2, 'embed_size': 200, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0005885303468115297, 'weight_decay': 1.7203001197615383e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:13:57,694] Trial 10 finished with value: 0.8844472215725825 and parameters: {'sigma': 0.7712515088907079, 'num_layers': 2, 'embed_size': 90, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 1, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0007877862617721845, 'weight_decay': 1.0593097888181535e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:16:14,276] Trial 11 finished with value: 0.8685659536948571 and parameters: {'sigma': 0.6824948036188508, 'num_layers': 2, 'embed_size': 90, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 1, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.000796893714114766, 'weight_decay': 1.2539196085710924e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:17:23,168] Trial 12 finished with value: 0.9336208380185641 and parameters: {'sigma': 4.644093303081918, 'num_layers': 3, 'embed_size': 350, 'heads': 5, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0009371346351906823, 'weight_decay': 1.0576871088653054e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:18:41,306] Trial 13 finished with value: 0.9863393306732178 and parameters: {'sigma': 0.6199934829497831, 'num_layers': 3, 'embed_size': 160, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0.2, 'learning_rate': 0.00021521408020845503, 'weight_decay': 2.4538500498445946e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:21:39,533] Trial 14 finished with value: 0.8744409130169795 and parameters: {'sigma': 0.32674601112707596, 'num_layers': 2, 'embed_size': 90, 'heads': 5, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 1, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0009621441233823843, 'weight_decay': 2.0866416391878635e-05}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:22:38,280] Trial 15 finished with value: 0.889166350548084 and parameters: {'sigma': 1.8574513727479067, 'num_layers': 1, 'embed_size': 80, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 8, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.00046554717544594165, 'weight_decay': 2.4321820248405724e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:26:00,739] Trial 16 finished with value: 0.8532764453154343 and parameters: {'sigma': 0.2962715737885798, 'num_layers': 3, 'embed_size': 200, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0001443448000291845, 'weight_decay': 1.5278779456455277e-05}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:28:27,561] Trial 17 finished with value: 0.8827624962880061 and parameters: {'sigma': 0.25441347625998073, 'num_layers': 3, 'embed_size': 200, 'heads': 5, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 3, 'decoder_dropout': 0.2, 'class_drop': 0.2, 'learning_rate': 0.00014216144949154834, 'weight_decay': 1.7295312774378303e-05}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:31:33,380] Trial 18 finished with value: 0.9188028757388775 and parameters: {'sigma': 2.079145323184948, 'num_layers': 3, 'embed_size': 500, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 4, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 9.71664332723563e-05, 'weight_decay': 4.794258843853607e-05}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:33:16,198] Trial 19 finished with value: 0.9600662268125094 and parameters: {'sigma': 1.7736209268580048, 'num_layers': 4, 'embed_size': 70, 'heads': 5, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 5.928245455181524e-05, 'weight_decay': 9.695710243466028e-06}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:33:58,472] Trial 20 finished with value: 1.0152681194818938 and parameters: {'sigma': 0.2381920492143238, 'num_layers': 2, 'embed_size': 200, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 3, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.00037327848140942025, 'weight_decay': 1.0896745997164773e-05}. Best is trial 9 with value: 0.8510246689503009.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:34:41,330] Trial 21 finished with value: 0.8406074964083158 and parameters: {'sigma': 0.5054992960785056, 'num_layers': 2, 'embed_size': 180, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0005972219988272328, 'weight_decay': 2.2096414388937864e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:36:11,417] Trial 22 finished with value: 0.843196492928725 and parameters: {'sigma': 0.4105318079454861, 'num_layers': 3, 'embed_size': 180, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0005352592442484141, 'weight_decay': 2.7330172960889825e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:36:39,495] Trial 23 finished with value: 0.977464341200315 and parameters: {'sigma': 1.4096912636582895, 'num_layers': 1, 'embed_size': 180, 'heads': 5, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0005874131874145206, 'weight_decay': 2.4423382802950866e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:37:14,937] Trial 24 finished with value: 0.9359573217538687 and parameters: {'sigma': 4.124954789531053, 'num_layers': 2, 'embed_size': 180, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0005513118659116434, 'weight_decay': 2.8827984188107153e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:38:07,769] Trial 25 finished with value: 0.8573641777038574 and parameters: {'sigma': 0.45879911363935777, 'num_layers': 3, 'embed_size': 180, 'heads': 5, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0003267264610507554, 'weight_decay': 1.7058020524300434e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:38:56,979] Trial 26 finished with value: 0.9935628404984107 and parameters: {'sigma': 0.8982240577459539, 'num_layers': 2, 'embed_size': 180, 'heads': 1, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 2, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 0.0006012792002028058, 'weight_decay': 3.828321990701769e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:39:28,936] Trial 27 finished with value: 1.1934820138491118 and parameters: {'sigma': 2.4557040038280458, 'num_layers': 1, 'embed_size': 180, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 1, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.0004077597678578776, 'weight_decay': 1.6903101782954235e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:40:39,883] Trial 28 finished with value: 0.8420219375536993 and parameters: {'sigma': 1.308302872165852, 'num_layers': 2, 'embed_size': 80, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00028117613738886955, 'weight_decay': 6.731389172326474e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:43:37,924] Trial 29 finished with value: 0.8985941822712238 and parameters: {'sigma': 0.15358389565634434, 'num_layers': 3, 'embed_size': 80, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00026724307719032186, 'weight_decay': 6.8912633599914006e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:46:25,960] Trial 30 finished with value: 0.8419668353520907 and parameters: {'sigma': 0.49242784791275224, 'num_layers': 2, 'embed_size': 80, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0003662701197509151, 'weight_decay': 3.6522576212288785e-06}. Best is trial 21 with value: 0.8406074964083158.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:48:31,790] Trial 31 finished with value: 0.8281391583956205 and parameters: {'sigma': 0.47902778011062136, 'num_layers': 2, 'embed_size': 80, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00038383851693294746, 'weight_decay': 4.489250287352429e-06}. Best is trial 31 with value: 0.8281391583956205.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:49:53,527] Trial 32 finished with value: 0.8461336126694312 and parameters: {'sigma': 0.979038563876202, 'num_layers': 2, 'embed_size': 80, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0002672200862172835, 'weight_decay': 3.883615230529658e-06}. Best is trial 31 with value: 0.8281391583956205.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:51:28,301] Trial 33 finished with value: 0.8235765466323266 and parameters: {'sigma': 0.5347819646083243, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00040674780812929753, 'weight_decay': 6.081168643977236e-06}. Best is trial 33 with value: 0.8235765466323266.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:53:56,942] Trial 34 finished with value: 0.8319043242014371 and parameters: {'sigma': 0.42443074116362445, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0003787277408810612, 'weight_decay': 1.0412446744516598e-05}. Best is trial 33 with value: 0.8235765466323266.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:55:41,517] Trial 35 finished with value: 0.8562068480711716 and parameters: {'sigma': 0.16863137918312843, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0004231926277850712, 'weight_decay': 1.1569117441031467e-05}. Best is trial 33 with value: 0.8235765466323266.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:56:48,315] Trial 36 finished with value: 0.8078499344679025 and parameters: {'sigma': 0.5226799200350996, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007464621360371759, 'weight_decay': 3.0978677678455555e-05}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:58:01,573] Trial 37 finished with value: 1.0018384685883155 and parameters: {'sigma': 0.037520992208107715, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00021515665989349966, 'weight_decay': 2.7883685525338034e-05}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 16:59:11,394] Trial 38 finished with value: 0.8555151453384986 and parameters: {'sigma': 0.16599109912860413, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0008100325893228121, 'weight_decay': 8.692146458558012e-05}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:01:04,828] Trial 39 finished with value: 0.937582621207604 and parameters: {'sigma': 0.6830298522698911, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 1.2276682918553929e-05, 'weight_decay': 2.957464992849536e-05}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:02:31,201] Trial 40 finished with value: 0.8399257316039159 and parameters: {'sigma': 0.12063793015718301, 'num_layers': 1, 'embed_size': 100, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007003075354346371, 'weight_decay': 8.636854816289173e-06}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:05:06,824] Trial 41 finished with value: 0.9005252214578482 and parameters: {'sigma': 0.11810141810176843, 'num_layers': 1, 'embed_size': 100, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000712437224370601, 'weight_decay': 7.950261853401552e-06}. Best is trial 36 with value: 0.8078499344679025.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:07:05,353] Trial 42 finished with value: 0.8013817026064947 and parameters: {'sigma': 0.2657552094307526, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0004689346160196964, 'weight_decay': 5.109136944977831e-06}. Best is trial 42 with value: 0.8013817026064947.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:08:28,659] Trial 43 finished with value: 0.8261657082117521 and parameters: {'sigma': 0.3599835493107749, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00048588181193064345, 'weight_decay': 5.999607727907774e-06}. Best is trial 42 with value: 0.8013817026064947.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:09:28,600] Trial 44 finished with value: 0.9483300447463989 and parameters: {'sigma': 0.23756001532960247, 'num_layers': 1, 'embed_size': 60, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0.1, 'class_drop': 0, 'learning_rate': 0.00048516959656903064, 'weight_decay': 5.112696899488693e-06}. Best is trial 42 with value: 0.8013817026064947.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:10:30,798] Trial 45 finished with value: 0.8475839449809148 and parameters: {'sigma': 1.0347873885041732, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 8, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00047521037661271714, 'weight_decay': 5.169598099814188e-06}. Best is trial 42 with value: 0.8013817026064947.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:13:07,633] Trial 46 finished with value: 0.791869424856626 and parameters: {'sigma': 0.3606689400944542, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.000839176275255698, 'weight_decay': 1.4248808291589091e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:14:59,841] Trial 47 finished with value: 0.9294236302375793 and parameters: {'sigma': 0.3307189189514288, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0009165951393792206, 'weight_decay': 1.3120208695518228e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:17:50,803] Trial 48 finished with value: 0.9112369280595046 and parameters: {'sigma': 0.6855367740592662, 'num_layers': 5, 'embed_size': 50, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.000997798973591624, 'weight_decay': 1.8342336516953004e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:19:01,446] Trial 49 finished with value: 0.8319588303565979 and parameters: {'sigma': 0.06777307281987, 'num_layers': 1, 'embed_size': 250, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0007756523834870565, 'weight_decay': 2.1922891182160593e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:21:23,563] Trial 50 finished with value: 0.8387816594197199 and parameters: {'sigma': 0.20285603477818995, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0.1, 'class_drop': 0.2, 'learning_rate': 0.0006916765762338636, 'weight_decay': 1.539194358970874e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:22:48,116] Trial 51 finished with value: 0.8194821797884427 and parameters: {'sigma': 0.3813855116635126, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005062079867658924, 'weight_decay': 6.685120137773705e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:24:47,041] Trial 52 finished with value: 0.8453531036010156 and parameters: {'sigma': 0.27726695573095067, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0004988223883957703, 'weight_decay': 5.774246411313287e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:26:17,661] Trial 53 finished with value: 0.852411687374115 and parameters: {'sigma': 0.34695967017692453, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0006530265847004132, 'weight_decay': 7.857708495994657e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:27:37,529] Trial 54 finished with value: 0.8596968559118418 and parameters: {'sigma': 0.7438590280995651, 'num_layers': 1, 'embed_size': 350, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 8, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007770812542037316, 'weight_decay': 1.3285720960328612e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:29:40,979] Trial 55 finished with value: 0.8707245542452886 and parameters: {'sigma': 0.565616783860025, 'num_layers': 4, 'embed_size': 160, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005099827231228688, 'weight_decay': 8.944636002242007e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:31:13,607] Trial 56 finished with value: 0.8485939411016611 and parameters: {'sigma': 0.2806804071847285, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.0008735889201723347, 'weight_decay': 6.4366234794336805e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:32:22,860] Trial 57 finished with value: 0.8903316075985248 and parameters: {'sigma': 1.2854613681497595, 'num_layers': 1, 'embed_size': 500, 'heads': 10, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006517088994567496, 'weight_decay': 1.2158051077365559e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:34:33,239] Trial 58 finished with value: 0.829303883589231 and parameters: {'sigma': 0.3463398189844616, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005517536191175115, 'weight_decay': 2.115305284743535e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:35:42,812] Trial 59 finished with value: 0.9607395713145916 and parameters: {'sigma': 0.2008286990418753, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.00032193630795689733, 'weight_decay': 3.291414536879161e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:38:03,873] Trial 60 finished with value: 0.8418454161057105 and parameters: {'sigma': 0.8400299618966034, 'num_layers': 2, 'embed_size': 140, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00046691062564340033, 'weight_decay': 4.647458305993272e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:39:59,246] Trial 61 finished with value: 0.8831043335107657 and parameters: {'sigma': 0.5517607529861538, 'num_layers': 2, 'embed_size': 140, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 8, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0004280922740320578, 'weight_decay': 4.338164376140473e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:41:30,530] Trial 62 finished with value: 0.865239257995899 and parameters: {'sigma': 0.38150018572909083, 'num_layers': 1, 'embed_size': 60, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000994004644565229, 'weight_decay': 6.7133419705107255e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:43:03,447] Trial 63 finished with value: 0.8551827256496136 and parameters: {'sigma': 0.4756257093144609, 'num_layers': 2, 'embed_size': 90, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005914272020128519, 'weight_decay': 5.181887411453348e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:44:29,846] Trial 64 finished with value: 0.830537213728978 and parameters: {'sigma': 0.6038835398098574, 'num_layers': 1, 'embed_size': 50, 'heads': 5, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0003675851330181122, 'weight_decay': 3.5302494706950805e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:45:58,510] Trial 65 finished with value: 0.8590170328433697 and parameters: {'sigma': 0.8819381953000293, 'num_layers': 2, 'embed_size': 250, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 0.000786211317090647, 'weight_decay': 7.809592307061509e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:47:02,279] Trial 66 finished with value: 0.8462846462543194 and parameters: {'sigma': 0.38982640245152256, 'num_layers': 1, 'embed_size': 140, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005525432545550839, 'weight_decay': 1.0447244858282178e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:48:57,705] Trial 67 finished with value: 0.8622510570746201 and parameters: {'sigma': 0.24419010752447579, 'num_layers': 2, 'embed_size': 140, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006536869225815073, 'weight_decay': 4.428602961148743e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:50:52,736] Trial 68 finished with value: 0.9007948545309213 and parameters: {'sigma': 1.165251588160354, 'num_layers': 1, 'embed_size': 120, 'heads': 5, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 8, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.00039748893164509157, 'weight_decay': 2.96389365284207e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:52:01,005] Trial 69 finished with value: 0.846090188393226 and parameters: {'sigma': 0.4787320042195534, 'num_layers': 1, 'embed_size': 160, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0004580034423637186, 'weight_decay': 6.211509241352141e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:53:07,428] Trial 70 finished with value: 0.84231403699288 and parameters: {'sigma': 0.3134970513484037, 'num_layers': 2, 'embed_size': 350, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0008715018688700204, 'weight_decay': 8.998512310986344e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:54:26,023] Trial 71 finished with value: 0.8280907227442815 and parameters: {'sigma': 0.3621347614487784, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005736008776850077, 'weight_decay': 2.2579517366586657e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:56:22,652] Trial 72 finished with value: 0.817779894058521 and parameters: {'sigma': 0.6357201328559703, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005496095331575765, 'weight_decay': 4.1749307524641145e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:57:32,739] Trial 73 finished with value: 0.8861712767527654 and parameters: {'sigma': 0.7186846625918201, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005521628931629238, 'weight_decay': 4.6261353386581834e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:58:13,284] Trial 74 finished with value: 0.931074280005235 and parameters: {'sigma': 1.5070958386500244, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0007144038179889205, 'weight_decay': 3.538440199670527e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 17:59:40,723] Trial 75 finished with value: 0.8318679653681241 and parameters: {'sigma': 0.3997919809550377, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0006288434575140524, 'weight_decay': 2.6262292736462448e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:01:29,272] Trial 76 finished with value: 0.8515059397770808 and parameters: {'sigma': 0.6030496399518418, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005175825692930972, 'weight_decay': 3.8155654188386455e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:02:34,352] Trial 77 finished with value: 0.8569492009969858 and parameters: {'sigma': 0.9140921037438606, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.00043682946084548744, 'weight_decay': 7.484043573479066e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:04:10,195] Trial 78 finished with value: 0.8671005689180814 and parameters: {'sigma': 0.2088807338638533, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0.2, 'learning_rate': 0.0008010590380727988, 'weight_decay': 1.5542223155161147e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:06:21,187] Trial 79 finished with value: 0.8525056976538438 and parameters: {'sigma': 0.28071315368352523, 'num_layers': 1, 'embed_size': 500, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.00034027861139694654, 'weight_decay': 2.644890627734818e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:08:43,497] Trial 80 finished with value: 0.8130025817797735 and parameters: {'sigma': 0.14300060389998367, 'num_layers': 1, 'embed_size': 200, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0002958541433104799, 'weight_decay': 1.3785618190597795e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:11:09,461] Trial 81 finished with value: 0.8383843256877019 and parameters: {'sigma': 0.1374967087290248, 'num_layers': 1, 'embed_size': 200, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.00030292831923098295, 'weight_decay': 1.8772291050332617e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:13:27,582] Trial 82 finished with value: 0.8932251150791461 and parameters: {'sigma': 0.1783438787326698, 'num_layers': 1, 'embed_size': 200, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0004053377457671086, 'weight_decay': 1.4372990039030411e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:14:51,176] Trial 83 finished with value: 0.8486544810808622 and parameters: {'sigma': 0.24694670255779275, 'num_layers': 1, 'embed_size': 200, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005654240303409856, 'weight_decay': 1.0636325066054169e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:16:46,655] Trial 84 finished with value: 0.8070477614035974 and parameters: {'sigma': 0.42492496597515644, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0006139849557134155, 'weight_decay': 1.7080169973208027e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:20:05,461] Trial 85 finished with value: 0.9402617995555584 and parameters: {'sigma': 0.09908630142586576, 'num_layers': 5, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.000485822595650917, 'weight_decay': 1.1009889518224408e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:21:59,430] Trial 86 finished with value: 0.8835164858744695 and parameters: {'sigma': 0.5315701842422392, 'num_layers': 1, 'embed_size': 140, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0007288074335010455, 'weight_decay': 1.5993457919008394e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:23:19,311] Trial 87 finished with value: 1.1230288056226878 and parameters: {'sigma': 0.4322990197793879, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0.5, 'class_drop': 0.5, 'learning_rate': 0.0006221751161859704, 'weight_decay': 1.2841746417739775e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:28:10,663] Trial 88 finished with value: 0.9091790914535522 and parameters: {'sigma': 0.1515571650873787, 'num_layers': 4, 'embed_size': 100, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0008582523849920385, 'weight_decay': 7.3416170038791e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:29:24,433] Trial 89 finished with value: 0.881343676493718 and parameters: {'sigma': 0.723662481495688, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00044715811722976606, 'weight_decay': 9.191673916443535e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:31:15,225] Trial 90 finished with value: 0.8295817787830646 and parameters: {'sigma': 0.2913920737649007, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007155374417458151, 'weight_decay': 1.720176125646207e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:33:28,805] Trial 91 finished with value: 0.8199884387163016 and parameters: {'sigma': 0.3608802826003036, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0005203987793482032, 'weight_decay': 1.949871810448787e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:35:58,167] Trial 92 finished with value: 0.841373819571275 and parameters: {'sigma': 0.21157210283738617, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.00035949442931590246, 'weight_decay': 5.826531531570154e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:37:31,274] Trial 93 finished with value: 0.8388022780418396 and parameters: {'sigma': 0.5673964390379301, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0004982955854557806, 'weight_decay': 2.4187422515145833e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:40:00,270] Trial 94 finished with value: 0.8358606833678025 and parameters: {'sigma': 0.34056972316910944, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0004089949594213808, 'weight_decay': 2.1532245231847077e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:42:26,559] Trial 95 finished with value: 0.8282645573982825 and parameters: {'sigma': 0.4485558073083492, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 3, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.000617597089905524, 'weight_decay': 1.2864774213508103e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:43:30,959] Trial 96 finished with value: 0.8620075033261225 and parameters: {'sigma': 1.0246532713438798, 'num_layers': 1, 'embed_size': 140, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000509257352900712, 'weight_decay': 3.0180500330036075e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:44:39,887] Trial 97 finished with value: 0.8642520583592929 and parameters: {'sigma': 0.30707454758414443, 'num_layers': 1, 'embed_size': 60, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 6, 'decoder_dropout': 0.1, 'class_drop': 0.2, 'learning_rate': 0.0008886114382388415, 'weight_decay': 1.9060293753497317e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:45:56,230] Trial 98 finished with value: 0.8632953808857844 and parameters: {'sigma': 0.6476550957976229, 'num_layers': 1, 'embed_size': 250, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0003511876708774114, 'weight_decay': 8.29123714263964e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:47:20,096] Trial 99 finished with value: 0.8536240366789011 and parameters: {'sigma': 0.2552794102638897, 'num_layers': 1, 'embed_size': 200, 'heads': 5, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 8, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.0006840685472214593, 'weight_decay': 1.5344379293162827e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:49:23,598] Trial 100 finished with value: 0.8247890564111563 and parameters: {'sigma': 0.4063100180935974, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005232761989740501, 'weight_decay': 9.605449626144824e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:50:45,290] Trial 101 finished with value: 0.8531432381043067 and parameters: {'sigma': 0.4102353405043195, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.00043612420323118543, 'weight_decay': 9.731959588941846e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:53:01,128] Trial 102 finished with value: 0.8074069802577679 and parameters: {'sigma': 0.5122516894801137, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005429104567453182, 'weight_decay': 1.1962321813343313e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:54:58,218] Trial 103 finished with value: 0.8146897554397583 and parameters: {'sigma': 0.47440456976545503, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005992107236633875, 'weight_decay': 1.2085998591194012e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:56:49,639] Trial 104 finished with value: 0.8333876591462356 and parameters: {'sigma': 0.5393925048866188, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006127568127906992, 'weight_decay': 1.8692965996337893e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:57:44,067] Trial 105 finished with value: 0.8322842304523175 and parameters: {'sigma': 0.8165696340206852, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007308013752778028, 'weight_decay': 1.2499788427045473e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 18:59:06,559] Trial 106 finished with value: 0.8945752244729263 and parameters: {'sigma': 0.4776721925945505, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0005795439035775205, 'weight_decay': 1.7033812736661507e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:00:37,008] Trial 107 finished with value: 0.8512638027851398 and parameters: {'sigma': 0.655520788215941, 'num_layers': 1, 'embed_size': 120, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0006595708764714885, 'weight_decay': 1.1260399936427582e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:02:31,630] Trial 108 finished with value: 0.8825575846892136 and parameters: {'sigma': 0.7898322917761766, 'num_layers': 1, 'embed_size': 350, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0009386751594868993, 'weight_decay': 2.3638534688667443e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:04:37,410] Trial 109 finished with value: 0.843642729979295 and parameters: {'sigma': 0.3423165593112243, 'num_layers': 1, 'embed_size': 160, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0008137914569120158, 'weight_decay': 1.4092306464423376e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:05:34,403] Trial 110 finished with value: 0.9183269509902368 and parameters: {'sigma': 0.22035776666425794, 'num_layers': 1, 'embed_size': 120, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0.2, 'class_drop': 0.2, 'learning_rate': 0.0004532750381321661, 'weight_decay': 7.482777841719865e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:07:40,742] Trial 111 finished with value: 0.8152464765768784 and parameters: {'sigma': 0.4438813745727633, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005304515937886101, 'weight_decay': 1.0195590522621904e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:10:10,467] Trial 112 finished with value: 0.8461922636398902 and parameters: {'sigma': 0.28621590993834767, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000556718419326368, 'weight_decay': 1.1797239967855263e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:12:27,554] Trial 113 finished with value: 0.853866343314831 and parameters: {'sigma': 0.5041880049966356, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0003875323760688009, 'weight_decay': 8.465267386833889e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:15:36,237] Trial 114 finished with value: 0.8231253165465134 and parameters: {'sigma': 0.18131105038531534, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000512343324365497, 'weight_decay': 1.4133286317006474e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:17:21,384] Trial 115 finished with value: 0.8161515593528748 and parameters: {'sigma': 0.17123946603071377, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007471701738841499, 'weight_decay': 1.4483854720239721e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:19:32,005] Trial 116 finished with value: 0.8435505628585815 and parameters: {'sigma': 0.33298584505412493, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000649983483219714, 'weight_decay': 1.61492087571916e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:20:57,815] Trial 117 finished with value: 0.8651603368612436 and parameters: {'sigma': 0.24088604899301802, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000751485054884686, 'weight_decay': 1.9994447471020776e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:22:36,939] Trial 118 finished with value: 0.8985860026799716 and parameters: {'sigma': 0.17070475337022975, 'num_layers': 1, 'embed_size': 500, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.0008221393291870036, 'weight_decay': 2.601497216881723e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:24:39,303] Trial 119 finished with value: 0.8351865640053382 and parameters: {'sigma': 0.12864861526907645, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0, 'learning_rate': 0.0006616119767435873, 'weight_decay': 2.039626074115682e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:26:27,681] Trial 120 finished with value: 0.8318981390732986 and parameters: {'sigma': 0.6182944293762367, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.000988224952870418, 'weight_decay': 2.9551583891461567e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:28:36,682] Trial 121 finished with value: 0.8136643629807693 and parameters: {'sigma': 0.19499123719719774, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005913836196644989, 'weight_decay': 1.3991491096249987e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:31:15,941] Trial 122 finished with value: 0.8195421535235184 and parameters: {'sigma': 0.4238293283533031, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000587227127226575, 'weight_decay': 1.0578478836361124e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:33:23,566] Trial 123 finished with value: 0.7987833573268011 and parameters: {'sigma': 0.18962351983055664, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005942623839360499, 'weight_decay': 1.1328216910769061e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:35:45,135] Trial 124 finished with value: 0.8164242368478042 and parameters: {'sigma': 0.19692196885532776, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007233390973121522, 'weight_decay': 1.2074163070264442e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:38:40,159] Trial 125 finished with value: 0.8511845056827252 and parameters: {'sigma': 0.09825266010565055, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007454499343187543, 'weight_decay': 1.394290747592771e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:40:30,490] Trial 126 finished with value: 0.8294298098637507 and parameters: {'sigma': 0.20342702566928322, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0008425419447353833, 'weight_decay': 1.1974639094706483e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:43:12,081] Trial 127 finished with value: 0.807847953759707 and parameters: {'sigma': 0.12004388447061456, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.000675295281382884, 'weight_decay': 1.7050108334363708e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:45:29,097] Trial 128 finished with value: 0.8271919167958773 and parameters: {'sigma': 0.13844133488063137, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006903365001639287, 'weight_decay': 1.68610122103315e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:47:54,354] Trial 129 finished with value: 0.824488992874439 and parameters: {'sigma': 0.11452884593337927, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007561098469969107, 'weight_decay': 1.0217066945748128e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:48:21,993] Trial 130 finished with value: 1.3007087065623357 and parameters: {'sigma': 0.14921415460098258, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0009050632739061395, 'weight_decay': 1.3468770148060861e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:48:52,385] Trial 131 finished with value: 0.9519940477151138 and parameters: {'sigma': 0.18003739643925115, 'num_layers': 1, 'embed_size': 80, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006067164891397702, 'weight_decay': 1.5345871778531166e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:51:06,211] Trial 132 finished with value: 0.8478146470510043 and parameters: {'sigma': 0.23911877590413003, 'num_layers': 1, 'embed_size': 100, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006699483509098969, 'weight_decay': 1.1249466584665378e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:53:25,186] Trial 133 finished with value: 0.8010432078288152 and parameters: {'sigma': 0.08860330818243871, 'num_layers': 1, 'embed_size': 180, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005517268982875988, 'weight_decay': 9.05902724930016e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:55:30,083] Trial 134 finished with value: 0.8546706942411569 and parameters: {'sigma': 0.11832366740121744, 'num_layers': 1, 'embed_size': 180, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0008083664370283334, 'weight_decay': 9.435945394391656e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 19:58:21,501] Trial 135 finished with value: 0.8272428145775428 and parameters: {'sigma': 0.0771838640956329, 'num_layers': 3, 'embed_size': 180, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006058374749464041, 'weight_decay': 8.289305364060194e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:00:09,861] Trial 136 finished with value: 0.9451776238588186 and parameters: {'sigma': 0.08482539783423956, 'num_layers': 1, 'embed_size': 180, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0007020835486731977, 'weight_decay': 1.2239361025428127e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:02:00,292] Trial 137 finished with value: 0.8206472947047307 and parameters: {'sigma': 0.16177983425946948, 'num_layers': 1, 'embed_size': 200, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0004718363994542304, 'weight_decay': 1.773783523538798e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:02:59,561] Trial 138 finished with value: 0.9959649581175584 and parameters: {'sigma': 0.10837310418463623, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005477506485540223, 'weight_decay': 7.334046852793354e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:04:46,546] Trial 139 finished with value: 0.8312609424957862 and parameters: {'sigma': 0.13513998551174378, 'num_layers': 1, 'embed_size': 60, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 6, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0008972610998665802, 'weight_decay': 1.441975298867128e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:06:49,393] Trial 140 finished with value: 0.796863500888531 and parameters: {'sigma': 0.19394791669188535, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007581479334205916, 'weight_decay': 9.370372069784769e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:08:39,731] Trial 141 finished with value: 0.8343582382568946 and parameters: {'sigma': 0.20747587544844878, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0007897470205454438, 'weight_decay': 9.767067742154137e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:10:47,390] Trial 142 finished with value: 0.8006777671667246 and parameters: {'sigma': 0.271469138398753, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006444788605683726, 'weight_decay': 1.1968836049465604e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:12:52,124] Trial 143 finished with value: 0.8066194791060227 and parameters: {'sigma': 0.27802582800008, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006346844309249213, 'weight_decay': 8.989373366541977e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:14:26,884] Trial 144 finished with value: 0.8278618454933167 and parameters: {'sigma': 0.27532415367432544, 'num_layers': 1, 'embed_size': 250, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0006108476759425675, 'weight_decay': 8.382045455046593e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:16:40,849] Trial 145 finished with value: 0.834328293800354 and parameters: {'sigma': 0.25927210333289646, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 4, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.0006542718315538416, 'weight_decay': 7.110239199515912e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:19:14,817] Trial 146 finished with value: 0.8508529387987577 and parameters: {'sigma': 0.30132381293906596, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0005593368786625551, 'weight_decay': 1.0800450885177285e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:21:25,935] Trial 147 finished with value: 0.8458876151304978 and parameters: {'sigma': 0.055756414713904245, 'num_layers': 1, 'embed_size': 180, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0004713572751820559, 'weight_decay': 9.259291751577743e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:22:50,233] Trial 148 finished with value: 0.8154400403683002 and parameters: {'sigma': 0.23347055070361938, 'num_layers': 1, 'embed_size': 350, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.0004239788627091617, 'weight_decay': 5.810247749108445e-06}. Best is trial 46 with value: 0.791869424856626.\n",
      "Early stopping\n",
      "[I 2024-01-06 20:23:50,648] Trial 149 finished with value: 0.9474787482848535 and parameters: {'sigma': 0.31900972584141296, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 0.0005440326952244279, 'weight_decay': 1.2461901292444689e-05}. Best is trial 46 with value: 0.791869424856626.\n",
      "Best Hyperparameters: {'sigma': 0.3606689400944542, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.000839176275255698, 'weight_decay': 1.4248808291589091e-05}\n",
      "Best Validation RMSE (at Early Stopping): 0.791869424856626\n"
     ]
    }
   ],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 150\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='minimize')  \n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_rmse = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation RMSE (at Early Stopping):\", best_val_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
