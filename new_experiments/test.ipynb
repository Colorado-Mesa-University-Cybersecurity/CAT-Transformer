{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from rtdl_revisiting_models import FTTransformer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/wdwatson2/projects/CAT-Transformer/model')\n",
    "from testingModel import CATTransformer, MyFTTransformer, Combined_Dataset, train, test, EarlyStopping\n",
    "\n",
    "device_in_use = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/income/train.csv')\n",
    "df_test = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/income/test.csv')\n",
    "df_val = pd.read_csv('/home/wdwatson2/projects/CAT-Transformer/datasets/income/validation.csv') \n",
    "\n",
    "cont_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "       'hours-per-week']\n",
    "cat_columns = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "       'relationship', 'race', 'sex', 'native-country']\n",
    "target = ['income']\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cont_columns + cat_columns+target\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put one of them in the list\"\n",
    "\n",
    "cat_features = (10,16,7,16,6,5,2,43)\n",
    "\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]\n",
    "print(target_classes)\n",
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = Combined_Dataset(df_train, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "val_dataset = Combined_Dataset(df_val, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "test_dataset = Combined_Dataset(df_test, cat_columns=cat_columns, num_columns=cont_columns, task1_column=target[0])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FTTransformer(\n",
    "    n_cont_features=len(cont_columns),\n",
    "    cat_cardinalities=cat_features,\n",
    "    d_out=target_classes[0],\n",
    "    **FTTransformer.get_default_kwargs(),\n",
    ").to(device_in_use)\n",
    "optimizer = ft_model.make_default_optimizer()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
