{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smbm2\\AppData\\Local\\miniconda3\\envs\\ml-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and being used\n"
     ]
    }
   ],
   "source": [
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_val = pd.read_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(df_train.columns)-1\n",
    "class_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTaskDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.int64).values\n",
    "\n",
    "        # self.scalar = StandardScaler()\n",
    "        # self.x = self.scalar.fit_transform(df.drop(columns=[task1_column])).astype(np.float32)\n",
    "        self.x = df.drop(task1_column, axis=1).astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        features = self.x[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return features, labels_task1\n",
    "        # return self.x[index], self.task1_labels[index], self.task2_labels[index]\n",
    "\n",
    "train_dataset = SingleTaskDataset(df_train, 'income')\n",
    "val_dataset = SingleTaskDataset(df_val, 'income')\n",
    "test_dataset = SingleTaskDataset(df_test, 'income')\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each task loss is scaled by its own learnable parameter, then regularization is applied \n",
    "class UncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks):\n",
    "        super(UncertaintyLoss, self).__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        self.loss_fns = [nn.CrossEntropyLoss() for x in range(num_tasks)] \n",
    "\n",
    "    def forward(self, predictions, labels_task1):\n",
    "\n",
    "        #task 1\n",
    "        target = labels_task1\n",
    "        prediction = predictions[0]\n",
    "        loss_fn = self.loss_fns[0]\n",
    "        task_loss = loss_fn(prediction, target)\n",
    "        \n",
    "        return task_loss\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_features, num_target_labels, rff_on):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.rff_on = rff_on\n",
    "\n",
    "        if self.rff_on:\n",
    "            self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_features)])\n",
    "            self.dropout = nn.Dropout(embedding_dropout)\n",
    "            self.mlp_in = embed_size\n",
    "        else:\n",
    "            self.mlp_in = input_size\n",
    "\n",
    "        self.embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_features)])\n",
    "\n",
    "        # Classifcation Embeddings for each target label\n",
    "        self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "        rff_vectors = []\n",
    "        if self.rff_on:\n",
    "            for i, r in enumerate(self.rffs):\n",
    "                input = x[:,i,:]\n",
    "                out = r(input)\n",
    "                rff_vectors.append(out)\n",
    "        \n",
    "            x = torch.stack(rff_vectors, dim=1)\n",
    "        \n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embeddings):\n",
    "            goin_in = x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embeddings:\n",
    "            input = torch.tensor([0], device=x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(x.size(0), 1)\n",
    "            tmep = temp.unsqueeze(1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "        \n",
    "        # class_embed = self.classification_embedding(torch.tensor([0], device=x.device))  # use index 0 for the classification embedding\n",
    "        # class_embed = class_embed.repeat(x.size(0), 1) # -> (batch_size, embed_size)\n",
    "        # class_embed = class_embed.unsqueeze(1)\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "        return class_embeddings, context\n",
    "\n",
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(classificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, num_target_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "\n",
    "# DEFAULT PARAMETERS SET UP FOR VPN DATASET. BE CAREFUL AND MAKE SURE YOU SET THEM UP HOW YOU WANT.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rff_on = False,\n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 embedding_dropout = 0,\n",
    "                 n_features=23, # YOU WILL PROBABLY NEED TO CHANGE\n",
    "                 num_layers=1,\n",
    "                 heads=1,\n",
    "                 forward_expansion=4, # Determines how wide the MLP is in the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0,\n",
    "                 classification_dropout = 0,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 4,\n",
    "                 targets_classes : list=  [3,8]\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(rff_on=rff_on, sigma=sigma, embed_size=embed_size, input_size=input_size, embedding_dropout=embedding_dropout, n_features=n_features, num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        self.classifying_heads = nn.ModuleList([classificationHead(embed_size=embed_size, dropout=classification_dropout, mlp_scale_classification=mlp_scale_classification, num_target_classes=x) for x in targets_classes])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        class_embed, context = self.embeddings(x)\n",
    "\n",
    "        x = self.decoder(class_embed, context)\n",
    "        \n",
    "        probability_dist_raw = []\n",
    "        for i, e in enumerate(self.classifying_heads):\n",
    "            input = x[:, i,:]\n",
    "            output = e(input)\n",
    "            probability_dist_raw.append(output)\n",
    "        \n",
    "        return probability_dist_raw\n",
    "\n",
    "# Training and Testing Loops\n",
    "def train(dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    total_correct_1 = 0\n",
    "    total_samples_1 = 0\n",
    "    all_targets_1 = []\n",
    "    all_predictions_1 = []\n",
    "\n",
    "    total_correct_2 = 0\n",
    "    total_samples_2 = 0\n",
    "    all_targets_2 = []\n",
    "    all_predictions_2 = []\n",
    "\n",
    "    for (features,labels_task1,) in dataloader:\n",
    "        features,labels_task1 = features.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "\n",
    "        task_predictions = model(features) #contains a list of the tensor outputs for each task\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #computing accuracy for first target\n",
    "        y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "        _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "        total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "        total_samples_1 += labels_task1.size(0)\n",
    "        all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "        all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "        # #computing accuaracy for second target\n",
    "        # y_pred_softmax_2 = torch.softmax(task_predictions[1], dim=1)\n",
    "        # _, y_pred_labels_2 = torch.max(y_pred_softmax_2, dim=1)\n",
    "        # total_correct_2 += (y_pred_labels_2 == labels_task2).sum().item()\n",
    "        # total_samples_2 += labels_task2.size(0)\n",
    "        # all_targets_2.extend(labels_task2.cpu().numpy())\n",
    "        # all_predictions_2.extend(y_pred_labels_2.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss/len(dataloader)\n",
    "    accuracy_1 = total_correct_1 / total_samples_1\n",
    "    # accuracy_2 = total_correct_2 / total_samples_2\n",
    "\n",
    "    # # precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    # f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "    return avg_loss, accuracy_1\n",
    "\n",
    "def test(dataloader, model, loss_function, device_in_use):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_correct_1 = 0\n",
    "  total_samples_1 = 0\n",
    "  all_targets_1 = []\n",
    "  all_predictions_1 = []\n",
    "\n",
    "  total_correct_2 = 0\n",
    "  total_samples_2 = 0\n",
    "  all_targets_2 = []\n",
    "  all_predictions_2 = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (features,labels_task1) in dataloader:\n",
    "      features,labels_task1 = features.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "      #compute prediction error\n",
    "      task_predictions = model(features) #contains a list of the tensor outputs for each task\n",
    "\n",
    "      loss = loss_function(task_predictions, labels_task1)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      #computing accuracy for first target\n",
    "      y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "      _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "      total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "      total_samples_1 += labels_task1.size(0)\n",
    "      all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "      all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "      # #computing accuaracy for second target\n",
    "      # y_pred_softmax_2 = torch.softmax(task_predictions[1], dim=1)\n",
    "      # _, y_pred_labels_2 = torch.max(y_pred_softmax_2, dim=1)\n",
    "      # total_correct_2 += (y_pred_labels_2 == labels_task2).sum().item()\n",
    "      # total_samples_2 += labels_task2.size(0)\n",
    "      # all_targets_2.extend(labels_task2.cpu().numpy())\n",
    "      # all_predictions_2.extend(y_pred_labels_2.cpu().numpy())\n",
    "\n",
    "  avg = total_loss/len(dataloader)\n",
    "  accuracy_1 = total_correct_1 / total_samples_1\n",
    "  # accuracy_2 = total_correct_2 / total_samples_2\n",
    "  # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "  f1_1 = f1_score(all_targets_1, all_predictions_1, average='weighted')\n",
    "  # f1_2 = f1_score(all_targets_2, all_predictions_2, average=\"weighted\")\n",
    "\n",
    "  return avg, accuracy_1, all_predictions_1, all_targets_1, f1_1\n",
    "\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_metric = float('-inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Function to log results to a text file\n",
    "def log_to_file(filename, text):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(text + '\\n')\n",
    "\n",
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    rff_on = trial.suggest_categorical('rff_on', [True, False])\n",
    "    sigma = trial.suggest_categorical('sigma', [.001, 0.1, 1, 2, 3, 5, 10])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    prenorm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.001, 0.01])\n",
    "\n",
    "    num_epochs = 75\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = Classifier(\n",
    "        n_features=num_features,\n",
    "        targets_classes=[class_count],\n",
    "        rff_on=rff_on,\n",
    "        sigma=sigma,\n",
    "        embed_size=embed_size,\n",
    "        num_layers=num_layers,\n",
    "        heads=heads,\n",
    "        forward_expansion=forward_expansion,\n",
    "        pre_norm_on=prenorm_on,\n",
    "        mlp_scale_classification=mlp_scale_classification\n",
    "    ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = UncertaintyLoss(1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=4)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
    "        \n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy, _, _, _ = test(test_dataloader, model, loss_function, device_in_use)\n",
    "        \n",
    "        # Check if we should early stop based on validation accuracy\n",
    "        if early_stopping(val_accuracy):\n",
    "            break\n",
    "\n",
    "    # # Evaluate the model on the test set\n",
    "    # test_loss, test_accuracy, _, _, _ = test(test_dataloader, model, loss_function, device_in_use)\n",
    "    \n",
    "    # Log the final test accuracy for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation Accuracy = {val_accuracy:.4f}\"\n",
    "    log_to_file('all_trials_log.txt', final_log)\n",
    "\n",
    "    # Return the test accuracy as the objective to optimize\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 19:50:14,706] A new study created in memory with name: no-name-343c4c21-5c14-4ab2-a242-66de2d5f0367\n",
      "Best trial: 0. Best value: 0.852756:   2%|▏         | 1/50 [02:25<1:59:04, 145.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 19:52:40,512] Trial 0 finished with value: 0.8527560264087211 and parameters: {'rff_on': False, 'sigma': 1, 'num_layers': 1, 'embed_size': 100, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 3, 'learning_rate': 0.01}. Best is trial 0 with value: 0.8527560264087211.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.852756:   4%|▍         | 2/50 [04:37<1:50:08, 137.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 19:54:52,492] Trial 1 finished with value: 0.8470750806080147 and parameters: {'rff_on': False, 'sigma': 2, 'num_layers': 1, 'embed_size': 160, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 8, 'learning_rate': 0.001}. Best is trial 0 with value: 0.8527560264087211.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.854906:   6%|▌         | 3/50 [07:15<1:54:50, 146.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 19:57:29,711] Trial 2 finished with value: 0.8549055734684478 and parameters: {'rff_on': True, 'sigma': 10, 'num_layers': 2, 'embed_size': 100, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 5, 'learning_rate': 0.01}. Best is trial 2 with value: 0.8549055734684478.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.854906:   8%|▊         | 4/50 [09:23<1:46:53, 139.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 19:59:38,130] Trial 3 finished with value: 0.8541378780899739 and parameters: {'rff_on': False, 'sigma': 1, 'num_layers': 1, 'embed_size': 90, 'heads': 5, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 2, 'learning_rate': 0.01}. Best is trial 2 with value: 0.8549055734684478.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.854906:  10%|█         | 5/50 [12:02<1:49:47, 146.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:02:16,879] Trial 4 finished with value: 0.7640104406571473 and parameters: {'rff_on': True, 'sigma': 1, 'num_layers': 2, 'embed_size': 70, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.01}. Best is trial 2 with value: 0.8549055734684478.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.857823:  12%|█▏        | 6/50 [14:31<1:48:05, 147.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:04:46,240] Trial 5 finished with value: 0.8578228159066482 and parameters: {'rff_on': True, 'sigma': 3, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 8, 'learning_rate': 0.001}. Best is trial 5 with value: 0.8578228159066482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.857823:  14%|█▍        | 7/50 [16:50<1:43:41, 144.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:07:05,358] Trial 6 finished with value: 0.7640104406571473 and parameters: {'rff_on': False, 'sigma': 3, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 6, 'learning_rate': 0.01}. Best is trial 5 with value: 0.8578228159066482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  16%|█▌        | 8/50 [19:13<1:40:56, 144.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:09:28,481] Trial 7 finished with value: 0.8610471364962383 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 70, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 1, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  18%|█▊        | 9/50 [21:25<1:35:52, 140.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:11:40,220] Trial 8 finished with value: 0.8418547520343928 and parameters: {'rff_on': False, 'sigma': 1, 'num_layers': 1, 'embed_size': 100, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  20%|██        | 10/50 [23:38<1:31:59, 137.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:13:53,029] Trial 9 finished with value: 0.8027022877322278 and parameters: {'rff_on': False, 'sigma': 5, 'num_layers': 2, 'embed_size': 50, 'heads': 1, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 1, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  22%|██▏       | 11/50 [26:02<1:30:57, 139.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:16:17,352] Trial 10 finished with value: 0.8496852448948258 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  24%|██▍       | 12/50 [28:37<1:31:25, 144.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:18:51,863] Trial 11 finished with value: 0.8507600184246891 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 2, 'embed_size': 70, 'heads': 5, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 8, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  26%|██▌       | 13/50 [30:57<1:28:16, 143.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:21:12,256] Trial 12 finished with value: 0.8435436818670352 and parameters: {'rff_on': True, 'sigma': 0.001, 'num_layers': 1, 'embed_size': 60, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 6, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  28%|██▊       | 14/50 [33:32<1:27:57, 146.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:23:46,782] Trial 13 finished with value: 0.8337171810225702 and parameters: {'rff_on': True, 'sigma': 3, 'num_layers': 2, 'embed_size': 140, 'heads': 5, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 7, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  30%|███       | 15/50 [35:56<1:25:05, 145.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:26:10,974] Trial 14 finished with value: 0.8377091969906341 and parameters: {'rff_on': True, 'sigma': 3, 'num_layers': 1, 'embed_size': 80, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 4, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  32%|███▏      | 16/50 [38:27<1:23:38, 147.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:28:42,568] Trial 15 finished with value: 0.8598188238906802 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 5, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  34%|███▍      | 17/50 [41:06<1:23:01, 150.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:31:21,334] Trial 16 finished with value: 0.8570551205281745 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 2, 'embed_size': 70, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 5, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  36%|███▌      | 18/50 [43:29<1:19:15, 148.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:33:44,449] Trial 17 finished with value: 0.8487640104406572 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 80, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 4, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  38%|███▊      | 19/50 [45:56<1:16:27, 147.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:36:11,018] Trial 18 finished with value: 0.8576692768309535 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 6, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  40%|████      | 20/50 [48:33<1:15:23, 150.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:38:48,340] Trial 19 finished with value: 0.8395516658989712 and parameters: {'rff_on': True, 'sigma': 10, 'num_layers': 2, 'embed_size': 140, 'heads': 10, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 3, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  42%|████▏     | 21/50 [51:06<1:13:08, 151.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:41:20,869] Trial 20 finished with value: 0.7640104406571473 and parameters: {'rff_on': True, 'sigma': 0.001, 'num_layers': 2, 'embed_size': 160, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 2, 'learning_rate': 0.01}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  44%|████▍     | 22/50 [53:35<1:10:24, 150.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:43:50,687] Trial 21 finished with value: 0.8555197297712268 and parameters: {'rff_on': True, 'sigma': 2, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 7, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  46%|████▌     | 23/50 [56:05<1:07:40, 150.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:46:20,002] Trial 22 finished with value: 0.855366190695532 and parameters: {'rff_on': True, 'sigma': 5, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 7, 'prenorm_on': False, 'mlp_scale_classification': 7, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.861047:  48%|████▊     | 24/50 [58:36<1:05:19, 150.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:48:51,575] Trial 23 finished with value: 0.8575157377552587 and parameters: {'rff_on': True, 'sigma': 3, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 5, 'learning_rate': 0.001}. Best is trial 7 with value: 0.8610471364962383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.861201:  50%|█████     | 25/50 [1:01:07<1:02:50, 150.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:51:22,573] Trial 24 finished with value: 0.861200675571933 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 2, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 4, 'learning_rate': 0.001}. Best is trial 24 with value: 0.861200675571933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.861201:  52%|█████▏    | 26/50 [1:03:41<1:00:36, 151.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:53:55,747] Trial 25 finished with value: 0.8578228159066482 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 2, 'embed_size': 50, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 4, 'learning_rate': 0.001}. Best is trial 24 with value: 0.861200675571933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 26. Best value: 0.861508:  54%|█████▍    | 27/50 [1:06:07<57:26, 149.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:56:21,742] Trial 26 finished with value: 0.8615077537233226 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 26 with value: 0.8615077537233226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  56%|█████▌    | 28/50 [1:08:31<54:20, 148.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 20:58:46,098] Trial 27 finished with value: 0.8648856133886074 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  58%|█████▊    | 29/50 [1:10:58<51:43, 147.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:01:12,943] Trial 28 finished with value: 0.8584369722094273 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  60%|██████    | 30/50 [1:13:14<48:08, 144.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:03:29,477] Trial 29 finished with value: 0.846307385229541 and parameters: {'rff_on': False, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  62%|██████▏   | 31/50 [1:15:41<45:57, 145.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:05:56,176] Trial 30 finished with value: 0.8602794411177644 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  64%|██████▍   | 32/50 [1:18:06<43:34, 145.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:08:21,700] Trial 31 finished with value: 0.8622754491017964 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  66%|██████▌   | 33/50 [1:20:30<40:59, 144.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:10:45,120] Trial 32 finished with value: 0.846307385229541 and parameters: {'rff_on': True, 'sigma': 2, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  68%|██████▊   | 34/50 [1:22:54<38:31, 144.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:13:09,088] Trial 33 finished with value: 0.8585905112851221 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  70%|███████   | 35/50 [1:25:10<35:30, 142.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:15:25,436] Trial 34 finished with value: 0.8507600184246891 and parameters: {'rff_on': False, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  72%|███████▏  | 36/50 [1:27:40<33:41, 144.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:17:55,229] Trial 35 finished with value: 0.8433901427913404 and parameters: {'rff_on': True, 'sigma': 10, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  74%|███████▍  | 37/50 [1:30:15<31:58, 147.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:20:30,281] Trial 36 finished with value: 0.8476892369107938 and parameters: {'rff_on': True, 'sigma': 5, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  76%|███████▌  | 38/50 [1:32:46<29:41, 148.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:23:00,767] Trial 37 finished with value: 0.7784431137724551 and parameters: {'rff_on': True, 'sigma': 0.001, 'num_layers': 1, 'embed_size': 160, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  78%|███████▊  | 39/50 [1:35:08<26:53, 146.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:25:23,244] Trial 38 finished with value: 0.8472286196837095 and parameters: {'rff_on': False, 'sigma': 1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  80%|████████  | 40/50 [1:37:42<24:48, 148.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:27:57,248] Trial 39 finished with value: 0.8638108398587441 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  82%|████████▏ | 41/50 [1:40:03<21:59, 146.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:30:18,514] Trial 40 finished with value: 0.8545984953170582 and parameters: {'rff_on': False, 'sigma': 2, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  84%|████████▍ | 42/50 [1:42:38<19:51, 148.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:32:52,780] Trial 41 finished with value: 0.8578228159066482 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  86%|████████▌ | 43/50 [1:45:09<17:27, 149.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:35:24,375] Trial 42 finished with value: 0.861200675571933 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  88%|████████▊ | 44/50 [1:47:41<15:01, 150.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:37:56,121] Trial 43 finished with value: 0.8590511285122063 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  90%|█████████ | 45/50 [1:50:06<12:24, 148.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:40:21,631] Trial 44 finished with value: 0.8622754491017964 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  92%|█████████▏| 46/50 [1:52:39<09:59, 149.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:42:53,937] Trial 45 finished with value: 0.8261937663135268 and parameters: {'rff_on': True, 'sigma': 1, 'num_layers': 1, 'embed_size': 100, 'heads': 10, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  94%|█████████▍| 47/50 [1:55:09<07:30, 150.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:45:24,439] Trial 46 finished with value: 0.8515277138031629 and parameters: {'rff_on': True, 'sigma': 10, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  96%|█████████▌| 48/50 [1:57:39<04:59, 149.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:47:53,909] Trial 47 finished with value: 0.8555197297712268 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 50, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 2, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886:  98%|█████████▊| 49/50 [2:00:06<02:29, 149.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:50:20,822] Trial 48 finished with value: 0.8569015814524796 and parameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 140, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}. Best is trial 27 with value: 0.8648856133886074.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.864886: 100%|██████████| 50/50 [2:02:28<00:00, 146.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-03 21:52:42,845] Trial 49 finished with value: 0.7640104406571473 and parameters: {'rff_on': False, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 80, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 3, 'learning_rate': 0.01}. Best is trial 27 with value: 0.8648856133886074.\n",
      "Best Hyperparameters: {'rff_on': True, 'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'learning_rate': 0.001}\n",
      "Best Validation Accuracy (at Early Stopping): 0.8648856133886074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 50\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')  # Maximize validation accuracy\n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation Accuracy (at Early Stopping):\", best_val_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
