{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU instead\n"
     ]
    }
   ],
   "source": [
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD AND PROCESS DATA\n",
    "**EXAMPLE WITH ADULT INCOME DATASET**\n",
    "1. Divide features into a set of numerical and a set of categorical.\n",
    "1. Retrieve class counts for each categorical feature (will be used later down the line)\n",
    "1. Standardize or perform quantile transformations to numerical/continuous features.\n",
    "1. Wrap with Dataset and Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.261189</td>\n",
       "      <td>-0.764261</td>\n",
       "      <td>-0.358478</td>\n",
       "      <td>0.584211</td>\n",
       "      <td>0.643412</td>\n",
       "      <td>0.431828</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>-0.627034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.786025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.906340</td>\n",
       "      <td>1.384381</td>\n",
       "      <td>0.355019</td>\n",
       "      <td>0.401362</td>\n",
       "      <td>0.681233</td>\n",
       "      <td>0.077837</td>\n",
       "      <td>0.741252</td>\n",
       "      <td>-0.993331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.764461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.425748</td>\n",
       "      <td>1.000528</td>\n",
       "      <td>1.861291</td>\n",
       "      <td>-0.415056</td>\n",
       "      <td>-0.361193</td>\n",
       "      <td>-0.698186</td>\n",
       "      <td>-0.372218</td>\n",
       "      <td>-0.104586</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.523613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.581963</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>0.196464</td>\n",
       "      <td>0.115662</td>\n",
       "      <td>0.258117</td>\n",
       "      <td>0.173441</td>\n",
       "      <td>0.362254</td>\n",
       "      <td>-0.108109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.936559</td>\n",
       "      <td>-0.736174</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>-0.620761</td>\n",
       "      <td>-0.599934</td>\n",
       "      <td>-0.179689</td>\n",
       "      <td>-0.476769</td>\n",
       "      <td>-0.674510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.630765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12254</th>\n",
       "      <td>0.806707</td>\n",
       "      <td>-0.904695</td>\n",
       "      <td>-0.358478</td>\n",
       "      <td>0.163202</td>\n",
       "      <td>-0.086995</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>-0.118681</td>\n",
       "      <td>0.814126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>1.021462</td>\n",
       "      <td>-0.885971</td>\n",
       "      <td>-1.864750</td>\n",
       "      <td>1.468283</td>\n",
       "      <td>1.177626</td>\n",
       "      <td>1.579069</td>\n",
       "      <td>1.313670</td>\n",
       "      <td>0.481794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.402187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>0.581963</td>\n",
       "      <td>-0.768942</td>\n",
       "      <td>1.068516</td>\n",
       "      <td>-0.475396</td>\n",
       "      <td>-0.396649</td>\n",
       "      <td>-0.407070</td>\n",
       "      <td>-0.356535</td>\n",
       "      <td>-0.410684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.103841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12257</th>\n",
       "      <td>-1.225976</td>\n",
       "      <td>0.897543</td>\n",
       "      <td>-1.309808</td>\n",
       "      <td>1.410229</td>\n",
       "      <td>1.246175</td>\n",
       "      <td>1.732379</td>\n",
       "      <td>1.460041</td>\n",
       "      <td>0.740152</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.205055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12258</th>\n",
       "      <td>-1.420754</td>\n",
       "      <td>0.972441</td>\n",
       "      <td>1.861291</td>\n",
       "      <td>0.442503</td>\n",
       "      <td>0.475584</td>\n",
       "      <td>0.728113</td>\n",
       "      <td>0.388392</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.382742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12259 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0       1.261189 -0.764261           -0.358478     0.584211        0.643412   \n",
       "1      -0.906340  1.384381            0.355019     0.401362        0.681233   \n",
       "2      -1.425748  1.000528            1.861291    -0.415056       -0.361193   \n",
       "3       0.581963 -0.689363            0.196464     0.115662        0.258117   \n",
       "4       0.936559 -0.736174            0.037909    -0.620761       -0.599934   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "12254   0.806707 -0.904695           -0.358478     0.163202       -0.086995   \n",
       "12255   1.021462 -0.885971           -1.864750     1.468283        1.177626   \n",
       "12256   0.581963 -0.768942            1.068516    -0.475396       -0.396649   \n",
       "12257  -1.225976  0.897543           -1.309808     1.410229        1.246175   \n",
       "12258  -1.420754  0.972441            1.861291     0.442503        0.475584   \n",
       "\n",
       "       population  households  median_income  ocean_proximity  \\\n",
       "0        0.431828    0.688976      -0.627034              1.0   \n",
       "1        0.077837    0.741252      -0.993331              1.0   \n",
       "2       -0.698186   -0.372218      -0.104586              3.0   \n",
       "3        0.173441    0.362254      -0.108109              0.0   \n",
       "4       -0.179689   -0.476769      -0.674510              1.0   \n",
       "...           ...         ...            ...              ...   \n",
       "12254    0.010657   -0.118681       0.814126              0.0   \n",
       "12255    1.579069    1.313670       0.481794              0.0   \n",
       "12256   -0.407070   -0.356535      -0.410684              0.0   \n",
       "12257    1.732379    1.460041       0.740152              3.0   \n",
       "12258    0.728113    0.388392       0.006980              3.0   \n",
       "\n",
       "       median_house_value  \n",
       "0               -0.786025  \n",
       "1               -0.764461  \n",
       "2                2.523613  \n",
       "3                1.104704  \n",
       "4               -0.630765  \n",
       "...                   ...  \n",
       "12254            0.569055  \n",
       "12255           -0.402187  \n",
       "12256            1.103841  \n",
       "12257            0.205055  \n",
       "12258            0.382742  \n",
       "\n",
       "[12259 rows x 10 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/train.csv')\n",
    "# df_test = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/test.csv')\n",
    "# df_val = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/validation.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "df_val = pd.read_csv('./data/validation.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "#Take a look at what the datasets look like initially to get an idea\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'ocean_proximity', 'median_house_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look at the feature names\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ocean_proximity']\n",
      "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n",
      "5\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "def categorize_columns(dataframe):\n",
    "    categorical_columns = []\n",
    "    continuous_columns = []\n",
    "    unique_classes_per_column = []  # To hold the number of unique classes for each categorical column\n",
    "\n",
    "    for column in dataframe.columns:\n",
    "        if dataframe[column].dtype == 'object' or len(dataframe[column].unique()) <= 10:\n",
    "            # If the column's data type is 'object' or it has 10 or fewer unique values, consider it categorical.\n",
    "            categorical_columns.append(column)\n",
    "            unique_classes_per_column.append(dataframe[column].nunique())  # Store the number of unique classes\n",
    "        else:\n",
    "            # Otherwise, consider it continuous.\n",
    "            continuous_columns.append(column)\n",
    "\n",
    "    # Calculate the total number of unique classes across all categorical columns.\n",
    "    total_unique_classes = sum(dataframe[col].nunique() for col in categorical_columns)\n",
    "\n",
    "    return categorical_columns, continuous_columns, total_unique_classes, unique_classes_per_column\n",
    "\n",
    "\n",
    "cat_cols, cont_cols, total_unique, unique_classes_per_column = categorize_columns(df_train)\n",
    "print(cat_cols)\n",
    "cont_cols.remove('median_house_value')\n",
    "print(cont_cols)\n",
    "print(total_unique)\n",
    "print(unique_classes_per_column)\n",
    "\n",
    "target_classes = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continous columns stored in: cont_cols\n",
    "\n",
    "categorical in: cat_cols\n",
    "\n",
    "list of unique classes for each categorical variable: unique_classes_per_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['households', 'housing_median_age', 'latitude', 'longitude', 'median_house_value', 'median_income', 'ocean_proximity', 'population', 'total_bedrooms', 'total_rooms']\n"
     ]
    }
   ],
   "source": [
    "# Divide the features up (DO THIS MANUALLY TO ENSURE YOU SEPERATE THEM HOW YOU NEED)\n",
    "\n",
    "#SET cat-columns TO NONE IF THERE ARE NO CATEGORICAL FEATURES\n",
    "\n",
    "cat_columns = cat_cols\n",
    "cont_columns = cont_cols\n",
    "target = ['median_house_value']\n",
    "\n",
    "#CHECKING TO MAKE SURE YOUR LIST IS CORRECT (NO NEED TO TOUCH)\n",
    "yourlist = cat_columns + cont_columns + target\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "\n",
    "print(yourlist)\n",
    "\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTaskDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cat_columns, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        self.cate = df[cat_columns].astype(np.int64).values\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = SingleTaskDataset(df_train, cat_columns, cont_columns, 'median_house_value')\n",
    "val_dataset = SingleTaskDataset(df_val, cat_columns, cont_columns, 'median_house_value')\n",
    "test_dataset = SingleTaskDataset(df_test, cat_columns, cont_columns, 'median_house_value')\n",
    "\n",
    "#This is a hyperparameter that is not tuned. Maybe mess with what makes sense here\n",
    "#Also try looking to see what other papers have done\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "torch.Size([256])\n",
      "torch.Size([227, 1])\n",
      "torch.Size([227, 8])\n",
      "torch.Size([227])\n"
     ]
    }
   ],
   "source": [
    "for cat, cont, targ in train_dataloader:\n",
    "    print(cat.shape)\n",
    "    print(cont.shape)\n",
    "    print(targ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL AND HELPERS\n",
    "\n",
    "1. All you should have to do is interact with Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each task loss is scaled by its own learnable parameter, then regularization is applied \n",
    "class UncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks):\n",
    "        super(UncertaintyLoss, self).__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        self.loss_fns = [nn.MSELoss() for x in range(num_tasks)] \n",
    "\n",
    "    def forward(self, predictions, labels_task1):\n",
    "\n",
    "        #task 1\n",
    "        target = labels_task1\n",
    "        prediction = predictions[0]\n",
    "        loss_fn = self.loss_fns[0]\n",
    "        task_loss = loss_fn(prediction, target)\n",
    "\n",
    "        \n",
    "        return task_loss\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_cont, cat_feat, num_target_labels, rff_on):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.rff_on = rff_on\n",
    "\n",
    "        if self.rff_on:\n",
    "            self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_cont)])\n",
    "            self.dropout = nn.Dropout(embedding_dropout)\n",
    "            self.mlp_in = embed_size\n",
    "        else:\n",
    "            self.mlp_in = input_size\n",
    "\n",
    "        self.cont_embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_cont)])\n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(num_classes, embed_size) for num_classes in cat_feat])\n",
    "\n",
    "        # Classifcation Embeddings for each target label\n",
    "        self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "    def forward(self, cat_x, cont_x):\n",
    "        x = cont_x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "        rff_vectors = []\n",
    "        if self.rff_on:\n",
    "            for i, r in enumerate(self.rffs):\n",
    "                input = x[:,i,:]\n",
    "                out = r(input)\n",
    "                rff_vectors.append(out)\n",
    "        \n",
    "            x = torch.stack(rff_vectors, dim=1)\n",
    "        \n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.cont_embeddings):\n",
    "            goin_in = x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        # print('after conts', len(embeddings))\n",
    "\n",
    "        #embedding cat features\n",
    "        cat_x = cat_x.unsqueeze(2)\n",
    "        for i, e in enumerate(self.cat_embeddings):\n",
    "\n",
    "            goin_in = cat_x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            print(goin_out.shape)\n",
    "            print(goin_out)\n",
    "            goin_out=goin_out.squeeze(1)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        # print('after cats', len(embeddings))\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embeddings:\n",
    "            input = torch.tensor([0], device=x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(x.size(0), 1)\n",
    "            temp = temp.unsqueeze(1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "\n",
    "        # print(len(embeddings))\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "        # print(context.shape)\n",
    "\n",
    "        return class_embeddings, context\n",
    "\n",
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(classificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rff_on = False,\n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 embedding_dropout = 0,\n",
    "                 n_cont = 0,\n",
    "                 cat_feat:list = [],\n",
    "                 num_layers=1,\n",
    "                 heads=1,\n",
    "                 forward_expansion=4, # Determines how wide the MLP is in the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0,\n",
    "                 classification_dropout = 0,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 4,\n",
    "                 targets_classes : list=  [3,8]\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(rff_on=rff_on, sigma=sigma, embed_size=embed_size, input_size=input_size, \n",
    "                                     embedding_dropout=embedding_dropout,n_cont=n_cont, cat_feat=cat_feat, num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, \n",
    "                               decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        self.classifying_heads = nn.ModuleList([classificationHead(embed_size=embed_size, dropout=classification_dropout, \n",
    "                                                                   mlp_scale_classification=mlp_scale_classification, \n",
    "                                                                   num_target_classes=x) for x in targets_classes])\n",
    "        \n",
    "    def forward(self, cat_x, cont_x):\n",
    "        class_embed, context = self.embeddings(cat_x, cont_x)\n",
    "\n",
    "        x = self.decoder(class_embed, context)\n",
    "        \n",
    "        probability_dist_raw = []\n",
    "        for i, e in enumerate(self.classifying_heads):\n",
    "            input = x[:, i,:]\n",
    "            output = e(input)\n",
    "            probability_dist_raw.append(output)\n",
    "        \n",
    "        return probability_dist_raw\n",
    "\n",
    "# Training and Testing Loops\n",
    "def train(dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_r2_score = 0\n",
    "    root_mean_squared_error_total = 0\n",
    "\n",
    "    for (x_cat, x_cont, labels_task1) in dataloader:\n",
    "        x_cat, x_cont, labels_task1 = x_cat.to(device_in_use), x_cont.to(device_in_use), labels_task1.to(device_in_use)\n",
    "\n",
    "        task_predictions = model(x_cat, x_cont)\n",
    "\n",
    "        # print('preds (train)', task_predictions[0].squeeze(1).shape)\n",
    "        # print('targ (train)', labels_task1.shape)\n",
    "\n",
    "        if task_predictions[0].squeeze(1).nelement() == 0:\n",
    "            print(\"The tensor is empty.\")\n",
    "        else:\n",
    "            print(\"The tensor is not empty.\")\n",
    "\n",
    "        loss = loss_function(task_predictions[0].squeeze(1), labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        print('loss', loss)\n",
    "        \n",
    "        # Calculate R^2 score for the regression task\n",
    "        r2 = r2_score_manual(labels_task1, task_predictions[0].squeeze(1))\n",
    "        total_r2_score += r2\n",
    "\n",
    "        # Calculate RMSE score for the regression task\n",
    "        rmse_value = rmse(labels_task1, task_predictions[0].squeeze(1))\n",
    "        root_mean_squared_error_total+=rmse_value\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_r2_score = total_r2_score / len(dataloader)\n",
    "    avg_rmse_score = root_mean_squared_error_total / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_r2_score, avg_rmse_score\n",
    "\n",
    "def test(dataloader, model, loss_function, device_in_use):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_loss = 0\n",
    "  total_r2_score = 0\n",
    "  root_mean_squared_error_total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (x_cat, x_cont, labels_task1) in dataloader:\n",
    "        x_cat, x_cont, labels_task1 = x_cat.to(device_in_use), x_cont.to(device_in_use), labels_task1.to(device_in_use)\n",
    "\n",
    "        task_predictions = model(x_cat, x_cont)\n",
    "\n",
    "        loss = loss_function(task_predictions[0].squeeze(1), labels_task1)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate R^2 score for the regression task\n",
    "        r2 = r2_score_manual(labels_task1, task_predictions[0].squeeze(1))\n",
    "        total_r2_score += r2\n",
    "        \n",
    "        # Calculate RMSE score for the regression task\n",
    "        rmse_value = rmse(labels_task1, task_predictions[0].squeeze(1))\n",
    "        root_mean_squared_error_total+=rmse_value\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_r2_score = total_r2_score / len(dataloader)\n",
    "    avg_rmse_score = root_mean_squared_error_total / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_r2_score, avg_rmse_score\n",
    "\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.4f}\"\n",
    "\n",
    "def r2_score_manual(y_true, y_pred):\n",
    "    # Calculate the mean of true labels\n",
    "    y_mean = torch.mean(y_true)\n",
    "\n",
    "    # Calculate the total sum of squares\n",
    "    total_ss = torch.sum((y_true - y_mean)**2)\n",
    "\n",
    "    # Calculate the residual sum of squares\n",
    "    residual_ss = torch.sum((y_true - y_pred)**2)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r2 = 1 - (residual_ss / total_ss)\n",
    "\n",
    "    return r2.item()  # Convert to a Python float\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    # Calculate the squared differences\n",
    "    squared_diff = (y_true - y_pred)**2\n",
    "\n",
    "    # Calculate the mean of the squared differences\n",
    "    mean_squared_diff = torch.mean(squared_diff)\n",
    "\n",
    "    # Calculate the square root to obtain RMSE\n",
    "    rmse = torch.sqrt(mean_squared_diff)\n",
    "\n",
    "    return rmse.item()  # Convert to a Python float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN EXPERIMENTS\n",
    "\n",
    "1. Using Optuna to optimize CAT-Transformers hyperparameters for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_metric = float('-inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Function to log results to a text file\n",
    "def log_to_file(filename, text):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(text + '\\n')\n",
    "\n",
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    sigma = trial.suggest_categorical('sigma', [.001, 0.1, 1, 2, 3, 5, 10])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    prenorm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "    embedding_dropout = trial.suggest_categorical('embedding_dropout', [0, .1, .2, .5])\n",
    "    decoder_dropout = trial.suggest_categorical('decoder_dropout', [0,.1,.2,.5])\n",
    "    classification_dropout = trial.suggest_categorical('class_drop', [0,.1,.2,.5])\n",
    "\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.0001, 0.001, 0.01])\n",
    "\n",
    "    num_epochs = 75\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = Classifier(\n",
    "        targets_classes=target_classes,\n",
    "        rff_on=True, #LEAVING ON\n",
    "        n_cont=len(cont_columns),\n",
    "        cat_feat=unique_classes_per_column,\n",
    "        sigma=sigma,\n",
    "        embed_size=embed_size,\n",
    "        num_layers=num_layers,\n",
    "        heads=heads,\n",
    "        forward_expansion=forward_expansion,\n",
    "        pre_norm_on=prenorm_on,\n",
    "        mlp_scale_classification=mlp_scale_classification,\n",
    "        embedding_dropout=embedding_dropout,\n",
    "        decoder_dropout=decoder_dropout,\n",
    "        classification_dropout=classification_dropout\n",
    "    ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = UncertaintyLoss(1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=3)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
    "        \n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy, _, _, _ = test(val_dataloader, model, loss_function, device_in_use)\n",
    "        \n",
    "        # Check if we should early stop based on validation accuracy\n",
    "        if early_stopping(val_accuracy):\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Log the final test accuracy for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation Accuracy = {val_accuracy:.4f}\"\n",
    "    log_to_file('all_trials_log.txt', final_log)\n",
    "\n",
    "    # Return the test accuracy as the objective to optimize\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-27 12:14:37,699] A new study created in memory with name: no-name-15aa44e3-739a-4337-a50d-55b468f16c0f\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([227])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/50 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([256, 9, 60])\n",
      "after conts 8\n",
      "after cats 9\n",
      "9\n",
      "torch.Size([227, 9, 60])\n",
      "[W 2023-10-27 12:14:39,234] Trial 0 failed with parameters: {'sigma': 1, 'num_layers': 1, 'embed_size': 60, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0.1, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0001} because of the following error: ValueError('too many values to unpack (expected 2)').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\prime\\AppData\\Local\\Temp\\ipykernel_21472\\905411970.py\", line 70, in objective\n",
      "    train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "[W 2023-10-27 12:14:39,244] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 16\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Maximize validation accuracy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Start the optimization process\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mnum_trials, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Get the best hyperparameters and the validation accuracy at the point of early stopping\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 16\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Training loop with a large number of epochs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train(train_dataloader, model, loss_function, optimizer, device_in_use)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39m# Validation loop\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     val_loss, val_accuracy, _, _, _ \u001b[39m=\u001b[39m test(val_dataloader, model, loss_function, device_in_use)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 50\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')  # Maximize validation accuracy\n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation Accuracy (at Early Stopping):\", best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Testing against the test dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Classifier(targets_classes\u001b[39m=\u001b[39mtarget_classes,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     rff_on\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     n_cont\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(cont_columns),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     cat_feat\u001b[39m=\u001b[39munique_classes_per_column, \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                    sigma\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                    embed_size\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39membed_size\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                    num_layers\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mnum_layers\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                    heads\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mheads\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                    forward_expansion\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mforward_expansion\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                    pre_norm_on\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mprenorm_on\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                    mlp_scale_classification\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mmlp_scale_classification\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                    embedding_dropout\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39membedding_dropout\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                    decoder_dropout\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mdecoder_dropout\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                    classification_dropout\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mclass_drop\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                    )\u001b[39m.\u001b[39mto(device_in_use) \u001b[39m# Instantiate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss_functions \u001b[39m=\u001b[39m UncertaintyLoss(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m best_params[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m# Maybe try messing around with optimizers. try other torch optimizers with different configurations.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "#Testing against the test dataset\n",
    "model = Classifier(targets_classes=target_classes,\n",
    "                    rff_on=True,\n",
    "                    n_cont=len(cont_columns),\n",
    "                    cat_feat=unique_classes_per_column, \n",
    "                   sigma=best_params['sigma'],\n",
    "                   embed_size=best_params['embed_size'],\n",
    "                   num_layers=best_params['num_layers'],\n",
    "                   heads=best_params['heads'],\n",
    "                   forward_expansion=best_params['forward_expansion'],\n",
    "                   pre_norm_on=best_params['prenorm_on'],\n",
    "                   mlp_scale_classification=best_params['mlp_scale_classification'],\n",
    "                   embedding_dropout=best_params['embedding_dropout'],\n",
    "                   decoder_dropout=best_params['decoder_dropout'],\n",
    "                   classification_dropout=best_params['class_drop']\n",
    "                   ).to(device_in_use) # Instantiate the model\n",
    "loss_functions = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = best_params['learning_rate']) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "epochs = 75 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "train_accuracies_2 = []\n",
    "train_recalls = [] \n",
    "train_f1_scores = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = []\n",
    "test_accuracies_2 = []\n",
    "test_recalls = []  \n",
    "test_f1_scores = [] \n",
    "all_attention_scores = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  train_loss, train_accuracy_1 = train(train_dataloader, model, loss_functions, optimizer, device_in_use=device_in_use)\n",
    "  test_loss, test_accuracy_1, all_predictions_1, all_targets_1, f1_1 = test(test_dataloader, model, loss_functions, device_in_use=device_in_use)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accuracies_1.append(train_accuracy_1)\n",
    "  # train_accuracies_2.append(train_accuracy_2)\n",
    "  # train_recalls.append(train_recall) \n",
    "  # train_f1_scores.append(train_f1)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies_1.append(test_accuracy_1)\n",
    "  # test_accuracies_2.append(test_accuracy_2)\n",
    "  # test_recalls.append(test_recall)\n",
    "  # test_f1_scores.append(test_f1)\n",
    "  # Formatting for easier reading\n",
    "  epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "  train_metrics = f\"Train: Loss {format_metric(train_loss)}, Accuracy {format_metric(train_accuracy_1)}\"\n",
    "  test_metrics = f\"Test: Loss {format_metric(test_loss)}, Accuracy {format_metric(test_accuracy_1)}, F1 {format_metric(f1_1)}\"\n",
    "  print(f\"{epoch_str:20} | {train_metrics:65} | {test_metrics}\")\n",
    "\n",
    "  if early_stopping(test_accuracy_1):\n",
    "    break\n",
    "\n",
    "# Save the model after pre-training\n",
    "torch.save(model.state_dict(), 'final_model_trained.pth')\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accuracies_1, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accuracies_1, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Display confusion matrix for the first task (Traffic Type) on test data\n",
    "conf_matrix_1 = confusion_matrix(all_targets_1, all_predictions_1)\n",
    "print(\"Confusion Matrix for income\")\n",
    "print(conf_matrix_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9463, -1.0359, -0.9344,  ...,  3.0497, -0.5409, -0.6614]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9098, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0532, -0.8731,  1.1310,  ..., -0.5388,  0.9876,  0.3013]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0532, -0.8731,  1.1310,  ..., -0.5388,  0.9876,  0.3013]],\n",
      "\n",
      "        [[ 0.0532, -0.8731,  1.1310,  ..., -0.5388,  0.9876,  0.3013]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(5.6701, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0525, -0.8724,  1.1303,  ..., -0.5395,  0.9869,  0.3020]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.2101, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[ 0.0516,  0.6137,  1.4632,  ..., -0.6277, -1.4840,  1.6858]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.2648, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        [[ 0.0510,  0.6143,  1.4638,  ..., -0.6272, -1.4834,  1.6863]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0510,  0.6143,  1.4638,  ..., -0.6272, -1.4834,  1.6863]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]],\n",
      "\n",
      "        [[-0.2523, -1.2602, -1.9360,  ..., -0.5817, -1.7092, -0.0489]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.5479, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2529, -1.2596, -1.9365,  ..., -0.5811, -1.7098, -0.0484]],\n",
      "\n",
      "        [[-0.9434, -1.0389, -0.9314,  ...,  3.0527, -0.5379, -0.6585]],\n",
      "\n",
      "        [[-0.2529, -1.2596, -1.9365,  ..., -0.5811, -1.7098, -0.0484]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2529, -1.2596, -1.9365,  ..., -0.5811, -1.7098, -0.0484]],\n",
      "\n",
      "        [[ 0.0505,  0.6148,  1.4643,  ..., -0.6267, -1.4829,  1.6868]],\n",
      "\n",
      "        [[-0.9434, -1.0389, -0.9314,  ...,  3.0527, -0.5379, -0.6585]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.3610, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9431, -1.0392, -0.9311,  ...,  3.0530, -0.5376, -0.6582]],\n",
      "\n",
      "        [[ 0.0501,  0.6152,  1.4647,  ..., -0.6262, -1.4825,  1.6872]],\n",
      "\n",
      "        [[ 0.0501,  0.6152,  1.4647,  ..., -0.6262, -1.4825,  1.6872]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0501,  0.6152,  1.4647,  ..., -0.6262, -1.4825,  1.6872]],\n",
      "\n",
      "        [[ 0.0504, -0.8707,  1.1281,  ..., -0.5419,  0.9848,  0.3047]],\n",
      "\n",
      "        [[ 0.0501,  0.6152,  1.4647,  ..., -0.6262, -1.4825,  1.6872]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0759, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0497,  0.6156,  1.4651,  ..., -0.6259, -1.4821,  1.6876]],\n",
      "\n",
      "        [[ 0.0497,  0.6156,  1.4651,  ..., -0.6259, -1.4821,  1.6876]],\n",
      "\n",
      "        [[-0.9431, -1.0397, -0.9307,  ...,  3.0534, -0.5374, -0.6581]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0497,  0.6156,  1.4651,  ..., -0.6259, -1.4821,  1.6876]],\n",
      "\n",
      "        [[ 0.0497,  0.6156,  1.4651,  ..., -0.6259, -1.4821,  1.6876]],\n",
      "\n",
      "        [[-0.9431, -1.0397, -0.9307,  ...,  3.0534, -0.5374, -0.6581]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1121, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0493,  0.6160,  1.4654,  ..., -0.6255, -1.4820,  1.6882]],\n",
      "\n",
      "        [[-0.2546, -1.2586, -1.9380,  ..., -0.5801, -1.7101, -0.0468]],\n",
      "\n",
      "        [[ 0.0493,  0.6160,  1.4654,  ..., -0.6255, -1.4820,  1.6882]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0493,  0.6160,  1.4654,  ..., -0.6255, -1.4820,  1.6882]],\n",
      "\n",
      "        [[-0.2546, -1.2586, -1.9380,  ..., -0.5801, -1.7101, -0.0468]],\n",
      "\n",
      "        [[-0.2546, -1.2586, -1.9380,  ..., -0.5801, -1.7101, -0.0468]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9284, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0491,  0.6166,  1.4656,  ..., -0.6251, -1.4817,  1.6883]],\n",
      "\n",
      "        [[-0.2550, -1.2584, -1.9384,  ..., -0.5798, -1.7102, -0.0464]],\n",
      "\n",
      "        [[-0.2550, -1.2584, -1.9384,  ..., -0.5798, -1.7102, -0.0464]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2550, -1.2584, -1.9384,  ..., -0.5798, -1.7102, -0.0464]],\n",
      "\n",
      "        [[ 0.0491,  0.6166,  1.4656,  ..., -0.6251, -1.4817,  1.6883]],\n",
      "\n",
      "        [[ 0.0491,  0.6166,  1.4656,  ..., -0.6251, -1.4817,  1.6883]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0822, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9433, -1.0411, -0.9296,  ...,  3.0543, -0.5369, -0.6580]],\n",
      "\n",
      "        [[-0.2554, -1.2582, -1.9388,  ..., -0.5796, -1.7103, -0.0461]],\n",
      "\n",
      "        [[ 0.0492,  0.6172,  1.4658,  ..., -0.6247, -1.4812,  1.6879]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2554, -1.2582, -1.9388,  ..., -0.5796, -1.7103, -0.0461]],\n",
      "\n",
      "        [[-0.2554, -1.2582, -1.9388,  ..., -0.5796, -1.7103, -0.0461]],\n",
      "\n",
      "        [[-0.2554, -1.2582, -1.9388,  ..., -0.5796, -1.7103, -0.0461]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0072, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0494,  0.6177,  1.4659,  ..., -0.6243, -1.4807,  1.6875]],\n",
      "\n",
      "        [[-0.2558, -1.2580, -1.9391,  ..., -0.5794, -1.7104, -0.0458]],\n",
      "\n",
      "        [[ 0.0494,  0.6177,  1.4659,  ..., -0.6243, -1.4807,  1.6875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2558, -1.2580, -1.9391,  ..., -0.5794, -1.7104, -0.0458]],\n",
      "\n",
      "        [[-0.2558, -1.2580, -1.9391,  ..., -0.5794, -1.7104, -0.0458]],\n",
      "\n",
      "        [[-0.2558, -1.2580, -1.9391,  ..., -0.5794, -1.7104, -0.0458]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1257, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2561, -1.2578, -1.9393,  ..., -0.5792, -1.7105, -0.0455]],\n",
      "\n",
      "        [[-0.2561, -1.2578, -1.9393,  ..., -0.5792, -1.7105, -0.0455]],\n",
      "\n",
      "        [[-0.2561, -1.2578, -1.9393,  ..., -0.5792, -1.7105, -0.0455]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0498,  0.6184,  1.4657,  ..., -0.6237, -1.4801,  1.6869]],\n",
      "\n",
      "        [[ 0.0498,  0.6184,  1.4657,  ..., -0.6237, -1.4801,  1.6869]],\n",
      "\n",
      "        [[-0.2561, -1.2578, -1.9393,  ..., -0.5792, -1.7105, -0.0455]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.2427, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9429, -1.0406, -0.9304,  ...,  3.0557, -0.5360, -0.6591]],\n",
      "\n",
      "        [[-0.2563, -1.2574, -1.9397,  ..., -0.5787, -1.7101, -0.0453]],\n",
      "\n",
      "        [[-0.9429, -1.0406, -0.9304,  ...,  3.0557, -0.5360, -0.6591]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0503,  0.6190,  1.4654,  ..., -0.6232, -1.4795,  1.6864]],\n",
      "\n",
      "        [[ 0.0503,  0.6190,  1.4654,  ..., -0.6232, -1.4795,  1.6864]],\n",
      "\n",
      "        [[-0.2563, -1.2574, -1.9397,  ..., -0.5787, -1.7101, -0.0453]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.2999, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0506,  0.6196,  1.4652,  ..., -0.6228, -1.4790,  1.6859]],\n",
      "\n",
      "        [[ 0.0485, -0.8692,  1.1261,  ..., -0.5442,  0.9828,  0.3071]],\n",
      "\n",
      "        [[ 0.0506,  0.6196,  1.4652,  ..., -0.6228, -1.4790,  1.6859]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2564, -1.2571, -1.9400,  ..., -0.5782, -1.7098, -0.0451]],\n",
      "\n",
      "        [[-0.9427, -1.0404, -0.9309,  ...,  3.0564, -0.5356, -0.6596]],\n",
      "\n",
      "        [[-0.9427, -1.0404, -0.9309,  ...,  3.0564, -0.5356, -0.6596]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0839, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2565, -1.2568, -1.9403,  ..., -0.5778, -1.7095, -0.0449]],\n",
      "\n",
      "        [[-0.2565, -1.2568, -1.9403,  ..., -0.5778, -1.7095, -0.0449]],\n",
      "\n",
      "        [[-0.9425, -1.0401, -0.9313,  ...,  3.0569, -0.5353, -0.6601]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0510,  0.6202,  1.4650,  ..., -0.6224, -1.4786,  1.6854]],\n",
      "\n",
      "        [[-0.2565, -1.2568, -1.9403,  ..., -0.5778, -1.7095, -0.0449]],\n",
      "\n",
      "        [[-0.2565, -1.2568, -1.9403,  ..., -0.5778, -1.7095, -0.0449]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0534, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2566, -1.2566, -1.9406,  ..., -0.5775, -1.7092, -0.0448]],\n",
      "\n",
      "        [[-0.2566, -1.2566, -1.9406,  ..., -0.5775, -1.7092, -0.0448]],\n",
      "\n",
      "        [[ 0.0483, -0.8689,  1.1258,  ..., -0.5445,  0.9825,  0.3075]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2566, -1.2566, -1.9406,  ..., -0.5775, -1.7092, -0.0448]],\n",
      "\n",
      "        [[ 0.0514,  0.6207,  1.4648,  ..., -0.6220, -1.4781,  1.6850]],\n",
      "\n",
      "        [[-0.2566, -1.2566, -1.9406,  ..., -0.5775, -1.7092, -0.0448]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0553, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2568, -1.2565, -1.9408,  ..., -0.5775, -1.7087, -0.0446]],\n",
      "\n",
      "        [[ 0.0482, -0.8688,  1.1256,  ..., -0.5446,  0.9824,  0.3076]],\n",
      "\n",
      "        [[ 0.0518,  0.6212,  1.4646,  ..., -0.6216, -1.4778,  1.6846]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9421, -1.0397, -0.9319,  ...,  3.0579, -0.5348, -0.6610]],\n",
      "\n",
      "        [[-0.9421, -1.0397, -0.9319,  ...,  3.0579, -0.5348, -0.6610]],\n",
      "\n",
      "        [[ 0.0518,  0.6212,  1.4646,  ..., -0.6216, -1.4778,  1.6846]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1521, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2571, -1.2565, -1.9409,  ..., -0.5778, -1.7080, -0.0443]],\n",
      "\n",
      "        [[-0.2571, -1.2565, -1.9409,  ..., -0.5778, -1.7080, -0.0443]],\n",
      "\n",
      "        [[-0.2571, -1.2565, -1.9409,  ..., -0.5778, -1.7080, -0.0443]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9420, -1.0395, -0.9322,  ...,  3.0583, -0.5345, -0.6614]],\n",
      "\n",
      "        [[-0.9420, -1.0395, -0.9322,  ...,  3.0583, -0.5345, -0.6614]],\n",
      "\n",
      "        [[ 0.0521,  0.6217,  1.4644,  ..., -0.6213, -1.4774,  1.6843]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1876, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0479, -0.8687,  1.1254,  ..., -0.5449,  0.9822,  0.3079]],\n",
      "\n",
      "        [[-0.2575, -1.2566, -1.9411,  ..., -0.5783, -1.7072, -0.0440]],\n",
      "\n",
      "        [[ 0.0479, -0.8687,  1.1254,  ..., -0.5449,  0.9822,  0.3079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0523,  0.6221,  1.4642,  ..., -0.6210, -1.4771,  1.6840]],\n",
      "\n",
      "        [[-0.9418, -1.0394, -0.9325,  ...,  3.0587, -0.5343, -0.6617]],\n",
      "\n",
      "        [[-0.9418, -1.0394, -0.9325,  ...,  3.0587, -0.5343, -0.6617]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0760, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0479, -0.8686,  1.1253,  ..., -0.5450,  0.9821,  0.3080]],\n",
      "\n",
      "        [[-0.2579, -1.2567, -1.9412,  ..., -0.5787, -1.7065, -0.0437]],\n",
      "\n",
      "        [[ 0.0479, -0.8686,  1.1253,  ..., -0.5450,  0.9821,  0.3080]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2579, -1.2567, -1.9412,  ..., -0.5787, -1.7065, -0.0437]],\n",
      "\n",
      "        [[ 0.0526,  0.6225,  1.4641,  ..., -0.6207, -1.4769,  1.6837]],\n",
      "\n",
      "        [[-0.2579, -1.2567, -1.9412,  ..., -0.5787, -1.7065, -0.0437]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0110, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0478, -0.8685,  1.1252,  ..., -0.5451,  0.9820,  0.3082]],\n",
      "\n",
      "        [[ 0.0528,  0.6228,  1.4639,  ..., -0.6204, -1.4766,  1.6834]],\n",
      "\n",
      "        [[-0.2583, -1.2569, -1.9413,  ..., -0.5792, -1.7058, -0.0435]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9416, -1.0391, -0.9329,  ...,  3.0594, -0.5339, -0.6623]],\n",
      "\n",
      "        [[-0.2583, -1.2569, -1.9413,  ..., -0.5792, -1.7058, -0.0435]],\n",
      "\n",
      "        [[ 0.0478, -0.8685,  1.1252,  ..., -0.5451,  0.9820,  0.3082]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9612, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0530,  0.6231,  1.4638,  ..., -0.6202, -1.4764,  1.6832]],\n",
      "\n",
      "        [[ 0.0530,  0.6231,  1.4638,  ..., -0.6202, -1.4764,  1.6832]],\n",
      "\n",
      "        [[ 0.0530,  0.6231,  1.4638,  ..., -0.6202, -1.4764,  1.6832]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0530,  0.6231,  1.4638,  ..., -0.6202, -1.4764,  1.6832]],\n",
      "\n",
      "        [[-0.2586, -1.2570, -1.9414,  ..., -0.5795, -1.7052, -0.0432]],\n",
      "\n",
      "        [[-0.9415, -1.0389, -0.9331,  ...,  3.0597, -0.5338, -0.6626]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9793, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0476, -0.8684,  1.1251,  ..., -0.5453,  0.9819,  0.3084]],\n",
      "\n",
      "        [[ 0.0533,  0.6234,  1.4637,  ..., -0.6199, -1.4761,  1.6829]],\n",
      "\n",
      "        [[-0.9414, -1.0388, -0.9333,  ...,  3.0599, -0.5336, -0.6628]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2589, -1.2571, -1.9415,  ..., -0.5799, -1.7047, -0.0430]],\n",
      "\n",
      "        [[ 0.0476, -0.8684,  1.1251,  ..., -0.5453,  0.9819,  0.3084]],\n",
      "\n",
      "        [[ 0.0533,  0.6234,  1.4637,  ..., -0.6199, -1.4761,  1.6829]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.2565, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0535,  0.6236,  1.4636,  ..., -0.6197, -1.4759,  1.6826]],\n",
      "\n",
      "        [[-0.2591, -1.2572, -1.9416,  ..., -0.5802, -1.7042, -0.0428]],\n",
      "\n",
      "        [[-0.2591, -1.2572, -1.9416,  ..., -0.5802, -1.7042, -0.0428]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0535,  0.6236,  1.4636,  ..., -0.6197, -1.4759,  1.6826]],\n",
      "\n",
      "        [[ 0.0535,  0.6236,  1.4636,  ..., -0.6197, -1.4759,  1.6826]],\n",
      "\n",
      "        [[-0.2591, -1.2572, -1.9416,  ..., -0.5802, -1.7042, -0.0428]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1313, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0475, -0.8683,  1.1250,  ..., -0.5453,  0.9818,  0.3084]],\n",
      "\n",
      "        [[-0.2594, -1.2573, -1.9417,  ..., -0.5805, -1.7038, -0.0426]],\n",
      "\n",
      "        [[-0.2594, -1.2573, -1.9417,  ..., -0.5805, -1.7038, -0.0426]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6236,  1.4635,  ..., -0.6193, -1.4758,  1.6821]],\n",
      "\n",
      "        [[ 0.0540,  0.6236,  1.4635,  ..., -0.6193, -1.4758,  1.6821]],\n",
      "\n",
      "        [[ 0.0475, -0.8683,  1.1250,  ..., -0.5453,  0.9818,  0.3084]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0197, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2596, -1.2573, -1.9418,  ..., -0.5807, -1.7034, -0.0425]],\n",
      "\n",
      "        [[-0.9412, -1.0385, -0.9338,  ...,  3.0606, -0.5333, -0.6634]],\n",
      "\n",
      "        [[ 0.0544,  0.6236,  1.4635,  ..., -0.6190, -1.4757,  1.6817]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2596, -1.2573, -1.9418,  ..., -0.5807, -1.7034, -0.0425]],\n",
      "\n",
      "        [[ 0.0544,  0.6236,  1.4635,  ..., -0.6190, -1.4757,  1.6817]],\n",
      "\n",
      "        [[-0.2596, -1.2573, -1.9418,  ..., -0.5807, -1.7034, -0.0425]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.8070, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0547,  0.6236,  1.4635,  ..., -0.6186, -1.4755,  1.6812]],\n",
      "\n",
      "        [[-0.2598, -1.2574, -1.9418,  ..., -0.5810, -1.7030, -0.0423]],\n",
      "\n",
      "        [[-0.2598, -1.2574, -1.9418,  ..., -0.5810, -1.7030, -0.0423]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2598, -1.2574, -1.9418,  ..., -0.5810, -1.7030, -0.0423]],\n",
      "\n",
      "        [[ 0.0547,  0.6236,  1.4635,  ..., -0.6186, -1.4755,  1.6812]],\n",
      "\n",
      "        [[-0.2598, -1.2574, -1.9418,  ..., -0.5810, -1.7030, -0.0423]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0309, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2600, -1.2575, -1.9419,  ..., -0.5812, -1.7027, -0.0422]],\n",
      "\n",
      "        [[-0.2600, -1.2575, -1.9419,  ..., -0.5812, -1.7027, -0.0422]],\n",
      "\n",
      "        [[-0.2600, -1.2575, -1.9419,  ..., -0.5812, -1.7027, -0.0422]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0545,  0.6240,  1.4634,  ..., -0.6188, -1.4754,  1.6814]],\n",
      "\n",
      "        [[ 0.0545,  0.6240,  1.4634,  ..., -0.6188, -1.4754,  1.6814]],\n",
      "\n",
      "        [[-0.2600, -1.2575, -1.9419,  ..., -0.5812, -1.7027, -0.0422]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.8928, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0474, -0.8682,  1.1248,  ..., -0.5454,  0.9816,  0.3083]],\n",
      "\n",
      "        [[-0.2601, -1.2575, -1.9420,  ..., -0.5814, -1.7024, -0.0421]],\n",
      "\n",
      "        [[-0.2601, -1.2575, -1.9420,  ..., -0.5814, -1.7024, -0.0421]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0543,  0.6243,  1.4633,  ..., -0.6189, -1.4753,  1.6815]],\n",
      "\n",
      "        [[ 0.0543,  0.6243,  1.4633,  ..., -0.6189, -1.4753,  1.6815]],\n",
      "\n",
      "        [[-0.2601, -1.2575, -1.9420,  ..., -0.5814, -1.7024, -0.0421]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9651, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0541,  0.6246,  1.4633,  ..., -0.6190, -1.4752,  1.6816]],\n",
      "\n",
      "        [[-0.2603, -1.2576, -1.9420,  ..., -0.5815, -1.7021, -0.0420]],\n",
      "\n",
      "        [[-0.2603, -1.2576, -1.9420,  ..., -0.5815, -1.7021, -0.0420]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0541,  0.6246,  1.4633,  ..., -0.6190, -1.4752,  1.6816]],\n",
      "\n",
      "        [[-0.2603, -1.2576, -1.9420,  ..., -0.5815, -1.7021, -0.0420]],\n",
      "\n",
      "        [[ 0.0541,  0.6246,  1.4633,  ..., -0.6190, -1.4752,  1.6816]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0475, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2604, -1.2576, -1.9421,  ..., -0.5817, -1.7019, -0.0419]],\n",
      "\n",
      "        [[ 0.0539,  0.6248,  1.4632,  ..., -0.6191, -1.4751,  1.6817]],\n",
      "\n",
      "        [[-0.2604, -1.2576, -1.9421,  ..., -0.5817, -1.7019, -0.0419]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0539,  0.6248,  1.4632,  ..., -0.6191, -1.4751,  1.6817]],\n",
      "\n",
      "        [[-0.9409, -1.0382, -0.9343,  ...,  3.0613, -0.5328, -0.6641]],\n",
      "\n",
      "        [[-0.2604, -1.2576, -1.9421,  ..., -0.5817, -1.7019, -0.0419]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0326, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2605, -1.2577, -1.9421,  ..., -0.5817, -1.7018, -0.0418]],\n",
      "\n",
      "        [[-0.2605, -1.2577, -1.9421,  ..., -0.5817, -1.7018, -0.0418]],\n",
      "\n",
      "        [[ 0.0538,  0.6251,  1.4631,  ..., -0.6192, -1.4750,  1.6818]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9409, -1.0382, -0.9344,  ...,  3.0614, -0.5328, -0.6642]],\n",
      "\n",
      "        [[-0.2605, -1.2577, -1.9421,  ..., -0.5817, -1.7018, -0.0418]],\n",
      "\n",
      "        [[ 0.0538,  0.6251,  1.4631,  ..., -0.6192, -1.4750,  1.6818]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9275, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0536,  0.6253,  1.4631,  ..., -0.6193, -1.4749,  1.6819]],\n",
      "\n",
      "        [[-0.2606, -1.2577, -1.9421,  ..., -0.5818, -1.7015, -0.0418]],\n",
      "\n",
      "        [[-0.9408, -1.0381, -0.9345,  ...,  3.0615, -0.5327, -0.6643]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2606, -1.2577, -1.9421,  ..., -0.5818, -1.7015, -0.0418]],\n",
      "\n",
      "        [[ 0.0473, -0.8683,  1.1247,  ..., -0.5455,  0.9815,  0.3081]],\n",
      "\n",
      "        [[-0.2606, -1.2577, -1.9421,  ..., -0.5818, -1.7015, -0.0418]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0949, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2607, -1.2578, -1.9422,  ..., -0.5820, -1.7013, -0.0417]],\n",
      "\n",
      "        [[-0.9408, -1.0381, -0.9345,  ...,  3.0616, -0.5327, -0.6643]],\n",
      "\n",
      "        [[ 0.0534,  0.6255,  1.4631,  ..., -0.6194, -1.4748,  1.6820]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2607, -1.2578, -1.9422,  ..., -0.5820, -1.7013, -0.0417]],\n",
      "\n",
      "        [[-0.2607, -1.2578, -1.9422,  ..., -0.5820, -1.7013, -0.0417]],\n",
      "\n",
      "        [[-0.2607, -1.2578, -1.9422,  ..., -0.5820, -1.7013, -0.0417]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1942, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0533,  0.6256,  1.4631,  ..., -0.6195, -1.4748,  1.6821]],\n",
      "\n",
      "        [[ 0.0533,  0.6256,  1.4631,  ..., -0.6195, -1.4748,  1.6821]],\n",
      "\n",
      "        [[ 0.0533,  0.6256,  1.4631,  ..., -0.6195, -1.4748,  1.6821]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2608, -1.2578, -1.9422,  ..., -0.5820, -1.7011, -0.0417]],\n",
      "\n",
      "        [[-0.2608, -1.2578, -1.9422,  ..., -0.5820, -1.7011, -0.0417]],\n",
      "\n",
      "        [[-0.9408, -1.0380, -0.9346,  ...,  3.0617, -0.5326, -0.6644]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1575, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0472, -0.8683,  1.1246,  ..., -0.5456,  0.9814,  0.3081]],\n",
      "\n",
      "        [[-0.9407, -1.0380, -0.9346,  ...,  3.0618, -0.5326, -0.6645]],\n",
      "\n",
      "        [[-0.9407, -1.0380, -0.9346,  ...,  3.0618, -0.5326, -0.6645]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0531,  0.6258,  1.4630,  ..., -0.6196, -1.4747,  1.6822]],\n",
      "\n",
      "        [[-0.9407, -1.0380, -0.9346,  ...,  3.0618, -0.5326, -0.6645]],\n",
      "\n",
      "        [[-0.2608, -1.2578, -1.9423,  ..., -0.5821, -1.7010, -0.0416]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9079, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2609, -1.2578, -1.9423,  ..., -0.5822, -1.7009, -0.0416]],\n",
      "\n",
      "        [[-0.2609, -1.2578, -1.9423,  ..., -0.5822, -1.7009, -0.0416]],\n",
      "\n",
      "        [[-0.2609, -1.2578, -1.9423,  ..., -0.5822, -1.7009, -0.0416]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2609, -1.2578, -1.9423,  ..., -0.5822, -1.7009, -0.0416]],\n",
      "\n",
      "        [[-0.9407, -1.0380, -0.9347,  ...,  3.0619, -0.5325, -0.6646]],\n",
      "\n",
      "        [[ 0.0472, -0.8683,  1.1246,  ..., -0.5456,  0.9814,  0.3081]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.8968, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0529,  0.6261,  1.4630,  ..., -0.6198, -1.4745,  1.6823]],\n",
      "\n",
      "        [[ 0.0529,  0.6261,  1.4630,  ..., -0.6198, -1.4745,  1.6823]],\n",
      "\n",
      "        [[ 0.0472, -0.8683,  1.1246,  ..., -0.5456,  0.9814,  0.3080]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0529,  0.6261,  1.4630,  ..., -0.6198, -1.4745,  1.6823]],\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9423,  ..., -0.5822, -1.7007, -0.0415]],\n",
      "\n",
      "        [[ 0.0529,  0.6261,  1.4630,  ..., -0.6198, -1.4745,  1.6823]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9234, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2579, -1.9423,  ..., -0.5823, -1.7006, -0.0415]],\n",
      "\n",
      "        [[ 0.0471, -0.8683,  1.1246,  ..., -0.5456,  0.9814,  0.3080]],\n",
      "\n",
      "        [[-0.2610, -1.2579, -1.9423,  ..., -0.5823, -1.7006, -0.0415]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2579, -1.9423,  ..., -0.5823, -1.7006, -0.0415]],\n",
      "\n",
      "        [[-0.2610, -1.2579, -1.9423,  ..., -0.5823, -1.7006, -0.0415]],\n",
      "\n",
      "        [[-0.2610, -1.2579, -1.9423,  ..., -0.5823, -1.7006, -0.0415]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9229, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0526,  0.6261,  1.4630,  ..., -0.6200, -1.4743,  1.6825]],\n",
      "\n",
      "        [[-0.9407, -1.0379, -0.9348,  ...,  3.0620, -0.5324, -0.6647]],\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0415]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0415]],\n",
      "\n",
      "        [[ 0.0526,  0.6261,  1.4630,  ..., -0.6200, -1.4743,  1.6825]],\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0415]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9838, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0526,  0.6261,  1.4632,  ..., -0.6200, -1.4743,  1.6824]],\n",
      "\n",
      "        [[ 0.0471, -0.8684,  1.1246,  ..., -0.5456,  0.9814,  0.3080]],\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0379, -0.9348,  ...,  3.0621, -0.5324, -0.6648]],\n",
      "\n",
      "        [[-0.2610, -1.2578, -1.9424,  ..., -0.5823, -1.7007, -0.0414]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1229, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9425,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0379, -0.9349,  ...,  3.0621, -0.5324, -0.6648]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9425,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9425,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0379, -0.9349,  ...,  3.0621, -0.5324, -0.6648]],\n",
      "\n",
      "        [[ 0.0528,  0.6259,  1.4633,  ..., -0.6197, -1.4743,  1.6822]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9223, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0471, -0.8684,  1.1246,  ..., -0.5457,  0.9814,  0.3080]],\n",
      "\n",
      "        [[ 0.0531,  0.6258,  1.4634,  ..., -0.6195, -1.4743,  1.6820]],\n",
      "\n",
      "        [[ 0.0471, -0.8684,  1.1246,  ..., -0.5457,  0.9814,  0.3080]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2609, -1.2577, -1.9426,  ..., -0.5822, -1.7008, -0.0414]],\n",
      "\n",
      "        [[-0.2609, -1.2577, -1.9426,  ..., -0.5822, -1.7008, -0.0414]],\n",
      "\n",
      "        [[ 0.0531,  0.6258,  1.4634,  ..., -0.6195, -1.4743,  1.6820]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1305, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2608, -1.2576, -1.9426,  ..., -0.5822, -1.7009, -0.0414]],\n",
      "\n",
      "        [[ 0.0533,  0.6256,  1.4635,  ..., -0.6193, -1.4742,  1.6818]],\n",
      "\n",
      "        [[ 0.0533,  0.6256,  1.4635,  ..., -0.6193, -1.4742,  1.6818]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2608, -1.2576, -1.9426,  ..., -0.5822, -1.7009, -0.0414]],\n",
      "\n",
      "        [[-0.2608, -1.2576, -1.9426,  ..., -0.5822, -1.7009, -0.0414]],\n",
      "\n",
      "        [[ 0.0533,  0.6256,  1.4635,  ..., -0.6193, -1.4742,  1.6818]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.1156, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2608, -1.2576, -1.9427,  ..., -0.5821, -1.7010, -0.0414]],\n",
      "\n",
      "        [[-0.2608, -1.2576, -1.9427,  ..., -0.5821, -1.7010, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9349,  ...,  3.0623, -0.5323, -0.6649]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9349,  ...,  3.0623, -0.5323, -0.6649]],\n",
      "\n",
      "        [[ 0.0471, -0.8684,  1.1245,  ..., -0.5457,  0.9814,  0.3079]],\n",
      "\n",
      "        [[ 0.0535,  0.6255,  1.4635,  ..., -0.6191, -1.4742,  1.6816]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9510, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2608, -1.2576, -1.9427,  ..., -0.5821, -1.7009, -0.0414]],\n",
      "\n",
      "        [[-0.2608, -1.2576, -1.9427,  ..., -0.5821, -1.7009, -0.0414]],\n",
      "\n",
      "        [[-0.2608, -1.2576, -1.9427,  ..., -0.5821, -1.7009, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6649]],\n",
      "\n",
      "        [[ 0.0471, -0.8684,  1.1245,  ..., -0.5457,  0.9814,  0.3079]],\n",
      "\n",
      "        [[ 0.0471, -0.8684,  1.1245,  ..., -0.5457,  0.9814,  0.3079]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(0.9161, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([227, 1, 100])\n",
      "tensor([[[-0.2609, -1.2576, -1.9427,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2609, -1.2576, -1.9427,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2609, -1.2576, -1.9427,  ..., -0.5823, -1.7007, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[ 0.0538,  0.6253,  1.4637,  ..., -0.6188, -1.4742,  1.6813]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0152, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([227])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]]])\n",
      "torch.Size([247, 1, 100])\n",
      "tensor([[[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([247])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/75]        | Train: Loss 1.1617, R2 -0.1730, RMSE 1.0584                       | Test: Loss 1.0037, R2 -0.0061, RMSE 1.0009\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0470, -0.8684,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.2610, -1.2577, -1.9426,  ..., -0.5824, -1.7004, -0.0414]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[ 0.0540,  0.6252,  1.4638,  ..., -0.6186, -1.4742,  1.6812]],\n",
      "\n",
      "        [[-0.9406, -1.0378, -0.9350,  ...,  3.0623, -0.5323, -0.6650]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0556, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[-0.2612, -1.2578, -1.9426,  ..., -0.5826, -1.7001, -0.0413]],\n",
      "\n",
      "        [[ 0.0541,  0.6251,  1.4638,  ..., -0.6185, -1.4742,  1.6811]],\n",
      "\n",
      "        [[-0.2612, -1.2578, -1.9426,  ..., -0.5826, -1.7001, -0.0413]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2612, -1.2578, -1.9426,  ..., -0.5826, -1.7001, -0.0413]],\n",
      "\n",
      "        [[ 0.0470, -0.8685,  1.1245,  ..., -0.5457,  0.9813,  0.3079]],\n",
      "\n",
      "        [[-0.2612, -1.2578, -1.9426,  ..., -0.5826, -1.7001, -0.0413]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "The tensor is not empty.\n",
      "loss tensor(1.0584, grad_fn=<MseLossBackward0>)\n",
      "torch.Size([256, 1, 100])\n",
      "tensor([[[ 0.0542,  0.6250,  1.4639,  ..., -0.6184, -1.4742,  1.6810]],\n",
      "\n",
      "        [[ 0.0542,  0.6250,  1.4639,  ..., -0.6184, -1.4742,  1.6810]],\n",
      "\n",
      "        [[-0.2613, -1.2579, -1.9426,  ..., -0.5827, -1.6999, -0.0413]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9405, -1.0378, -0.9350,  ...,  3.0624, -0.5322, -0.6650]],\n",
      "\n",
      "        [[-0.2613, -1.2579, -1.9426,  ..., -0.5827, -1.6999, -0.0413]],\n",
      "\n",
      "        [[ 0.0470, -0.8685,  1.1245,  ..., -0.5457,  0.9813,  0.3079]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m all_attention_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m   train_loss, r2_train, rmse_train \u001b[39m=\u001b[39m train(train_dataloader, model, loss_functions, optimizer, device_in_use\u001b[39m=\u001b[39;49mdevice_in_use)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m   test_loss, r2_test, rmse_test \u001b[39m=\u001b[39m test(test_dataloader, model, loss_functions, device_in_use\u001b[39m=\u001b[39mdevice_in_use)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m   train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=295'>296</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x_cat, x_cont, labels_task1) \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=296'>297</a>\u001b[0m     x_cat, x_cont, labels_task1 \u001b[39m=\u001b[39m x_cat\u001b[39m.\u001b[39mto(device_in_use), x_cont\u001b[39m.\u001b[39mto(device_in_use), labels_task1\u001b[39m.\u001b[39mto(device_in_use)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=298'>299</a>\u001b[0m     task_predictions \u001b[39m=\u001b[39m model(x_cat, x_cont)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=300'>301</a>\u001b[0m     \u001b[39m# print('preds (train)', task_predictions[0].squeeze(1).shape)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=301'>302</a>\u001b[0m     \u001b[39m# print('targ (train)', labels_task1.shape)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=303'>304</a>\u001b[0m     \u001b[39mif\u001b[39;00m task_predictions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnelement() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=274'>275</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, cat_x, cont_x):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=275'>276</a>\u001b[0m     class_embed, context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(cat_x, cont_x)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=277'>278</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(class_embed, context)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=279'>280</a>\u001b[0m     probability_dist_raw \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=280'>281</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, e \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifying_heads):\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, class_embed, context):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m         \u001b[39m# x is the classification embedding (CLS Token)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m         \u001b[39m# context are the feature embeddings that will be used as key and value\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m         x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_attention \u001b[39m=\u001b[39m layer(class_embed, context, context)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, value, key):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     out, avg_attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_block(value, key, x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out, avg_attention\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\prime\\OneDrive\\Documents\\CMU\\research\\CAT-Transformer\\experiments\\housing\\ca_cat_cont.ipynb Cell 18\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m attention, avg_attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(value, key, query)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(attention \u001b[39m+\u001b[39m query))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(forward \u001b[39m+\u001b[39m x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prime/OneDrive/Documents/CMU/research/CAT-Transformer/experiments/housing/ca_cat_cont.ipynb#X26sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out, avg_attention\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prime\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Testing against the test dataset\n",
    "\n",
    "# model = Classifier(targets_classes=target_classes,\n",
    "#                     rff_on=True,\n",
    "#                     n_cont=len(cont_columns),\n",
    "#                     cat_feat=unique_classes_per_column, \n",
    "#                    sigma=best_params['sigma'],\n",
    "#                    embed_size=best_params['embed_size'],\n",
    "#                    num_layers=best_params['num_layers'],\n",
    "#                    heads=best_params['heads'],\n",
    "#                    forward_expansion=best_params['forward_expansion'],\n",
    "#                    pre_norm_on=best_params['prenorm_on'],\n",
    "#                    mlp_scale_classification=best_params['mlp_scale_classification'],\n",
    "#                    embedding_dropout=best_params['embedding_dropout'],\n",
    "#                    decoder_dropout=best_params['decoder_dropout'],\n",
    "#                    classification_dropout=best_params['class_drop']\n",
    "#                    ).to(device_in_use) # Instantiate the model\n",
    "\n",
    "model = Classifier(targets_classes=[0],\n",
    "                   n_cont=len(cont_columns),\n",
    "                   cat_feat=unique_classes_per_column,\n",
    "                   rff_on=True,\n",
    "                   sigma=4,\n",
    "                   embed_size=100,\n",
    "                   num_layers=1,\n",
    "                   heads=1,\n",
    "                   forward_expansion=1,\n",
    "                   pre_norm_on=True,\n",
    "                   mlp_scale_classification=8,\n",
    "                   embedding_dropout=0,\n",
    "                   decoder_dropout=0,\n",
    "                   classification_dropout=0,\n",
    "                   ).to(device_in_use) # Instantiate the model\n",
    "loss_functions = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = .001) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "epochs = 75 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "train_accuracies_2 = []\n",
    "train_recalls = [] \n",
    "train_f1_scores = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = []\n",
    "test_accuracies_2 = []\n",
    "test_recalls = []  \n",
    "test_f1_scores = [] \n",
    "all_attention_scores = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  train_loss, r2_train, rmse_train = train(train_dataloader, model, loss_functions, optimizer, device_in_use=device_in_use)\n",
    "  test_loss, r2_test, rmse_test = test(test_dataloader, model, loss_functions, device_in_use=device_in_use)\n",
    "  train_losses.append(train_loss)\n",
    "\n",
    "  # train_accuracies_2.append(train_accuracy_2)\n",
    "  # train_recalls.append(train_recall) \n",
    "  # train_f1_scores.append(train_f1)\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  # test_accuracies_2.append(test_accuracy_2)\n",
    "  # test_recalls.append(test_recall)\n",
    "  # test_f1_scores.append(test_f1)\n",
    "  # Formatting for easier reading\n",
    "  epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "  train_metrics = f\"Train: Loss {format_metric(train_loss)}, R2 {format_metric(r2_train)}, RMSE {format_metric(rmse_train)}\"\n",
    "  test_metrics = f\"Test: Loss {format_metric(test_loss)}, R2 {format_metric(r2_test)}, RMSE {format_metric(rmse_test)}\"\n",
    "  print(f\"{epoch_str:20} | {train_metrics:65} | {test_metrics}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'final_model_trained.pth')\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
