{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cscadmin/miniconda3/envs/torch-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and being used\n"
     ]
    }
   ],
   "source": [
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>153475</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>122076</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7298</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>206362</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>137076</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>198660</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26043</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>200117</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26044</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>90896</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26045</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>370057</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26046</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>216284</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26047</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>54261</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       27          4  153475          9             13               4   \n",
       "1       38          4  122076         15             10               2   \n",
       "2       39          5  206362          8             11               2   \n",
       "3       32          4  137076         15             10               2   \n",
       "4       46          4  198660         11              9               0   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "26043   35          4  200117          9             13               2   \n",
       "26044   21          4   90896         11              9               4   \n",
       "26045   23          4  370057         11              9               0   \n",
       "26046   18          4  216284          1              7               4   \n",
       "26047   50          6   54261         11              9               2   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0              12             1     4    0             0             0   \n",
       "1              14             0     4    1          7298             0   \n",
       "2               3             0     4    1             0             0   \n",
       "3               4             0     4    1         15024             0   \n",
       "4               8             1     4    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "26043           4             0     1    1             0          1887   \n",
       "26044           7             3     4    0             0             0   \n",
       "26045           1             1     4    0             0             0   \n",
       "26046           1             3     4    0             0             0   \n",
       "26047           5             0     4    1             0             0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0                  40              39       0  \n",
       "1                  43              39       1  \n",
       "2                  40              39       0  \n",
       "3                  60              39       1  \n",
       "4                  40              39       0  \n",
       "...               ...             ...     ...  \n",
       "26043              50               0       1  \n",
       "26044              40              39       0  \n",
       "26045              40              39       0  \n",
       "26046              20              39       0  \n",
       "26047              84              39       0  \n",
       "\n",
       "[26048 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/train.csv')\n",
    "df_test = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/test.csv')\n",
    "df_val = pd.read_csv('/home/cscadmin/CyberResearch/CAT-Transformer/datasets/income/validation.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train['native-country'].value_counts()))\n",
    "print(len(df_test['native-country'].value_counts()))\n",
    "print(len(df_val['native-country'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "16\n",
      "7\n",
      "16\n",
      "6\n",
      "5\n",
      "2\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "cat_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "for x in cat_columns:\n",
    "    print(len(df_train[x].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should all features be embedded with an rff transformation? This is what we are doing currently\n",
    "#or should we only do that to the cont features and embed the cat features with a lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTaskDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cat_columns, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        self.cate = df[cat_columns].astype(np.int64).values\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "        # return self.x[index], self.task1_labels[index], self.task2_labels[index]\n",
    "\n",
    "cat_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "num_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "train_dataset = SingleTaskDataset(df_train, cat_columns, num_columns, 'income')\n",
    "val_dataset = SingleTaskDataset(df_val, cat_columns, num_columns, 'income')\n",
    "test_dataset = SingleTaskDataset(df_test, cat_columns, num_columns, 'income')\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat tensor([[ 0, 11,  6,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 27],\n",
      "        [ 4,  9,  5,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  2,  ...,  2,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[7.8000e+01, 3.6313e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
      "        [2.6000e+01, 2.7472e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 1.6320e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [2.4000e+01, 3.2752e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.3000e+01, 1.3767e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 1.3713e+05, 1.3000e+01, 0.0000e+00, 1.9770e+03, 4.5000e+01]])\n",
      "label tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 2, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 7, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  0,  4,  ...,  2,  1, 39]])\n",
      "num tensor([[3.6000e+01, 1.9234e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 1.4306e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [4.0000e+01, 2.2466e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.1000e+01, 1.8555e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.1000e+01],\n",
      "        [4.5000e+01, 2.7600e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.2000e+01, 6.6006e+04, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 2,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 7,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[3.2000e+01, 2.4427e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.3000e+01, 6.0001e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [2.1000e+01, 1.0303e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        ...,\n",
      "        [2.3000e+01, 1.0831e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.4000e+01, 1.2859e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.8000e+01, 4.4788e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  2,  6,  ...,  1,  1, 13],\n",
      "        [ 5,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 12,  4,  ...,  2,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  5,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  5,  ...,  4,  0, 39]])\n",
      "num tensor([[4.8000e+01, 2.3620e+05, 8.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.4000e+01, 3.5768e+05, 1.3000e+01, 1.5024e+04, 0.0000e+00, 6.5000e+01],\n",
      "        [9.0000e+01, 5.1744e+04, 1.4000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [5.5000e+01, 1.1899e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        [2.4000e+01, 2.1197e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.2000e+01, 2.2732e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.8000e+01]])\n",
      "label tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 0,  6,  2,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  6,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  7,  3,  ...,  4,  1, 39]])\n",
      "num tensor([[6.6000e+01, 1.0818e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 9.5855e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.4000e+01, 1.8125e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.8000e+01, 1.7624e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.0000e+01, 1.8478e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 4.4041e+04, 1.2000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 14,  3,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[2.3000e+01, 9.7054e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [3.3000e+01, 2.2036e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 8.4000e+01],\n",
      "        [3.1000e+01, 1.7578e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.3000e+01, 2.0861e+05, 1.5000e+01, 9.9999e+04, 0.0000e+00, 4.0000e+01],\n",
      "        [7.3000e+01, 1.9274e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [4.1000e+01, 3.0855e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 7, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 7, 14,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[3.5000e+01, 2.1474e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.8000e+01],\n",
      "        [3.9000e+01, 1.0704e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 1.9181e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.9000e+01, 2.1417e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.5000e+01, 4.2488e+04, 1.5000e+01, 2.6530e+03, 0.0000e+00, 8.0000e+00],\n",
      "        [2.1000e+01, 1.4964e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 9, 15,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  1,  4,  ...,  2,  0, 39],\n",
      "        [ 5,  7,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.6000e+01, 1.9175e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [1.8000e+01, 3.9557e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.8000e+01, 2.2017e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        ...,\n",
      "        [5.5000e+01, 4.9996e+04, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.3000e+01, 1.1796e+05, 1.2000e+01, 0.0000e+00, 1.8870e+03, 6.0000e+01],\n",
      "        [2.2000e+01, 5.3722e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 9, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  2,  0, 39],\n",
      "        [ 4,  5,  5,  ...,  4,  1,  8],\n",
      "        [ 4,  8,  2,  ...,  2,  1, 39]])\n",
      "num tensor([[3.5000e+01, 1.6661e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.9000e+01, 1.3839e+05, 9.0000e+00, 1.4090e+03, 0.0000e+00, 3.5000e+01],\n",
      "        [3.7000e+01, 9.9146e+04, 1.3000e+01, 0.0000e+00, 1.9770e+03, 5.0000e+01],\n",
      "        ...,\n",
      "        [3.8000e+01, 3.2327e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 2.2695e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 1.2060e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  2,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  2,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[3.2000e+01, 3.6466e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.9000e+01, 1.6982e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 1.0807e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.7000e+01, 2.4115e+05, 1.3000e+01, 1.5024e+04, 0.0000e+00, 5.0000e+01],\n",
      "        [2.7000e+01, 3.8599e+04, 8.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 2.7662e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  0, 39],\n",
      "        [ 6, 11,  4,  ...,  1,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 5,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.7000e+01, 1.7415e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.8000e+01, 2.2463e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [1.8000e+01, 8.7169e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.9000e+01, 1.2542e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [4.6000e+01, 1.2589e+05, 1.3000e+01, 0.0000e+00, 1.9770e+03, 6.0000e+01],\n",
      "        [2.0000e+01, 1.3161e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.8000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0.])\n",
      "cat tensor([[ 6,  8,  6,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 2, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  4,  ...,  0,  1, 39],\n",
      "        [ 2,  9,  4,  ...,  2,  1, 39]])\n",
      "num tensor([[4.4000e+01, 1.1590e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.5000e+01, 5.3553e+04, 1.0000e+01, 7.2980e+03, 0.0000e+00, 4.8000e+01],\n",
      "        [5.3000e+01, 1.5875e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.3000e+01, 1.9705e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.5000e+01, 3.1234e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.3000e+01, 2.1730e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 12,  4,  ...,  2,  1, 39],\n",
      "        [ 5,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[5.0000e+01, 3.0158e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.2000e+01, 1.4104e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [5.7000e+01, 6.2539e+04, 9.0000e+00, 0.0000e+00, 1.8760e+03, 3.8000e+01],\n",
      "        ...,\n",
      "        [2.6000e+01, 2.0166e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.9000e+01, 9.5835e+04, 1.1000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [3.1000e+01, 4.7151e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.6000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4,  3,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  0,  ...,  2,  0, 39],\n",
      "        [ 4,  5,  2,  ...,  4,  1, 32],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[3.7000e+01, 3.4378e+04, 2.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.2000e+01, 2.4748e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.5000e+01, 2.9206e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 3.3791e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [4.7000e+01, 1.0277e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 5.8350e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 0, 15,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  7,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[5.4000e+01, 2.5932e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.5000e+01, 2.3860e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        [2.8000e+01, 8.0165e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        ...,\n",
      "        [3.8000e+01, 7.7820e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.6000e+01, 2.7802e+04, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.6000e+01, 8.1259e+04, 1.2000e+01, 0.0000e+00, 0.0000e+00, 3.6000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  0,  6],\n",
      "        [ 4,  4,  4,  ...,  1,  1, 25],\n",
      "        ...,\n",
      "        [ 4,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 14,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[6.2000e+01, 9.8076e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.0000e+01, 1.9354e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 1.0796e+05, 3.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.6000e+01, 8.6220e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [9.0000e+01, 8.7372e+04, 1.5000e+01, 2.0051e+04, 0.0000e+00, 7.2000e+01],\n",
      "        [2.9000e+01, 2.2934e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1.])\n",
      "cat tensor([[ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  7,  0,  ...,  2,  1, 39],\n",
      "        ...,\n",
      "        [ 6,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  5,  ...,  2,  1,  0],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[2.3000e+01, 1.6171e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [2.3000e+01, 2.0166e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.3000e+01, 5.2008e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [2.4000e+01, 2.6740e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 5.9313e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.4000e+01, 7.3413e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat tensor([[ 6, 15,  3,  ...,  4,  0, 39],\n",
      "        [ 9,  1,  4,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  3,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 0, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  2,  0, 39],\n",
      "        [ 4,  7,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[4.7000e+01, 6.0087e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [1.8000e+01, 1.4204e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        [4.2000e+01, 2.2158e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.1000e+01, 1.9181e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 7.5000e+01],\n",
      "        [2.2000e+01, 1.8326e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [3.7000e+01, 3.8061e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 1.3000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 6, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  1,  2,  ...,  1,  0, 17],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 5, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[4.9000e+01, 1.3021e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.0000e+01, 1.6639e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [3.8000e+01, 1.8328e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.3000e+01],\n",
      "        ...,\n",
      "        [3.0000e+01, 1.0405e+05, 9.0000e+00, 0.0000e+00, 1.7410e+03, 4.2000e+01],\n",
      "        [3.6000e+01, 1.8042e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [2.3000e+01, 2.0586e+05, 9.0000e+00, 0.0000e+00, 2.1790e+03, 6.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  6,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  6,  5,  ...,  2,  0, 39],\n",
      "        [ 4,  4,  2,  ...,  4,  1, 26],\n",
      "        ...,\n",
      "        [ 7,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[4.1000e+01, 2.9427e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [5.2000e+01, 1.5375e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [2.7000e+01, 3.7250e+05, 3.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [3.1000e+01, 5.5785e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.7000e+01],\n",
      "        [1.8000e+01, 2.5837e+04, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        [3.0000e+01, 2.0943e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4, 14,  0,  ...,  4,  1, 39],\n",
      "        [ 4,  0,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 6,  1,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  6,  2,  ...,  4,  1, 26],\n",
      "        [ 4,  0,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[4.4000e+01, 2.1289e+05, 1.5000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.2000e+01, 2.1473e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.5000e+01, 8.4231e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [4.2000e+01, 2.7242e+04, 7.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [3.0000e+01, 4.8872e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.9000e+01, 3.8269e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  8,  6,  ...,  4,  0, 39],\n",
      "        [ 0, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 1,  7,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  3,  1, 39],\n",
      "        [ 0, 11,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[7.1000e+01, 1.8770e+05, 1.1000e+01, 1.1678e+04, 0.0000e+00, 3.8000e+01],\n",
      "        [6.3000e+01, 1.1015e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [5.5000e+01, 2.0996e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        ...,\n",
      "        [4.2000e+01, 3.1621e+04, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 2.3002e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.8000e+01, 1.7727e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 7, 12,  4,  ...,  4,  1, 39],\n",
      "        [ 9, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[2.9000e+01, 1.9136e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 2.1730e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.6000e+01],\n",
      "        [2.0000e+01, 2.0584e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        ...,\n",
      "        [4.7000e+01, 1.7599e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [3.4000e+01, 8.5374e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 3.1895e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  3,  0,  0],\n",
      "        [ 4, 11,  2,  ...,  2,  1, 39]])\n",
      "num tensor([[6.5000e+01, 1.0525e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.0000e+01, 2.4165e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [2.9000e+01, 2.5082e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [1.9000e+01, 3.1102e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.3000e+01, 8.8725e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.5000e+01, 2.6308e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01]])\n",
      "label tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  1, 13],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 11,  5,  ...,  4,  0, 39],\n",
      "        [ 4,  7,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[5.4000e+01, 1.4217e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.0000e+01, 1.0775e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 1.0306e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.0000e+01, 9.1939e+04, 9.0000e+00, 0.0000e+00, 1.7210e+03, 3.0000e+01],\n",
      "        [3.0000e+01, 1.6844e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [2.6000e+01, 1.9394e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 2, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 1,  9,  4,  ...,  2,  1, 39],\n",
      "        ...,\n",
      "        [ 1,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 1, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[3.9000e+01, 1.3124e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.2000e+01, 7.0985e+04, 9.0000e+00, 4.0640e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [4.7000e+01, 5.5377e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.2000e+01, 3.8518e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.0000e+01, 1.8401e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 5.5854e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  2,  0,  0],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 7, 15,  0,  ...,  2,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  1,  2,  ...,  0,  1, 39]])\n",
      "num tensor([[4.2000e+01, 1.5737e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [2.4000e+01, 3.7363e+05, 1.3000e+01, 0.0000e+00, 1.5040e+03, 4.0000e+01],\n",
      "        [4.3000e+01, 4.3843e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.6000e+01, 3.3186e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [2.3000e+01, 2.2495e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        [4.7000e+01, 1.5790e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 3.6000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 12,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 7, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[5.6000e+01, 3.5794e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.6000e+01, 1.5566e+05, 1.0000e+01, 1.5024e+04, 0.0000e+00, 4.5000e+01],\n",
      "        [4.9000e+01, 3.3777e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [2.0000e+01, 1.3877e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [4.2000e+01, 9.9185e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [4.8000e+01, 2.5987e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 6,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 7, 10,  2,  ...,  4,  1, 20]])\n",
      "num tensor([[3.0000e+01, 2.8944e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.0000e+01, 3.5644e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        [4.2000e+01, 1.1732e+05, 9.0000e+00, 0.0000e+00, 1.6720e+03, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.2000e+01, 1.9309e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.7000e+01],\n",
      "        [5.1000e+01, 2.2000e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.2000e+01, 1.4965e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  2,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  2,  1, 39],\n",
      "        ...,\n",
      "        [ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[3.3000e+01, 1.9193e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.0000e+01, 3.4706e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.7000e+01],\n",
      "        [2.2000e+01, 1.8177e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.0000e+01, 2.0983e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [5.1000e+01, 3.9229e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.3000e+01, 1.8432e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.4000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 11,  2,  ...,  2,  1, 42]])\n",
      "num tensor([[4.2000e+01, 1.2600e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.4000e+01, 1.4478e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [3.5000e+01, 3.7655e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [3.5000e+01, 1.0730e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 1.7266e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.1000e+01, 2.2460e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.4000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4,  5,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  2,  0,  ...,  2,  0, 39],\n",
      "        ...,\n",
      "        [ 2,  1,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  7,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[2.8000e+01, 5.2732e+04, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.8000e+01, 2.0590e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.3000e+01, 4.2777e+05, 8.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        ...,\n",
      "        [1.7000e+01, 3.0890e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        [4.8000e+01, 1.6282e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [5.3000e+01, 1.6637e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 2,  9,  4,  ...,  2,  0, 11],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 0, 11,  2,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 0,  1,  4,  ...,  2,  0, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  6,  ...,  4,  1, 39]])\n",
      "num tensor([[3.0000e+01, 3.6431e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 1.8410e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.0000e+01, 8.4375e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [2.8000e+01, 2.6822e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.2000e+01, 1.8087e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [8.3000e+01, 2.1387e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+00]])\n",
      "label tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0.])\n",
      "cat tensor([[ 2,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  1, 39],\n",
      "        [ 0, 11,  4,  ...,  4,  1, 32],\n",
      "        ...,\n",
      "        [ 0, 11,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 32],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[4.9000e+01, 1.0655e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.5000e+01, 3.6873e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.9000e+01, 3.7183e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.0000e+01, 3.5557e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.8000e+01, 1.0343e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.0000e+01, 2.2694e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01]])\n",
      "label tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 2, 15,  6,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[5.1000e+01, 7.4784e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.6000e+01, 2.0348e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 1.8877e+05, 1.3000e+01, 0.0000e+00, 2.8240e+03, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 3.0271e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [5.3000e+01, 1.7302e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [2.1000e+01, 3.9943e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  6,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 9, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[2.5000e+01, 2.9715e+05, 9.0000e+00, 2.4070e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [2.8000e+01, 2.3265e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.6000e+01, 1.6944e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        ...,\n",
      "        [5.8000e+01, 1.9183e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [3.1000e+01, 1.3982e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.5000e+01, 1.0647e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 1, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  7,  0,  ...,  1,  0, 36],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 6,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 7,  9,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[5.8000e+01, 3.1973e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        [3.6000e+01, 2.4760e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 8.8926e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [2.5000e+01, 1.5991e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 3.1131e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 6.5000e+01],\n",
      "        [5.1000e+01, 1.0306e+05, 1.3000e+01, 7.2980e+03, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  2,  0, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 7, 10,  2,  ...,  1,  1, 19],\n",
      "        [ 4,  5,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[5.8000e+01, 1.4771e+05, 9.0000e+00, 1.5024e+04, 0.0000e+00, 6.0000e+01],\n",
      "        [3.7000e+01, 2.9061e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 1.6852e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.7000e+01, 3.3597e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.5000e+01, 1.2078e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.3000e+01, 1.8006e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  0,  ...,  1,  0, 30],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  3,  2,  ...,  3,  1, 42],\n",
      "        [ 4, 11,  4,  ...,  2,  1, 39]])\n",
      "num tensor([[2.8000e+01, 3.1842e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.8000e+01, 1.1576e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [5.6000e+01, 1.7661e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.6000e+01, 2.4975e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.5000e+01, 8.8145e+04, 2.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.1000e+01, 3.5603e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.1000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  0,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.7000e+01, 1.6748e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [9.0000e+01, 4.0388e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [4.9000e+01, 1.9573e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.8000e+01, 1.0433e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.7000e+01, 3.3246e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 1.3044e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 4,  3,  2,  ...,  2,  1, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  1,  2,  ...,  4,  0, 26],\n",
      "        ...,\n",
      "        [ 0, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[7.4000e+01, 9.1488e+04, 2.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [1.7000e+01, 1.8158e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        [2.8000e+01, 1.7796e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [6.2000e+01, 1.8269e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [5.0000e+01, 3.0679e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.6000e+01, 1.2959e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0.])\n",
      "cat tensor([[ 7,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  5,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 9, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.0000e+01, 1.8490e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.7000e+01, 1.6461e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [3.7000e+01, 1.1858e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        ...,\n",
      "        [5.7000e+01, 3.0010e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 8.4000e+01],\n",
      "        [4.3000e+01, 4.7897e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [1.9000e+01, 5.7185e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 2,  1,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[4.3000e+01, 1.9590e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.7000e+01, 8.0282e+04, 1.3000e+01, 3.1370e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [4.6000e+01, 1.4995e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [2.1000e+01, 1.5364e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        [3.6000e+01, 1.8710e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.7000e+01, 1.4024e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  4,  ...,  4,  0, 32],\n",
      "        [ 0,  6,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  2,  1, 39],\n",
      "        [ 7, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[2.9000e+01, 1.1661e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.8000e+01, 1.4118e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
      "        [7.4000e+01, 1.5435e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        ...,\n",
      "        [4.9000e+01, 1.6226e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.3000e+01, 1.0974e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [2.1000e+01, 1.9805e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.8000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  1,  0,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.0000e+01, 1.1226e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 1.7807e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.3000e+01, 1.5437e+05, 1.0000e+01, 1.5024e+04, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [5.6000e+01, 1.8308e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.1000e+01, 3.7583e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.8000e+01, 1.6073e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 0, 11,  0,  ...,  2,  0, 39],\n",
      "        [ 6,  9,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  2,  ...,  0,  1, 39]])\n",
      "num tensor([[3.1000e+01, 2.8353e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [4.1000e+01, 1.6902e+05, 1.3000e+01, 7.6880e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [6.4000e+01, 2.6566e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.7000e+01, 1.9271e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.0000e+01, 1.1777e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        [3.8000e+01, 3.2587e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1.])\n",
      "cat tensor([[ 4,  5,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  5,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 9,  1,  0,  ...,  2,  0, 14],\n",
      "        [ 4,  0,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[4.6000e+01, 1.0254e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 5.2000e+01],\n",
      "        [4.3000e+01, 3.4793e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [3.4000e+01, 4.5522e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.8000e+01, 1.5551e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        [1.7000e+01, 9.4774e+04, 6.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        [2.2000e+01, 2.2552e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 10,  5,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[6.2000e+01, 1.7703e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.1000e+01, 1.5416e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [5.2000e+01, 4.1723e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        ...,\n",
      "        [3.7000e+01, 1.8925e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.4000e+01, 2.0440e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [5.7000e+01, 1.4133e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  5,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  0,  ...,  2,  1, 14],\n",
      "        ...,\n",
      "        [ 7,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 6,  7,  0,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  2,  1, 39]])\n",
      "num tensor([[5.3000e+01, 2.2946e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [4.0000e+01, 3.0999e+05, 9.0000e+00, 8.6140e+03, 0.0000e+00, 6.0000e+01],\n",
      "        [5.1000e+01, 2.2927e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 1.9058e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.2000e+01, 1.0673e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.9000e+01, 2.3699e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  0,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  1,  0,  ...,  4,  0, 39],\n",
      "        [ 2,  9,  4,  ...,  3,  0,  0]])\n",
      "num tensor([[2.1000e+01, 1.3123e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.7000e+01],\n",
      "        [3.9000e+01, 1.6674e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [3.6000e+01, 1.2774e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 9.9000e+01],\n",
      "        ...,\n",
      "        [3.7000e+01, 1.1999e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.7000e+01, 2.2939e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.7000e+01, 2.8266e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 2,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 2, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  4,  2,  ...,  4,  1, 26],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[2.5000e+01, 1.9782e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 1.0527e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.9000e+01, 2.0675e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        ...,\n",
      "        [2.9000e+01, 1.2953e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.5000e+01, 2.9012e+05, 3.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.4000e+01, 9.6678e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 5,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0,  4],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[3.4000e+01, 1.7077e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.8000e+01, 2.5429e+05, 1.3000e+01, 7.2980e+03, 0.0000e+00, 5.0000e+01],\n",
      "        [4.2000e+01, 1.6288e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [2.6000e+01, 2.1430e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.3000e+01, 1.5713e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [3.4000e+01, 4.0571e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 0, 11,  4,  ...,  4,  0, 26],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  6,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 7, 15,  5,  ...,  4,  0, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  2,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[2.8000e+01, 2.2200e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.3000e+01, 2.2216e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 3.7476e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        ...,\n",
      "        [3.4000e+01, 2.5970e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.7000e+01, 2.9725e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 9.0000e+00],\n",
      "        [1.9000e+01, 3.3395e+05, 8.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 0, 15,  4,  ...,  2,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[2.0000e+01, 1.8168e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.1000e+01, 2.1577e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [5.0000e+01, 1.1329e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        ...,\n",
      "        [6.8000e+01, 1.7018e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.5000e+01, 1.9450e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.2000e+01, 2.4773e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  1, 39],\n",
      "        [ 0, 15,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 5, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 14,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.5000e+01, 1.6091e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.0000e+01, 2.9309e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [2.1000e+01, 2.5319e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.8000e+01],\n",
      "        ...,\n",
      "        [3.6000e+01, 4.8063e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 8.0000e+01],\n",
      "        [5.9000e+01, 1.7727e+05, 1.5000e+01, 9.9999e+04, 0.0000e+00, 8.4000e+01],\n",
      "        [2.4000e+01, 1.6506e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 6,  6,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 2, 10,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[5.8000e+01, 1.8381e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.4000e+01],\n",
      "        [2.7000e+01, 1.7869e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 3.8335e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        ...,\n",
      "        [3.6000e+01, 1.3603e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [1.9000e+01, 1.8157e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.1000e+01, 1.8008e+05, 1.6000e+01, 4.0640e+03, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 5,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 12,  6,  ...,  1,  0, 39]])\n",
      "num tensor([[8.3000e+01, 1.5318e+05, 1.3000e+01, 0.0000e+00, 2.3920e+03, 5.5000e+01],\n",
      "        [4.3000e+01, 1.9388e+05, 1.0000e+01, 7.6880e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 1.1315e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        ...,\n",
      "        [4.0000e+01, 2.2117e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 6.5000e+01],\n",
      "        [4.1000e+01, 3.3874e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.0000e+01, 1.4358e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0.])\n",
      "cat tensor([[ 4, 14,  2,  ...,  4,  1, 39],\n",
      "        [ 5,  9,  0,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 6, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 4,  1,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[4.2000e+01, 2.5252e+05, 1.5000e+01, 1.5024e+04, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 2.3778e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.0000e+01, 1.5478e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [6.9000e+01, 6.9306e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        [2.4000e+01, 2.1454e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.1000e+01, 1.8109e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  2,  1, 39]])\n",
      "num tensor([[4.7000e+01, 2.5687e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.8000e+01],\n",
      "        [3.4000e+01, 2.9254e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        [5.3000e+01, 3.1245e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [4.2000e+01, 2.8964e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.6000e+01],\n",
      "        [1.8000e+01, 3.7924e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [1.8000e+01, 1.8303e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01]])\n",
      "label tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  5,  5,  ...,  4,  0, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 14,  0,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0,  2],\n",
      "        [ 1, 15,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[4.7000e+01, 1.0694e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [3.1000e+01, 1.5300e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.5000e+01, 5.5894e+04, 1.5000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.7000e+01, 2.8520e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.1000e+01, 1.6865e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.4000e+01, 3.4170e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1.])\n",
      "cat tensor([[ 2,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  8,  2,  ...,  1,  1, 19],\n",
      "        [ 0,  5,  0,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 9, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 6,  5,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  5,  6,  ...,  2,  1, 39]])\n",
      "num tensor([[3.3000e+01, 1.6194e+05, 1.3000e+01, 1.0550e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 1.4300e+05, 1.1000e+01, 7.2980e+03, 0.0000e+00, 6.0000e+01],\n",
      "        [7.2000e+01, 1.8801e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        ...,\n",
      "        [5.8000e+01, 1.6959e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.2000e+01, 1.6868e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00],\n",
      "        [7.9000e+01, 1.2155e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00]])\n",
      "label tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 9,  0,  6,  ...,  2,  0, 39],\n",
      "        [ 6, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[4.2000e+01, 1.5349e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 1.5582e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.2000e+01, 4.4413e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.1000e+01, 9.8823e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [5.8000e+01, 2.3059e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 1.6319e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 1, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 0,  9,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 1,  0,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  6,  2,  ...,  3,  0, 32],\n",
      "        [ 7, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[3.9000e+01, 6.0070e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.4000e+01],\n",
      "        [2.0000e+01, 3.4022e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.8000e+01, 2.0326e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 8.0000e+00],\n",
      "        ...,\n",
      "        [3.8000e+01, 1.7868e+05, 6.0000e+00, 0.0000e+00, 1.3800e+03, 5.0000e+01],\n",
      "        [3.4000e+01, 7.1865e+04, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.7000e+01, 6.8830e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 14,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  2,  ...,  4,  1, 42],\n",
      "        [ 4,  9,  4,  ...,  1,  1, 40],\n",
      "        [ 4, 12,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[6.3000e+01, 2.0160e+05, 1.0000e+01, 0.0000e+00, 1.9020e+03, 6.0000e+01],\n",
      "        [3.3000e+01, 1.3350e+05, 9.0000e+00, 0.0000e+00, 1.9770e+03, 4.5000e+01],\n",
      "        [6.2000e+01, 1.6235e+05, 1.5000e+01, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        ...,\n",
      "        [3.1000e+01, 1.4182e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 1.8645e+05, 1.3000e+01, 4.6500e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [3.3000e+01, 3.4762e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 10,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 10,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  6,  ...,  4,  0, 39]])\n",
      "num tensor([[3.5000e+01, 1.5441e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.9000e+01, 1.9941e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.0000e+01, 2.3677e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.1000e+01, 1.5031e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 9.0000e+01],\n",
      "        [5.1000e+01, 1.7793e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [3.1000e+01, 7.3796e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 7, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 7,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  2,  0, 39],\n",
      "        ...,\n",
      "        [ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  9,  2,  ...,  1,  1, 30]])\n",
      "num tensor([[3.2000e+01, 9.0409e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [4.3000e+01, 2.4151e+05, 1.3000e+01, 1.5060e+03, 0.0000e+00, 3.6000e+01],\n",
      "        [5.2000e+01, 2.3020e+05, 1.0000e+01, 0.0000e+00, 2.0010e+03, 3.2000e+01],\n",
      "        ...,\n",
      "        [6.9000e+01, 5.0536e+05, 1.0000e+01, 6.5140e+03, 0.0000e+00, 4.5000e+01],\n",
      "        [4.7000e+01, 1.1994e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.3000e+01, 3.5586e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0.])\n",
      "cat tensor([[ 6, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  6,  ...,  4,  0, 39],\n",
      "        [ 2,  8,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[5.1000e+01, 4.6401e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.5000e+01, 2.8998e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [2.6000e+01, 2.2952e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.6000e+01],\n",
      "        ...,\n",
      "        [4.6000e+01, 1.6047e+05, 9.0000e+00, 0.0000e+00, 1.5900e+03, 4.3000e+01],\n",
      "        [5.3000e+01, 2.8608e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.7000e+01, 1.6297e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 5.6000e+01]])\n",
      "label tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 1, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  6,  ...,  4,  0, 22],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  5,  ...,  4,  1, 39],\n",
      "        [ 4,  1,  5,  ...,  2,  1, 39],\n",
      "        [ 4,  0,  4,  ...,  2,  1, 39]])\n",
      "num tensor([[3.1000e+01, 1.3006e+05, 1.4000e+01, 7.6880e+03, 0.0000e+00, 6.0000e+01],\n",
      "        [5.5000e+01, 1.9533e+05, 9.0000e+00, 2.2020e+03, 0.0000e+00, 3.5000e+01],\n",
      "        [3.9000e+01, 8.7076e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [3.3000e+01, 4.5472e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.8000e+01, 2.4018e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 2.2000e+01],\n",
      "        [4.6000e+01, 1.6151e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  1, 39],\n",
      "        [ 2, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[3.4000e+01, 1.0429e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 8.4817e+04, 1.1000e+01, 3.8870e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [2.6000e+01, 3.6529e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 3.7646e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.0000e+01, 2.6102e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [2.4000e+01, 2.5202e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 7.2000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  6,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  5,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  6,  ...,  4,  0, 39],\n",
      "        [ 4,  5,  3,  ...,  4,  0, 39]])\n",
      "num tensor([[3.1000e+01, 1.2483e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.0000e+01, 3.7932e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.6000e+01, 1.2926e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.3000e+01, 1.8984e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.1000e+01, 2.8489e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.1000e+01],\n",
      "        [6.6000e+01, 1.9741e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  0,  2],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  9,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 15,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[5.5000e+01, 1.9437e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.2000e+01, 2.2033e+05, 9.0000e+00, 7.2980e+03, 0.0000e+00, 4.6000e+01],\n",
      "        [2.3000e+01, 2.5830e+05, 1.3000e+01, 0.0000e+00, 2.2310e+03, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.6000e+01, 3.4186e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 4.5637e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.0000e+01, 2.5050e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01]])\n",
      "label tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1.])\n",
      "cat tensor([[ 9, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  0,  5,  ...,  2,  1, 39],\n",
      "        [ 4, 14,  6,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  6,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[2.1000e+01, 2.2896e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [3.0000e+01, 1.3984e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.4000e+01, 1.0108e+05, 1.5000e+01, 0.0000e+00, 2.4440e+03, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.4000e+01, 2.5986e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [5.0000e+01, 1.9868e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        [3.0000e+01, 1.4943e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01]])\n",
      "label tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0.])\n",
      "cat tensor([[ 4,  7,  2,  ...,  4,  0, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 0, 15,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  0,  5,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[2.4000e+01, 9.7212e+04, 1.2000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.6000e+01, 2.1685e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.8000e+01, 2.6492e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.7000e+01, 4.4671e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.8000e+01],\n",
      "        [3.2000e+01, 1.8483e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 3.2144e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 10,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 6,  8,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 2, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  2,  4,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1,  2]])\n",
      "num tensor([[7.2000e+01, 2.2578e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [3.6000e+01, 2.1948e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.0000e+01, 1.9436e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 7.2000e+01],\n",
      "        ...,\n",
      "        [3.8000e+01, 1.1508e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 7.0000e+01],\n",
      "        [2.5000e+01, 3.0246e+05, 8.0000e+00, 0.0000e+00, 1.7410e+03, 4.0000e+01],\n",
      "        [5.6000e+01, 3.3560e+05, 9.0000e+00, 0.0000e+00, 1.8870e+03, 5.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1.])\n",
      "cat tensor([[ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 0, 15,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  0, 39],\n",
      "        [ 0,  5,  4,  ...,  4,  1, 26]])\n",
      "num tensor([[2.8000e+01, 2.6361e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 1.9129e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [1.9000e+01, 2.2052e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        ...,\n",
      "        [2.2000e+01, 3.4054e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.8000e+01, 1.0365e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.1000e+01],\n",
      "        [1.9000e+01, 3.6587e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 4,  0,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 2, 11,  2,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[6.2000e+01, 4.1718e+04, 6.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [2.2000e+01, 1.4635e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [6.3000e+01, 8.3791e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [3.0000e+01, 3.8115e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.3000e+01, 4.7261e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [6.5000e+01, 2.0076e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 12,  2,  ...,  1,  0,  3],\n",
      "        [ 4,  1,  5,  ...,  4,  1, 26],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  5,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 12,  0,  ...,  4,  1, 39]])\n",
      "num tensor([[3.4000e+01, 8.8215e+04, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.4000e+01, 3.7476e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.2000e+01, 8.3315e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [6.6000e+01, 1.4058e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.5000e+01, 2.1212e+05, 1.3000e+01, 1.5024e+04, 0.0000e+00, 4.0000e+01],\n",
      "        [4.5000e+01, 5.4392e+05, 1.4000e+01, 1.4344e+04, 0.0000e+00, 4.8000e+01]])\n",
      "label tensor([1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1.])\n",
      "cat tensor([[ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 0,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 1, 12,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 2, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 12,  4,  ...,  4,  0, 39],\n",
      "        [ 7, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[2.1000e+01, 2.0464e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.7000e+01, 2.4127e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 8.0000e+00],\n",
      "        [4.0000e+01, 5.6795e+04, 1.4000e+01, 1.4084e+04, 0.0000e+00, 5.5000e+01],\n",
      "        ...,\n",
      "        [4.9000e+01, 1.9396e+05, 1.4000e+01, 0.0000e+00, 1.9020e+03, 4.0000e+01],\n",
      "        [4.4000e+01, 1.9646e+05, 1.4000e+01, 0.0000e+00, 1.6690e+03, 4.0000e+01],\n",
      "        [4.1000e+01, 2.9324e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 2, 15,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[4.0000e+01, 1.3898e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.6000e+01],\n",
      "        [2.6000e+01, 4.8099e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 9.8587e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 4.9674e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.1000e+01, 9.2898e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.5000e+01, 3.8948e+04, 1.1000e+01, 3.1030e+03, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  0,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 15,  2,  ...,  1,  0, 35]])\n",
      "num tensor([[4.3000e+01, 3.3664e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [3.3000e+01, 2.4333e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.5000e+01, 1.5703e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [6.3000e+01, 7.8383e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [5.9000e+01, 1.9100e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 3.6000e+01],\n",
      "        [3.1000e+01, 8.3748e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 7.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  0,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  0,  0, 39],\n",
      "        [ 4,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  0,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.4000e+01, 1.5249e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [3.1000e+01, 2.2649e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [2.9000e+01, 1.7416e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.9000e+01, 6.7306e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.1000e+01, 2.4262e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.0000e+01, 1.3214e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 5, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 1, 15,  3,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[2.6000e+01, 5.3209e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 2.5883e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.7000e+01, 7.7660e+04, 1.0000e+01, 1.5024e+04, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [2.3000e+01, 1.9281e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 1.9707e+05, 1.0000e+01, 4.6500e+03, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 1.4592e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 6, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  9,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 0,  1,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[5.6000e+01, 9.9479e+04, 1.0000e+01, 5.0130e+03, 0.0000e+00, 4.6000e+01],\n",
      "        [5.0000e+01, 1.7790e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [4.2000e+01, 9.6524e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [6.6000e+01, 1.1778e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.1000e+01, 5.0178e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.8000e+01, 1.7431e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.8000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  2,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 6,  0,  0,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.2000e+01, 6.8330e+04, 9.0000e+00, 0.0000e+00, 1.4850e+03, 4.0000e+01],\n",
      "        [1.9000e+01, 2.7892e+05, 8.0000e+00, 0.0000e+00, 0.0000e+00, 5.2000e+01],\n",
      "        [2.4000e+01, 2.5160e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.2000e+01, 2.4188e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.2000e+01, 2.3632e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.2000e+01],\n",
      "        [3.5000e+01, 2.0044e+05, 9.0000e+00, 0.0000e+00, 1.9740e+03, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 2, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  6,  ...,  4,  0, 39],\n",
      "        [ 1,  8,  0,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  0,  0, 39],\n",
      "        [ 4,  8,  5,  ...,  4,  0, 39]])\n",
      "num tensor([[2.9000e+01, 3.8374e+05, 1.0000e+01, 0.0000e+00, 1.4850e+03, 4.0000e+01],\n",
      "        [3.7000e+01, 4.0200e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [4.2000e+01, 1.2546e+05, 1.1000e+01, 0.0000e+00, 3.2300e+02, 4.0000e+01],\n",
      "        ...,\n",
      "        [1.9000e+01, 3.8649e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        [3.2000e+01, 1.6353e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.0000e+01, 3.3671e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0.])\n",
      "cat tensor([[ 1, 11,  4,  ...,  4,  0, 26],\n",
      "        [ 2,  9,  0,  ...,  4,  0, 39],\n",
      "        [ 5, 15,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1,  6],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  1,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[5.4000e+01, 1.6064e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.8000e+01, 1.9109e+05, 1.3000e+01, 2.3540e+03, 0.0000e+00, 6.0000e+01],\n",
      "        [3.9000e+01, 8.8973e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 8.4000e+01],\n",
      "        ...,\n",
      "        [4.8000e+01, 1.4504e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.2000e+01, 1.5543e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.8000e+01],\n",
      "        [6.1000e+01, 9.2178e+04, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 15,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 12],\n",
      "        [ 4, 11,  4,  ...,  4,  1,  0],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  6,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[2.2000e+01, 1.5733e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.0000e+01, 1.2761e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01],\n",
      "        [3.6000e+01, 1.3516e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        ...,\n",
      "        [5.1000e+01, 2.0588e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.8000e+01, 1.4650e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.7000e+01],\n",
      "        [2.8000e+01, 5.9509e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 6.3000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0.])\n",
      "cat tensor([[ 1, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 2, 15,  2,  ...,  2,  0, 39],\n",
      "        [ 1, 12,  4,  ...,  4,  0,  5],\n",
      "        [ 4, 11,  2,  ...,  4,  0, 39]])\n",
      "num tensor([[5.4000e+01, 3.3863e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 1.0832e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [3.6000e+01, 1.9612e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.3000e+01],\n",
      "        ...,\n",
      "        [5.8000e+01, 2.9431e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 5.5000e+01],\n",
      "        [2.6000e+01, 4.8853e+04, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 2.7234e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 2,  9,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  9,  2,  ...,  1,  1, 40],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  2,  1, 39],\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[2.8000e+01, 2.1094e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        [4.0000e+01, 2.5931e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        [5.3000e+01, 2.0629e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        ...,\n",
      "        [1.9000e+01, 1.9846e+05, 9.0000e+00, 0.0000e+00, 2.0010e+03, 4.0000e+01],\n",
      "        [2.5000e+01, 1.8985e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.3000e+01, 1.8506e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01]])\n",
      "label tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 6,  8,  2,  ...,  4,  0, 39],\n",
      "        [ 5,  8,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 6,  0,  5,  ...,  2,  1, 39]])\n",
      "num tensor([[2.7000e+01, 5.9068e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.8000e+01, 1.0123e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 1.5000e+01],\n",
      "        [4.3000e+01, 1.5053e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [2.3000e+01, 6.4520e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [3.6000e+01, 1.8539e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.9000e+01, 4.9752e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 6, 15,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 11],\n",
      "        [ 4, 15,  0,  ...,  4,  0, 39]])\n",
      "num tensor([[2.9000e+01, 3.9388e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 1.1221e+05, 9.0000e+00, 0.0000e+00, 1.4850e+03, 4.0000e+01],\n",
      "        [3.8000e+01, 1.3028e+05, 1.0000e+01, 0.0000e+00, 1.7260e+03, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.2000e+01, 9.3099e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        [3.1000e+01, 3.8237e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.7000e+01, 5.8337e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 7,  9,  5,  ...,  4,  0, 39],\n",
      "        [ 4,  1,  4,  ...,  1,  0, 30],\n",
      "        [ 4, 11,  5,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4,  7,  2,  ...,  4,  0, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[4.8000e+01, 1.5845e+05, 1.3000e+01, 9.1400e+02, 0.0000e+00, 4.0000e+01],\n",
      "        [1.9000e+01, 8.6150e+04, 7.0000e+00, 0.0000e+00, 0.0000e+00, 1.9000e+01],\n",
      "        [3.0000e+01, 2.7058e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.8000e+01, 3.1392e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+01],\n",
      "        [4.0000e+01, 2.0173e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.8000e+01],\n",
      "        [2.0000e+01, 4.2097e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0.])\n",
      "cat tensor([[ 4, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 1, 12,  6,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 7, 11,  0,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[2.7000e+01, 1.9113e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [7.4000e+01, 1.1913e+05, 9.0000e+00, 0.0000e+00, 2.1490e+03, 2.0000e+01],\n",
      "        [6.1000e+01, 1.9731e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.2000e+01, 2.2098e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.3000e+01, 2.8107e+05, 9.0000e+00, 0.0000e+00, 1.0920e+03, 4.0000e+01],\n",
      "        [6.4000e+01, 1.2104e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  4,  ...,  2,  0, 39],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  1,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[6.7000e+01, 2.4757e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 2.4000e+01],\n",
      "        [4.6000e+01, 2.5312e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.4000e+01, 2.2933e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [5.3000e+01, 1.2091e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [5.8000e+01, 1.6486e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 9.9000e+01],\n",
      "        [4.2000e+01, 1.3887e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 9.9000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 2, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 7, 10,  2,  ...,  4,  1, 39],\n",
      "        [ 0,  5,  4,  ...,  4,  0, 26],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  2,  1, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  0, 11],\n",
      "        [ 4,  1,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[5.1000e+01, 8.0123e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [5.6000e+01, 2.2274e+05, 1.6000e+01, 0.0000e+00, 0.0000e+00, 5.6000e+01],\n",
      "        [2.2000e+01, 2.1424e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.6000e+01, 2.0620e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.0000e+01, 3.1875e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [1.8000e+01, 1.1544e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  2,  ...,  2,  1, 39],\n",
      "        [ 4, 12,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1,  0],\n",
      "        [ 6, 11,  2,  ...,  4,  1, 21]])\n",
      "num tensor([[2.7000e+01, 1.3827e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [2.6000e+01, 1.8160e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.0000e+01, 2.3958e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+01],\n",
      "        ...,\n",
      "        [3.0000e+01, 3.2008e+04, 1.3000e+01, 0.0000e+00, 0.0000e+00, 7.2000e+01],\n",
      "        [2.8000e+01, 1.9220e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.7000e+01, 1.1544e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01]])\n",
      "label tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1.])\n",
      "cat tensor([[ 4,  5,  4,  ...,  2,  0, 39],\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 1, 14,  2,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  7,  4,  ...,  4,  1,  4]])\n",
      "num tensor([[5.2000e+01, 1.4508e+05, 4.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 2.0349e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.3000e+01, 1.9002e+05, 1.5000e+01, 0.0000e+00, 0.0000e+00, 6.0000e+01],\n",
      "        ...,\n",
      "        [1.9000e+01, 2.3657e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        [3.3000e+01, 4.8520e+04, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 3.8028e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01]])\n",
      "label tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 6, 12,  0,  ...,  4,  0, 39],\n",
      "        [ 4,  9,  2,  ...,  4,  1, 39],\n",
      "        [ 2,  1,  2,  ...,  2,  1, 39],\n",
      "        ...,\n",
      "        [ 4,  7,  4,  ...,  3,  1, 39],\n",
      "        [ 1, 15,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  9,  4,  ...,  4,  0, 39]])\n",
      "num tensor([[4.1000e+01, 1.4133e+05, 1.4000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [4.6000e+01, 1.5987e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [6.4000e+01, 2.4490e+05, 7.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.3000e+01, 1.4238e+05, 1.2000e+01, 0.0000e+00, 0.0000e+00, 3.6000e+01],\n",
      "        [4.1000e+01, 2.7444e+04, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 3.3057e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 1.6000e+01]])\n",
      "label tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0.])\n",
      "cat tensor([[ 4, 12,  2,  ...,  1,  1, 19],\n",
      "        [ 4, 12,  4,  ...,  4,  1, 39],\n",
      "        [ 4, 14,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  4,  ...,  4,  1, 39],\n",
      "        [ 2, 12,  2,  ...,  4,  0, 39],\n",
      "        [ 5, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[4.2000e+01, 1.9834e+05, 1.4000e+01, 0.0000e+00, 1.9020e+03, 5.5000e+01],\n",
      "        [2.6000e+01, 2.9957e+04, 1.4000e+01, 0.0000e+00, 0.0000e+00, 2.5000e+01],\n",
      "        [3.8000e+01, 1.1150e+05, 1.5000e+01, 0.0000e+00, 0.0000e+00, 5.0000e+01],\n",
      "        ...,\n",
      "        [2.4000e+01, 1.9934e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [4.5000e+01, 3.8463e+05, 1.4000e+01, 2.5800e+03, 0.0000e+00, 1.8000e+01],\n",
      "        [5.0000e+01, 1.3691e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+01]])\n",
      "label tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 6, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  2,  ...,  4,  1, 39],\n",
      "        [ 4,  8,  0,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 11,  0,  ...,  4,  0, 39],\n",
      "        [ 4, 11,  2,  ...,  4,  1, 39],\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39]])\n",
      "num tensor([[3.0000e+01, 1.4616e+05, 9.0000e+00, 0.0000e+00, 1.8870e+03, 5.0000e+01],\n",
      "        [5.5000e+01, 1.8488e+05, 1.1000e+01, 5.1780e+03, 0.0000e+00, 5.0000e+01],\n",
      "        [5.5000e+01, 2.8338e+04, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [4.6000e+01, 1.6443e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [6.0000e+01, 1.3253e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [2.3000e+01, 1.3336e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 1.5000e+01]])\n",
      "label tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "cat tensor([[ 4,  0,  4,  ...,  4,  1, 39],\n",
      "        [ 0,  6,  4,  ...,  4,  0,  6],\n",
      "        [ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  5,  ...,  4,  1, 39],\n",
      "        [ 2,  9,  2,  ...,  4,  1, 26],\n",
      "        [ 2, 15,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[1.7000e+01, 2.3935e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 1.8000e+01],\n",
      "        [6.2000e+01, 2.0313e+05, 5.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.1000e+01, 1.0208e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [2.0000e+01, 1.3232e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.4000e+01, 4.2990e+05, 1.3000e+01, 0.0000e+00, 0.0000e+00, 4.5000e+01],\n",
      "        [4.6000e+01, 2.7420e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01]])\n",
      "label tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 1.])\n",
      "cat tensor([[ 4, 11,  4,  ...,  4,  0, 39],\n",
      "        [ 4,  0,  4,  ...,  4,  1, 26],\n",
      "        [ 4,  8,  0,  ...,  4,  1, 39],\n",
      "        ...,\n",
      "        [ 4, 15,  4,  ...,  4,  1, 39],\n",
      "        [ 2, 14,  2,  ...,  4,  1, 39],\n",
      "        [ 2, 11,  2,  ...,  4,  1, 39]])\n",
      "num tensor([[2.3000e+01, 2.1681e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01],\n",
      "        [2.9000e+01, 2.7158e+05, 6.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [3.6000e+01, 3.5900e+05, 1.1000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        ...,\n",
      "        [3.9000e+01, 3.2537e+05, 1.0000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01],\n",
      "        [4.7000e+01, 2.8487e+05, 1.5000e+01, 0.0000e+00, 0.0000e+00, 3.5000e+01],\n",
      "        [6.1000e+01, 1.9208e+05, 9.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e+01]])\n",
      "label tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for cat,num,label in train_dataloader:\n",
    "    print(\"cat\",cat)\n",
    "    print(\"num\",num)\n",
    "    print(\"label\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each task loss is scaled by its own learnable parameter, then regularization is applied \n",
    "class UncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks):\n",
    "        super(UncertaintyLoss, self).__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        self.loss_fns = [nn.CrossEntropyLoss() for x in range(num_tasks)] \n",
    "\n",
    "    def forward(self, predictions, labels_task1):\n",
    "\n",
    "        #task 1\n",
    "        target = labels_task1.long()\n",
    "        prediction = predictions[0]\n",
    "        loss_fn = self.loss_fns[0]\n",
    "        task_loss = loss_fn(prediction, target)\n",
    "        \n",
    "        return task_loss\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_cont, cat_feat, num_target_labels, rff_on):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.rff_on = rff_on\n",
    "\n",
    "        if self.rff_on:\n",
    "            self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_cont)])\n",
    "            self.dropout = nn.Dropout(embedding_dropout)\n",
    "            self.mlp_in = embed_size\n",
    "        else:\n",
    "            self.mlp_in = input_size\n",
    "\n",
    "        self.cont_embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_cont)])\n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(num_classes, embed_size) for num_classes in cat_feat])\n",
    "\n",
    "        # Classifcation Embeddings for each target label\n",
    "        self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "    def forward(self, cat_x, cont_x):\n",
    "        x = cont_x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "        rff_vectors = []\n",
    "        if self.rff_on:\n",
    "            for i, r in enumerate(self.rffs):\n",
    "                input = x[:,i,:]\n",
    "                out = r(input)\n",
    "                rff_vectors.append(out)\n",
    "        \n",
    "            x = torch.stack(rff_vectors, dim=1)\n",
    "        \n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.cont_embeddings):\n",
    "            goin_in = x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        #embedding cat features\n",
    "        cat_x = cat_x.unsqueeze(2)\n",
    "        for i, e in enumerate(self.cat_embeddings):\n",
    "\n",
    "            goin_in = cat_x[:,i,:]\n",
    "  \n",
    "            goin_out = e(goin_in)\n",
    "            goin_out=goin_out.squeeze(1)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embeddings:\n",
    "            input = torch.tensor([0], device=x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(x.size(0), 1)\n",
    "            tmep = temp.unsqueeze(1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "        \n",
    "        # class_embed = self.classification_embedding(torch.tensor([0], device=x.device))  # use index 0 for the classification embedding\n",
    "        # class_embed = class_embed.repeat(x.size(0), 1) # -> (batch_size, embed_size)\n",
    "        # class_embed = class_embed.unsqueeze(1)\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "        return class_embeddings, context\n",
    "# class Embeddings(nn.Module):\n",
    "#     def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_features, num_target_labels, rff_on):\n",
    "#         super(Embeddings, self).__init__()\n",
    "\n",
    "#         self.rff_on = rff_on\n",
    "\n",
    "#         if self.rff_on:\n",
    "#             self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_features)])\n",
    "#             self.dropout = nn.Dropout(embedding_dropout)\n",
    "#             self.mlp_in = embed_size\n",
    "#         else:\n",
    "#             self.mlp_in = input_size\n",
    "\n",
    "#         self.embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_features)])\n",
    "\n",
    "#         # Classifcation Embeddings for each target label\n",
    "#         self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "#         rff_vectors = []\n",
    "#         if self.rff_on:\n",
    "#             for i, r in enumerate(self.rffs):\n",
    "#                 input = x[:,i,:]\n",
    "#                 out = r(input)\n",
    "#                 rff_vectors.append(out)\n",
    "        \n",
    "#             x = torch.stack(rff_vectors, dim=1)\n",
    "        \n",
    "#         embeddings = []\n",
    "#         for i, e in enumerate(self.embeddings):\n",
    "#             goin_in = x[:,i,:]\n",
    "#             goin_out = e(goin_in)\n",
    "#             embeddings.append(goin_out)\n",
    "\n",
    "#         target_label_embeddings_ = []\n",
    "#         for e in self.target_label_embeddings:\n",
    "#             input = torch.tensor([0], device=x.device)\n",
    "#             temp = e(input)\n",
    "#             temp = temp.repeat(x.size(0), 1)\n",
    "#             tmep = temp.unsqueeze(1)\n",
    "#             target_label_embeddings_.append(temp)\n",
    "\n",
    "#         class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "        \n",
    "#         # class_embed = self.classification_embedding(torch.tensor([0], device=x.device))  # use index 0 for the classification embedding\n",
    "#         # class_embed = class_embed.repeat(x.size(0), 1) # -> (batch_size, embed_size)\n",
    "#         # class_embed = class_embed.unsqueeze(1)\n",
    "\n",
    "#         context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "#         return class_embeddings, context\n",
    "\n",
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(classificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, num_target_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "\n",
    "# DEFAULT PARAMETERS SET UP FOR VPN DATASET. BE CAREFUL AND MAKE SURE YOU SET THEM UP HOW YOU WANT.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rff_on = False,\n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 embedding_dropout = 0,\n",
    "                 n_cont = 0,\n",
    "                 cat_feat:list = [],\n",
    "                 num_layers=1,\n",
    "                 heads=1,\n",
    "                 forward_expansion=4, # Determines how wide the MLP is in the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0,\n",
    "                 classification_dropout = 0,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 4,\n",
    "                 targets_classes : list=  [3,8]\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(rff_on=rff_on, sigma=sigma, embed_size=embed_size, input_size=input_size, embedding_dropout=embedding_dropout,n_cont=n_cont, cat_feat=cat_feat, num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        self.classifying_heads = nn.ModuleList([classificationHead(embed_size=embed_size, dropout=classification_dropout, mlp_scale_classification=mlp_scale_classification, num_target_classes=x) for x in targets_classes])\n",
    "        \n",
    "    def forward(self, cat_x, cont_x):\n",
    "        class_embed, context = self.embeddings(cat_x, cont_x)\n",
    "\n",
    "        x = self.decoder(class_embed, context)\n",
    "        \n",
    "        probability_dist_raw = []\n",
    "        for i, e in enumerate(self.classifying_heads):\n",
    "            input = x[:, i,:]\n",
    "            output = e(input)\n",
    "            probability_dist_raw.append(output)\n",
    "        \n",
    "        return probability_dist_raw\n",
    "\n",
    "# Training and Testing Loops\n",
    "def train(dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    total_correct_1 = 0\n",
    "    total_samples_1 = 0\n",
    "    all_targets_1 = []\n",
    "    all_predictions_1 = []\n",
    "\n",
    "    total_correct_2 = 0\n",
    "    total_samples_2 = 0\n",
    "    all_targets_2 = []\n",
    "    all_predictions_2 = []\n",
    "\n",
    "    for (cat_x, cont_x,labels_task1) in dataloader:\n",
    "        cat_x,cont_x,labels_task1 = cat_x.to(device_in_use),cont_x.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "\n",
    "        task_predictions = model(cat_x, cont_x) #contains a list of the tensor outputs for each task\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #computing accuracy for first target\n",
    "        y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "        _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "        total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "        total_samples_1 += labels_task1.size(0)\n",
    "        all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "        all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "        # #computing accuaracy for second target\n",
    "        # y_pred_softmax_2 = torch.softmax(task_predictions[1], dim=1)\n",
    "        # _, y_pred_labels_2 = torch.max(y_pred_softmax_2, dim=1)\n",
    "        # total_correct_2 += (y_pred_labels_2 == labels_task2).sum().item()\n",
    "        # total_samples_2 += labels_task2.size(0)\n",
    "        # all_targets_2.extend(labels_task2.cpu().numpy())\n",
    "        # all_predictions_2.extend(y_pred_labels_2.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss/len(dataloader)\n",
    "    accuracy_1 = total_correct_1 / total_samples_1\n",
    "    # accuracy_2 = total_correct_2 / total_samples_2\n",
    "\n",
    "    # # precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    # f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "    return avg_loss, accuracy_1\n",
    "\n",
    "def test(dataloader, model, loss_function, device_in_use):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_correct_1 = 0\n",
    "  total_samples_1 = 0\n",
    "  all_targets_1 = []\n",
    "  all_predictions_1 = []\n",
    "\n",
    "  total_correct_2 = 0\n",
    "  total_samples_2 = 0\n",
    "  all_targets_2 = []\n",
    "  all_predictions_2 = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (cat_x, cont_x,labels_task1) in dataloader:\n",
    "        cat_x,cont_x,labels_task1 = cat_x.to(device_in_use),cont_x.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "\n",
    "        task_predictions = model(cat_x, cont_x) #contains a list of the tensor outputs for each task\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #computing accuracy for first target\n",
    "        y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "        _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "        total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "        total_samples_1 += labels_task1.size(0)\n",
    "        all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "        all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "        # #computing accuaracy for second target\n",
    "        # y_pred_softmax_2 = torch.softmax(task_predictions[1], dim=1)\n",
    "        # _, y_pred_labels_2 = torch.max(y_pred_softmax_2, dim=1)\n",
    "        # total_correct_2 += (y_pred_labels_2 == labels_task2).sum().item()\n",
    "        # total_samples_2 += labels_task2.size(0)\n",
    "        # all_targets_2.extend(labels_task2.cpu().numpy())\n",
    "        # all_predictions_2.extend(y_pred_labels_2.cpu().numpy())\n",
    "\n",
    "  avg = total_loss/len(dataloader)\n",
    "  accuracy_1 = total_correct_1 / total_samples_1\n",
    "  # accuracy_2 = total_correct_2 / total_samples_2\n",
    "  # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "  f1_1 = f1_score(all_targets_1, all_predictions_1, average='weighted')\n",
    "  # f1_2 = f1_score(all_targets_2, all_predictions_2, average=\"weighted\")\n",
    "\n",
    "  return avg, accuracy_1, all_predictions_1, all_targets_1, f1_1\n",
    "\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5089169077429117\n",
      "0.44916285925051747\n",
      "0.44775271649454157\n"
     ]
    }
   ],
   "source": [
    "model = Classifier(\n",
    "        targets_classes=[2],\n",
    "        rff_on=True,\n",
    "        embed_size=50,\n",
    "        n_cont=6,\n",
    "        cat_feat=[10,16,7,16,6,5,2,43]\n",
    "    ).to(device_in_use)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Training loop with a large number of epochs\n",
    "for epoch in range(3):\n",
    "    train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
    "    print(train_loss)\n",
    "    \n",
    "    # Validation loop\n",
    "    val_loss, val_accuracy, _, _, _ = test(val_dataloader, model, loss_function, device_in_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_metric = float('-inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Function to log results to a text file\n",
    "def log_to_file(filename, text):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(text + '\\n')\n",
    "\n",
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    sigma = trial.suggest_categorical('sigma', [.001, 0.1, 1, 2, 3, 5, 10])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    prenorm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "    embedding_dropout = trial.suggest_categorical('embedding_dropout', [0, .1, .2, .5])\n",
    "    decoder_dropout = trial.suggest_categorical('decoder_dropout', [0,.1,.2,.5])\n",
    "    classification_dropout = trial.suggest_categorical('class_drop', [0,.1,.2,.5])\n",
    "\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.0001, 0.001, 0.01])\n",
    "\n",
    "    num_epochs = 75\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = Classifier(\n",
    "        targets_classes=[2],\n",
    "        rff_on=True,\n",
    "        n_cont=6,\n",
    "        cat_feat=[10,16,7,16,6,5,2,43],\n",
    "        sigma=sigma,\n",
    "        embed_size=embed_size,\n",
    "        num_layers=num_layers,\n",
    "        heads=heads,\n",
    "        forward_expansion=forward_expansion,\n",
    "        pre_norm_on=prenorm_on,\n",
    "        mlp_scale_classification=mlp_scale_classification,\n",
    "        embedding_dropout=embedding_dropout,\n",
    "        decoder_dropout=decoder_dropout,\n",
    "        classification_dropout=classification_dropout\n",
    "    ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = UncertaintyLoss(1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=3)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
    "        \n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy, _, _, _ = test(val_dataloader, model, loss_function, device_in_use)\n",
    "        \n",
    "        # Check if we should early stop based on validation accuracy\n",
    "        if early_stopping(val_accuracy):\n",
    "            break\n",
    "\n",
    "    # # Evaluate the model on the test set\n",
    "    # test_loss, test_accuracy, _, _, _ = test(test_dataloader, model, loss_function, device_in_use)\n",
    "    \n",
    "    # Log the final test accuracy for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation Accuracy = {val_accuracy:.4f}\"\n",
    "    log_to_file('all_trials_log.txt', final_log)\n",
    "\n",
    "    # Return the test accuracy as the objective to optimize\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 15:48:40,112] A new study created in memory with name: no-name-5d8d728d-4b51-4a62-ac37-f1c5a5c4eb2c\n",
      "Best trial: 0. Best value: 0.822662:   2%|â–         | 1/50 [02:33<2:05:22, 153.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 15:51:13,625] Trial 0 finished with value: 0.8226623675725472 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 120, 'heads': 10, 'forward_expansion': 4, 'prenorm_on': True, 'mlp_scale_classification': 1, 'embedding_dropout': 0.2, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.001}. Best is trial 0 with value: 0.8226623675725472.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.822662:   4%|â–         | 2/50 [05:12<2:05:36, 157.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 15:53:53,096] Trial 1 finished with value: 0.7597113465376938 and parameters: {'sigma': 3, 'num_layers': 2, 'embed_size': 60, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 6, 'embedding_dropout': 0.2, 'decoder_dropout': 0.5, 'class_drop': 0.5, 'learning_rate': 0.0001}. Best is trial 0 with value: 0.8226623675725472.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.822662:   6%|â–Œ         | 3/50 [07:51<2:03:23, 157.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 15:56:31,219] Trial 2 finished with value: 0.8031629049593122 and parameters: {'sigma': 3, 'num_layers': 2, 'embed_size': 160, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 6, 'embedding_dropout': 0.5, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.001}. Best is trial 0 with value: 0.8226623675725472.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.851067:   8%|â–Š         | 4/50 [10:23<1:59:17, 155.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 15:59:03,863] Trial 3 finished with value: 0.8510670965760786 and parameters: {'sigma': 1, 'num_layers': 1, 'embed_size': 90, 'heads': 5, 'forward_expansion': 7, 'prenorm_on': True, 'mlp_scale_classification': 1, 'embedding_dropout': 0.1, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.01}. Best is trial 3 with value: 0.8510670965760786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.868571:  10%|â–ˆ         | 5/50 [12:57<1:56:05, 154.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:01:37,198] Trial 4 finished with value: 0.8685705512052817 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 70, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.2, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.0001}. Best is trial 4 with value: 0.8685705512052817.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.868571:  12%|â–ˆâ–        | 6/50 [15:29<1:52:55, 153.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:04:09,647] Trial 5 finished with value: 0.8447719944725933 and parameters: {'sigma': 5, 'num_layers': 1, 'embed_size': 80, 'heads': 10, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 6, 'embedding_dropout': 0.2, 'decoder_dropout': 0, 'class_drop': 0.2, 'learning_rate': 0.01}. Best is trial 4 with value: 0.8685705512052817.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.868571:  14%|â–ˆâ–        | 7/50 [18:03<1:50:15, 153.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:06:43,215] Trial 6 finished with value: 0.8456932289267619 and parameters: {'sigma': 5, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0.1, 'decoder_dropout': 0.1, 'class_drop': 0.2, 'learning_rate': 0.01}. Best is trial 4 with value: 0.8685705512052817.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.869031:  16%|â–ˆâ–Œ        | 8/50 [20:33<1:46:48, 152.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:09:13,114] Trial 7 finished with value: 0.869031168432366 and parameters: {'sigma': 1, 'num_layers': 1, 'embed_size': 80, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0, 'learning_rate': 0.0001}. Best is trial 7 with value: 0.869031168432366.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.869031:  18%|â–ˆâ–Š        | 9/50 [23:13<1:45:55, 155.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:11:53,470] Trial 8 finished with value: 0.8475356978350991 and parameters: {'sigma': 0.1, 'num_layers': 2, 'embed_size': 140, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'embedding_dropout': 0, 'decoder_dropout': 0.5, 'class_drop': 0.2, 'learning_rate': 0.0001}. Best is trial 7 with value: 0.869031168432366.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.869031:  20%|â–ˆâ–ˆ        | 10/50 [25:51<1:44:03, 156.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:14:31,935] Trial 9 finished with value: 0.8552126516198373 and parameters: {'sigma': 0.1, 'num_layers': 2, 'embed_size': 60, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': True, 'mlp_scale_classification': 6, 'embedding_dropout': 0.2, 'decoder_dropout': 0.1, 'class_drop': 0, 'learning_rate': 0.01}. Best is trial 7 with value: 0.869031168432366.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.869031:  22%|â–ˆâ–ˆâ–       | 11/50 [28:16<1:39:12, 152.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:16:56,713] Trial 10 finished with value: 0.8674957776754184 and parameters: {'sigma': 1, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 7 with value: 0.869031168432366.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.869338:  24%|â–ˆâ–ˆâ–       | 12/50 [30:41<1:35:04, 150.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:19:21,131] Trial 11 finished with value: 0.8693382465837556 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 11 with value: 0.8693382465837556.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.870259:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [33:14<1:33:10, 151.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:21:54,430] Trial 12 finished with value: 0.8702594810379242 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 12 with value: 0.8702594810379242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.870259:  28%|â–ˆâ–ˆâ–Š       | 14/50 [35:48<1:31:10, 151.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:24:28,394] Trial 13 finished with value: 0.8639643789344388 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 12 with value: 0.8702594810379242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [38:13<1:27:22, 149.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:26:53,156] Trial 14 finished with value: 0.8704130201136189 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  32%|â–ˆâ–ˆâ–ˆâ–      | 16/50 [40:45<1:25:24, 150.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:29:26,020] Trial 15 finished with value: 0.8696453247351451 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [43:15<1:22:46, 150.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:31:56,062] Trial 16 finished with value: 0.8645785352372178 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [45:48<1:20:34, 151.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:34:28,492] Trial 17 finished with value: 0.862582527253186 and parameters: {'sigma': 0.001, 'num_layers': 2, 'embed_size': 100, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 19/50 [48:20<1:18:16, 151.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:37:00,926] Trial 18 finished with value: 0.8659603869184708 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 120, 'heads': 1, 'forward_expansion': 5, 'prenorm_on': False, 'mlp_scale_classification': 5, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [50:52<1:15:49, 151.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:39:32,899] Trial 19 finished with value: 0.8590511285122063 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 50, 'heads': 10, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.1, 'decoder_dropout': 0.1, 'class_drop': 0.1, 'learning_rate': 0.001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [53:28<1:13:52, 152.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:42:08,555] Trial 20 finished with value: 0.8621219100261016 and parameters: {'sigma': 0.001, 'num_layers': 2, 'embed_size': 160, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [56:03<1:11:38, 153.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:44:43,607] Trial 21 finished with value: 0.8648856133886074 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [58:36<1:09:00, 153.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:47:16,542] Trial 22 finished with value: 0.8154460310148933 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [1:01:07<1:06:08, 152.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:49:47,584] Trial 23 finished with value: 0.8702594810379242 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [1:03:39<1:03:28, 152.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:52:19,213] Trial 24 finished with value: 0.8644249961615231 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 140, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 5, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/50 [1:06:13<1:01:09, 152.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:54:53,451] Trial 25 finished with value: 0.8699524028865346 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [1:08:46<58:38, 152.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:57:26,636] Trial 26 finished with value: 0.866421004145555 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [1:11:17<55:51, 152.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 16:59:57,448] Trial 27 finished with value: 0.8638108398587441 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [1:13:49<53:16, 152.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:02:29,450] Trial 28 finished with value: 0.8412405957316137 and parameters: {'sigma': 0.1, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0.1, 'decoder_dropout': 0, 'class_drop': 0.5, 'learning_rate': 0.001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [1:16:30<51:40, 155.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:05:10,963] Trial 29 finished with value: 0.8384768923691079 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 120, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 5, 'embedding_dropout': 0.5, 'decoder_dropout': 0.1, 'class_drop': 0.5, 'learning_rate': 0.01}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [1:19:02<48:47, 154.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:07:42,870] Trial 30 finished with value: 0.8496852448948258 and parameters: {'sigma': 5, 'num_layers': 1, 'embed_size': 70, 'heads': 10, 'forward_expansion': 4, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0, 'decoder_dropout': 0, 'class_drop': 0.1, 'learning_rate': 0.001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [1:21:30<45:41, 152.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:10:11,085] Trial 31 finished with value: 0.8670351604483341 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [1:24:04<43:18, 152.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:12:45,079] Trial 32 finished with value: 0.8685705512052817 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [1:26:37<40:45, 152.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:15:17,870] Trial 33 finished with value: 0.8699524028865346 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [1:29:16<38:38, 154.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:17:56,455] Trial 34 finished with value: 0.869031168432366 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 60, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 2, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [1:31:46<35:46, 153.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:20:26,878] Trial 35 finished with value: 0.8588975894365116 and parameters: {'sigma': 3, 'num_layers': 2, 'embed_size': 90, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 1, 'embedding_dropout': 0.2, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [1:34:23<33:26, 154.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:23:03,598] Trial 36 finished with value: 0.8671886995240289 and parameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 80, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': True, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.5, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [1:36:55<30:44, 153.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:25:35,714] Trial 37 finished with value: 0.8522954091816367 and parameters: {'sigma': 0.001, 'num_layers': 1, 'embed_size': 160, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0.1, 'decoder_dropout': 0.2, 'class_drop': 0.2, 'learning_rate': 0.01}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [1:39:31<28:18, 154.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:28:11,949] Trial 38 finished with value: 0.8615077537233226 and parameters: {'sigma': 1, 'num_layers': 1, 'embed_size': 50, 'heads': 1, 'forward_expansion': 6, 'prenorm_on': False, 'mlp_scale_classification': 6, 'embedding_dropout': 0.2, 'decoder_dropout': 0.5, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [1:42:07<25:47, 154.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:30:47,535] Trial 39 finished with value: 0.8300322432058959 and parameters: {'sigma': 5, 'num_layers': 1, 'embed_size': 90, 'heads': 10, 'forward_expansion': 3, 'prenorm_on': True, 'mlp_scale_classification': 1, 'embedding_dropout': 0.5, 'decoder_dropout': 0, 'class_drop': 0, 'learning_rate': 0.001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [1:44:47<23:26, 156.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:33:27,211] Trial 40 finished with value: 0.7756794104099494 and parameters: {'sigma': 10, 'num_layers': 2, 'embed_size': 140, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0.5, 'decoder_dropout': 0.1, 'class_drop': 0.2, 'learning_rate': 0.01}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [1:47:19<20:40, 155.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:35:59,394] Trial 41 finished with value: 0.8670351604483341 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [1:49:49<17:55, 153.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:38:29,913] Trial 42 finished with value: 0.8665745432212498 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 3, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [1:52:21<15:18, 153.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:41:01,716] Trial 43 finished with value: 0.8693382465837556 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 90, 'heads': 1, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 2, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [1:54:52<12:42, 152.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:43:32,869] Trial 44 finished with value: 0.866421004145555 and parameters: {'sigma': 3, 'num_layers': 1, 'embed_size': 100, 'heads': 1, 'forward_expansion': 1, 'prenorm_on': False, 'mlp_scale_classification': 4, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [1:57:28<10:13, 153.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:46:08,576] Trial 45 finished with value: 0.8702594810379242 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 90, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.2, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [1:59:59<07:38, 152.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:48:39,424] Trial 46 finished with value: 0.8662674650698603 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 60, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.2, 'decoder_dropout': 0.5, 'class_drop': 0, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [2:02:29<05:03, 151.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:51:09,358] Trial 47 finished with value: 0.8685705512052817 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 70, 'heads': 5, 'forward_expansion': 8, 'prenorm_on': False, 'mlp_scale_classification': 7, 'embedding_dropout': 0.2, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [2:05:07<02:33, 153.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:53:47,485] Trial 48 finished with value: 0.8687240902809765 and parameters: {'sigma': 2, 'num_layers': 1, 'embed_size': 80, 'heads': 5, 'forward_expansion': 2, 'prenorm_on': True, 'mlp_scale_classification': 8, 'embedding_dropout': 0.2, 'decoder_dropout': 0.2, 'class_drop': 0.2, 'learning_rate': 0.0001}. Best is trial 14 with value: 0.8704130201136189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.870413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [2:07:41<00:00, 153.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-16 17:56:21,199] Trial 49 finished with value: 0.8238906801781053 and parameters: {'sigma': 0.1, 'num_layers': 1, 'embed_size': 120, 'heads': 5, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.2, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.01}. Best is trial 14 with value: 0.8704130201136189.\n",
      "Best Hyperparameters: {'sigma': 10, 'num_layers': 1, 'embed_size': 70, 'heads': 1, 'forward_expansion': 3, 'prenorm_on': False, 'mlp_scale_classification': 8, 'embedding_dropout': 0.5, 'decoder_dropout': 0.2, 'class_drop': 0.1, 'learning_rate': 0.0001}\n",
      "Best Validation Accuracy (at Early Stopping): 0.8704130201136189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 50\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')  # Maximize validation accuracy\n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation Accuracy (at Early Stopping):\", best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [ 1/100]       | Train: Loss 0.5302, income Accuracy 0.7610                        | Test: Loss 0.4314, income Accuracy 0.8068, income F1 0.7947\n",
      "Epoch [ 2/100]       | Train: Loss 0.4141, income Accuracy 0.8088                        | Test: Loss 0.3940, income Accuracy 0.8194, income F1 0.8124\n",
      "Epoch [ 3/100]       | Train: Loss 0.3928, income Accuracy 0.8231                        | Test: Loss 0.3764, income Accuracy 0.8303, income F1 0.8263\n",
      "Epoch [ 4/100]       | Train: Loss 0.3744, income Accuracy 0.8302                        | Test: Loss 0.3542, income Accuracy 0.8361, income F1 0.8296\n",
      "Epoch [ 5/100]       | Train: Loss 0.3574, income Accuracy 0.8373                        | Test: Loss 0.3448, income Accuracy 0.8427, income F1 0.8358\n",
      "Epoch [ 6/100]       | Train: Loss 0.3452, income Accuracy 0.8427                        | Test: Loss 0.3368, income Accuracy 0.8453, income F1 0.8409\n",
      "Epoch [ 7/100]       | Train: Loss 0.3366, income Accuracy 0.8461                        | Test: Loss 0.3283, income Accuracy 0.8501, income F1 0.8439\n",
      "Epoch [ 8/100]       | Train: Loss 0.3280, income Accuracy 0.8494                        | Test: Loss 0.3290, income Accuracy 0.8507, income F1 0.8374\n",
      "Epoch [ 9/100]       | Train: Loss 0.3226, income Accuracy 0.8517                        | Test: Loss 0.3195, income Accuracy 0.8535, income F1 0.8468\n",
      "Epoch [10/100]       | Train: Loss 0.3183, income Accuracy 0.8547                        | Test: Loss 0.3160, income Accuracy 0.8563, income F1 0.8480\n",
      "Epoch [11/100]       | Train: Loss 0.3133, income Accuracy 0.8574                        | Test: Loss 0.3159, income Accuracy 0.8564, income F1 0.8520\n",
      "Epoch [12/100]       | Train: Loss 0.3108, income Accuracy 0.8584                        | Test: Loss 0.3099, income Accuracy 0.8596, income F1 0.8520\n",
      "Epoch [13/100]       | Train: Loss 0.3081, income Accuracy 0.8585                        | Test: Loss 0.3078, income Accuracy 0.8608, income F1 0.8531\n",
      "Epoch [14/100]       | Train: Loss 0.3037, income Accuracy 0.8616                        | Test: Loss 0.3068, income Accuracy 0.8601, income F1 0.8554\n",
      "Epoch [15/100]       | Train: Loss 0.3044, income Accuracy 0.8603                        | Test: Loss 0.3061, income Accuracy 0.8605, income F1 0.8561\n",
      "Epoch [16/100]       | Train: Loss 0.3003, income Accuracy 0.8620                        | Test: Loss 0.3037, income Accuracy 0.8607, income F1 0.8539\n",
      "Epoch [17/100]       | Train: Loss 0.2982, income Accuracy 0.8631                        | Test: Loss 0.3046, income Accuracy 0.8584, income F1 0.8564\n",
      "Epoch [18/100]       | Train: Loss 0.2980, income Accuracy 0.8650                        | Test: Loss 0.3014, income Accuracy 0.8619, income F1 0.8549\n",
      "Epoch [19/100]       | Train: Loss 0.2966, income Accuracy 0.8649                        | Test: Loss 0.3010, income Accuracy 0.8605, income F1 0.8526\n",
      "Epoch [20/100]       | Train: Loss 0.2965, income Accuracy 0.8639                        | Test: Loss 0.3033, income Accuracy 0.8587, income F1 0.8563\n",
      "Epoch [21/100]       | Train: Loss 0.2957, income Accuracy 0.8627                        | Test: Loss 0.3064, income Accuracy 0.8567, income F1 0.8557\n",
      "Epoch [22/100]       | Train: Loss 0.2931, income Accuracy 0.8648                        | Test: Loss 0.3018, income Accuracy 0.8623, income F1 0.8586\n",
      "Epoch [23/100]       | Train: Loss 0.2934, income Accuracy 0.8642                        | Test: Loss 0.3004, income Accuracy 0.8626, income F1 0.8553\n",
      "Epoch [24/100]       | Train: Loss 0.2927, income Accuracy 0.8619                        | Test: Loss 0.3018, income Accuracy 0.8630, income F1 0.8596\n",
      "Epoch [25/100]       | Train: Loss 0.2902, income Accuracy 0.8646                        | Test: Loss 0.2996, income Accuracy 0.8627, income F1 0.8570\n",
      "Epoch [26/100]       | Train: Loss 0.2895, income Accuracy 0.8667                        | Test: Loss 0.2990, income Accuracy 0.8629, income F1 0.8578\n",
      "Epoch [27/100]       | Train: Loss 0.2895, income Accuracy 0.8635                        | Test: Loss 0.2980, income Accuracy 0.8636, income F1 0.8588\n",
      "Epoch [28/100]       | Train: Loss 0.2873, income Accuracy 0.8667                        | Test: Loss 0.2981, income Accuracy 0.8638, income F1 0.8580\n",
      "Epoch [29/100]       | Train: Loss 0.2870, income Accuracy 0.8661                        | Test: Loss 0.2987, income Accuracy 0.8633, income F1 0.8600\n",
      "Epoch [30/100]       | Train: Loss 0.2869, income Accuracy 0.8657                        | Test: Loss 0.2953, income Accuracy 0.8646, income F1 0.8585\n",
      "Epoch [31/100]       | Train: Loss 0.2854, income Accuracy 0.8661                        | Test: Loss 0.2973, income Accuracy 0.8650, income F1 0.8589\n",
      "Epoch [32/100]       | Train: Loss 0.2838, income Accuracy 0.8667                        | Test: Loss 0.2975, income Accuracy 0.8601, income F1 0.8585\n",
      "Epoch [33/100]       | Train: Loss 0.2838, income Accuracy 0.8671                        | Test: Loss 0.2960, income Accuracy 0.8661, income F1 0.8613\n",
      "Epoch [34/100]       | Train: Loss 0.2840, income Accuracy 0.8666                        | Test: Loss 0.2958, income Accuracy 0.8636, income F1 0.8606\n",
      "Epoch [35/100]       | Train: Loss 0.2827, income Accuracy 0.8667                        | Test: Loss 0.2968, income Accuracy 0.8645, income F1 0.8610\n",
      "Epoch [36/100]       | Train: Loss 0.2824, income Accuracy 0.8689                        | Test: Loss 0.2948, income Accuracy 0.8652, income F1 0.8614\n",
      "Epoch [37/100]       | Train: Loss 0.2820, income Accuracy 0.8683                        | Test: Loss 0.2956, income Accuracy 0.8651, income F1 0.8621\n",
      "Epoch [38/100]       | Train: Loss 0.2812, income Accuracy 0.8681                        | Test: Loss 0.2950, income Accuracy 0.8636, income F1 0.8610\n",
      "Epoch [39/100]       | Train: Loss 0.2807, income Accuracy 0.8686                        | Test: Loss 0.2957, income Accuracy 0.8639, income F1 0.8614\n",
      "Epoch [40/100]       | Train: Loss 0.2798, income Accuracy 0.8705                        | Test: Loss 0.3004, income Accuracy 0.8587, income F1 0.8582\n",
      "Epoch [41/100]       | Train: Loss 0.2806, income Accuracy 0.8681                        | Test: Loss 0.2930, income Accuracy 0.8662, income F1 0.8602\n",
      "Epoch [42/100]       | Train: Loss 0.2786, income Accuracy 0.8686                        | Test: Loss 0.2940, income Accuracy 0.8649, income F1 0.8596\n",
      "Epoch [43/100]       | Train: Loss 0.2786, income Accuracy 0.8694                        | Test: Loss 0.2967, income Accuracy 0.8634, income F1 0.8611\n",
      "Epoch [44/100]       | Train: Loss 0.2780, income Accuracy 0.8710                        | Test: Loss 0.2923, income Accuracy 0.8649, income F1 0.8589\n",
      "Epoch [45/100]       | Train: Loss 0.2781, income Accuracy 0.8702                        | Test: Loss 0.2927, income Accuracy 0.8636, income F1 0.8540\n",
      "Epoch [46/100]       | Train: Loss 0.2781, income Accuracy 0.8698                        | Test: Loss 0.2922, income Accuracy 0.8660, income F1 0.8600\n",
      "Epoch [47/100]       | Train: Loss 0.2775, income Accuracy 0.8701                        | Test: Loss 0.2951, income Accuracy 0.8625, income F1 0.8605\n",
      "Epoch [48/100]       | Train: Loss 0.2770, income Accuracy 0.8684                        | Test: Loss 0.2919, income Accuracy 0.8654, income F1 0.8583\n",
      "Epoch [49/100]       | Train: Loss 0.2771, income Accuracy 0.8702                        | Test: Loss 0.2948, income Accuracy 0.8654, income F1 0.8624\n",
      "Epoch [50/100]       | Train: Loss 0.2770, income Accuracy 0.8705                        | Test: Loss 0.2911, income Accuracy 0.8663, income F1 0.8592\n",
      "Epoch [51/100]       | Train: Loss 0.2766, income Accuracy 0.8696                        | Test: Loss 0.2935, income Accuracy 0.8660, income F1 0.8581\n",
      "Epoch [52/100]       | Train: Loss 0.2759, income Accuracy 0.8704                        | Test: Loss 0.2937, income Accuracy 0.8657, income F1 0.8632\n",
      "Epoch [53/100]       | Train: Loss 0.2762, income Accuracy 0.8705                        | Test: Loss 0.2914, income Accuracy 0.8659, income F1 0.8608\n",
      "Epoch [54/100]       | Train: Loss 0.2761, income Accuracy 0.8705                        | Test: Loss 0.2923, income Accuracy 0.8657, income F1 0.8593\n",
      "Epoch [55/100]       | Train: Loss 0.2760, income Accuracy 0.8687                        | Test: Loss 0.2954, income Accuracy 0.8621, income F1 0.8607\n",
      "Epoch [56/100]       | Train: Loss 0.2755, income Accuracy 0.8691                        | Test: Loss 0.2920, income Accuracy 0.8659, income F1 0.8591\n",
      "Epoch [57/100]       | Train: Loss 0.2763, income Accuracy 0.8704                        | Test: Loss 0.2908, income Accuracy 0.8657, income F1 0.8583\n",
      "Epoch [58/100]       | Train: Loss 0.2762, income Accuracy 0.8702                        | Test: Loss 0.2913, income Accuracy 0.8670, income F1 0.8625\n",
      "Epoch [59/100]       | Train: Loss 0.2748, income Accuracy 0.8710                        | Test: Loss 0.2910, income Accuracy 0.8660, income F1 0.8605\n",
      "Epoch [60/100]       | Train: Loss 0.2737, income Accuracy 0.8705                        | Test: Loss 0.2940, income Accuracy 0.8662, income F1 0.8621\n",
      "Epoch [61/100]       | Train: Loss 0.2744, income Accuracy 0.8710                        | Test: Loss 0.2911, income Accuracy 0.8665, income F1 0.8598\n",
      "Epoch [62/100]       | Train: Loss 0.2740, income Accuracy 0.8714                        | Test: Loss 0.2921, income Accuracy 0.8672, income F1 0.8627\n",
      "Epoch [63/100]       | Train: Loss 0.2747, income Accuracy 0.8704                        | Test: Loss 0.2969, income Accuracy 0.8632, income F1 0.8615\n",
      "Epoch [64/100]       | Train: Loss 0.2742, income Accuracy 0.8715                        | Test: Loss 0.2909, income Accuracy 0.8665, income F1 0.8617\n",
      "Epoch [65/100]       | Train: Loss 0.2727, income Accuracy 0.8716                        | Test: Loss 0.2926, income Accuracy 0.8668, income F1 0.8623\n",
      "Epoch [66/100]       | Train: Loss 0.2746, income Accuracy 0.8712                        | Test: Loss 0.2918, income Accuracy 0.8651, income F1 0.8566\n",
      "Epoch [67/100]       | Train: Loss 0.2730, income Accuracy 0.8717                        | Test: Loss 0.2923, income Accuracy 0.8667, income F1 0.8617\n",
      "Epoch [68/100]       | Train: Loss 0.2746, income Accuracy 0.8704                        | Test: Loss 0.2959, income Accuracy 0.8616, income F1 0.8604\n",
      "Epoch [69/100]       | Train: Loss 0.2745, income Accuracy 0.8707                        | Test: Loss 0.2909, income Accuracy 0.8651, income F1 0.8604\n",
      "Epoch [70/100]       | Train: Loss 0.2729, income Accuracy 0.8716                        | Test: Loss 0.2933, income Accuracy 0.8654, income F1 0.8592\n",
      "Epoch [71/100]       | Train: Loss 0.2727, income Accuracy 0.8715                        | Test: Loss 0.2952, income Accuracy 0.8634, income F1 0.8617\n",
      "Epoch [72/100]       | Train: Loss 0.2730, income Accuracy 0.8711                        | Test: Loss 0.2911, income Accuracy 0.8663, income F1 0.8602\n",
      "Epoch [73/100]       | Train: Loss 0.2734, income Accuracy 0.8699                        | Test: Loss 0.2960, income Accuracy 0.8628, income F1 0.8614\n",
      "Epoch [74/100]       | Train: Loss 0.2721, income Accuracy 0.8724                        | Test: Loss 0.2908, income Accuracy 0.8664, income F1 0.8607\n",
      "Epoch [75/100]       | Train: Loss 0.2724, income Accuracy 0.8721                        | Test: Loss 0.2905, income Accuracy 0.8658, income F1 0.8586\n",
      "Epoch [76/100]       | Train: Loss 0.2735, income Accuracy 0.8710                        | Test: Loss 0.2960, income Accuracy 0.8630, income F1 0.8613\n",
      "Epoch [77/100]       | Train: Loss 0.2724, income Accuracy 0.8714                        | Test: Loss 0.2927, income Accuracy 0.8663, income F1 0.8626\n",
      "Epoch [78/100]       | Train: Loss 0.2710, income Accuracy 0.8718                        | Test: Loss 0.2925, income Accuracy 0.8658, income F1 0.8620\n",
      "Epoch [79/100]       | Train: Loss 0.2721, income Accuracy 0.8716                        | Test: Loss 0.2969, income Accuracy 0.8635, income F1 0.8529\n",
      "Epoch [80/100]       | Train: Loss 0.2718, income Accuracy 0.8720                        | Test: Loss 0.2935, income Accuracy 0.8665, income F1 0.8596\n",
      "Epoch [81/100]       | Train: Loss 0.2714, income Accuracy 0.8720                        | Test: Loss 0.2944, income Accuracy 0.8651, income F1 0.8619\n",
      "Epoch [82/100]       | Train: Loss 0.2708, income Accuracy 0.8712                        | Test: Loss 0.2964, income Accuracy 0.8628, income F1 0.8521\n",
      "Epoch [83/100]       | Train: Loss 0.2717, income Accuracy 0.8719                        | Test: Loss 0.2947, income Accuracy 0.8654, income F1 0.8625\n",
      "Epoch [84/100]       | Train: Loss 0.2706, income Accuracy 0.8723                        | Test: Loss 0.2936, income Accuracy 0.8661, income F1 0.8613\n",
      "Epoch [85/100]       | Train: Loss 0.2711, income Accuracy 0.8721                        | Test: Loss 0.2926, income Accuracy 0.8660, income F1 0.8612\n",
      "Epoch [86/100]       | Train: Loss 0.2704, income Accuracy 0.8717                        | Test: Loss 0.2940, income Accuracy 0.8618, income F1 0.8497\n",
      "Epoch [87/100]       | Train: Loss 0.2709, income Accuracy 0.8725                        | Test: Loss 0.2946, income Accuracy 0.8660, income F1 0.8617\n",
      "Epoch [88/100]       | Train: Loss 0.2701, income Accuracy 0.8719                        | Test: Loss 0.2923, income Accuracy 0.8664, income F1 0.8613\n",
      "Epoch [89/100]       | Train: Loss 0.2698, income Accuracy 0.8727                        | Test: Loss 0.2926, income Accuracy 0.8662, income F1 0.8585\n",
      "Epoch [90/100]       | Train: Loss 0.2690, income Accuracy 0.8732                        | Test: Loss 0.2930, income Accuracy 0.8640, income F1 0.8550\n",
      "Epoch [91/100]       | Train: Loss 0.2700, income Accuracy 0.8715                        | Test: Loss 0.2965, income Accuracy 0.8646, income F1 0.8616\n",
      "Epoch [92/100]       | Train: Loss 0.2701, income Accuracy 0.8724                        | Test: Loss 0.2915, income Accuracy 0.8667, income F1 0.8610\n",
      "Epoch [93/100]       | Train: Loss 0.2687, income Accuracy 0.8730                        | Test: Loss 0.2932, income Accuracy 0.8664, income F1 0.8584\n",
      "Epoch [94/100]       | Train: Loss 0.2702, income Accuracy 0.8721                        | Test: Loss 0.2942, income Accuracy 0.8655, income F1 0.8618\n",
      "Epoch [95/100]       | Train: Loss 0.2693, income Accuracy 0.8706                        | Test: Loss 0.2957, income Accuracy 0.8646, income F1 0.8611\n",
      "Epoch [96/100]       | Train: Loss 0.2684, income Accuracy 0.8724                        | Test: Loss 0.2933, income Accuracy 0.8670, income F1 0.8609\n",
      "Epoch [97/100]       | Train: Loss 0.2695, income Accuracy 0.8725                        | Test: Loss 0.2930, income Accuracy 0.8652, income F1 0.8614\n",
      "Epoch [98/100]       | Train: Loss 0.2701, income Accuracy 0.8720                        | Test: Loss 0.2920, income Accuracy 0.8665, income F1 0.8597\n",
      "Epoch [99/100]       | Train: Loss 0.2685, income Accuracy 0.8734                        | Test: Loss 0.2957, income Accuracy 0.8657, income F1 0.8609\n",
      "Epoch [100/100]      | Train: Loss 0.2693, income Accuracy 0.8729                        | Test: Loss 0.2960, income Accuracy 0.8663, income F1 0.8619\n",
      "Confusion Matrix for income\n",
      "[[11614   753]\n",
      " [ 1423  2491]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Classifier(targets_classes=[2],\n",
    "                    rff_on=True,\n",
    "                    n_cont=6,\n",
    "                    cat_feat=[10,16,7,16,6,5,2,43], \n",
    "                   sigma=best_params['sigma'],\n",
    "                   embed_size=best_params['embed_size'],\n",
    "                   num_layers=best_params['num_layers'],\n",
    "                   heads=best_params['heads'],\n",
    "                   forward_expansion=best_params['forward_expansion'],\n",
    "                   pre_norm_on=best_params['prenorm_on'],\n",
    "                   mlp_scale_classification=best_params['mlp_scale_classification'],\n",
    "                   embedding_dropout=best_params['embedding_dropout'],\n",
    "                   decoder_dropout=best_params['decoder_dropout'],\n",
    "                   classification_dropout=best_params['class_drop']\n",
    "                   ).to(device_in_use) # Instantiate the model\n",
    "loss_functions = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = best_params['learning_rate']) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "epochs = 100 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "train_accuracies_2 = []\n",
    "train_recalls = [] \n",
    "train_f1_scores = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = []\n",
    "test_accuracies_2 = []\n",
    "test_recalls = []  \n",
    "test_f1_scores = [] \n",
    "all_attention_scores = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  train_loss, train_accuracy_1 = train(train_dataloader, model, loss_functions, optimizer, device_in_use=device_in_use)\n",
    "  test_loss, test_accuracy_1, all_predictions_1, all_targets_1, f1_1 = test(test_dataloader, model, loss_functions, device_in_use=device_in_use)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accuracies_1.append(train_accuracy_1)\n",
    "  # train_accuracies_2.append(train_accuracy_2)\n",
    "  # train_recalls.append(train_recall) \n",
    "  # train_f1_scores.append(train_f1)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies_1.append(test_accuracy_1)\n",
    "  # test_accuracies_2.append(test_accuracy_2)\n",
    "  # test_recalls.append(test_recall)\n",
    "  # test_f1_scores.append(test_f1)\n",
    "  # Formatting for easier reading\n",
    "  epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "  train_metrics = f\"Train: Loss {format_metric(train_loss)}, income Accuracy {format_metric(train_accuracy_1)}\"\n",
    "  test_metrics = f\"Test: Loss {format_metric(test_loss)}, income Accuracy {format_metric(test_accuracy_1)}, income F1 {format_metric(f1_1)}\"\n",
    "  print(f\"{epoch_str:20} | {train_metrics:65} | {test_metrics}\")\n",
    "\n",
    "  if early_stopping(test_accuracy_1):\n",
    "    break\n",
    "\n",
    "  # total_attention = model.decoder.avg_attention\n",
    "  # all_attention_scores.append(total_attention.tolist()) #UPDATED\n",
    "  # model.decoder.avg_attention = None\n",
    "\n",
    "# Save the model after pre-training\n",
    "torch.save(model.state_dict(), 'final_model_trained.pth')\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accuracies_1, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accuracies_1, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Curve for income')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.plot(range(1, epochs+1), train_accuracies_2, label='Train Accuracy')\n",
    "# plt.plot(range(1, epochs+1), test_accuracies_2, label='Test Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Test Accuracy Curve for Traffic Type')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Display confusion matrix for the first task (Traffic Type) on test data\n",
    "conf_matrix_1 = confusion_matrix(all_targets_1, all_predictions_1)\n",
    "print(\"Confusion Matrix for income\")\n",
    "print(conf_matrix_1)\n",
    "\n",
    "# # Display confusion matrix for the second task (Application Type) on test data\n",
    "# conf_matrix_2 = confusion_matrix(all_targets_2, all_predictions_2)\n",
    "# print(\"Confusion Matrix for Application Type\")\n",
    "# print(conf_matrix_2)\n",
    "\n",
    "# print(f\"Best accuracy: {max(test_accuracies)}\")\n",
    "\n",
    "# # Plot attention scores for each feature over epochs\n",
    "\n",
    "# # all_attention_scores = all_attention_scores.cpu().numpy() #CUDA tensor needs to be converted to cpu tensor\n",
    "# all_attention_scores = torch.tensor(all_attention_scores)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# features = df.drop(\"class1\", axis=1).columns.tolist()\n",
    "\n",
    "# for feature_idx in range(all_attention_scores.shape[1]):\n",
    "#     plt.plot(all_attention_scores[:, feature_idx], label=features[feature_idx])\n",
    "\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Attention Scores')\n",
    "# plt.title('Attention Scores for Each Feature over Epochs')\n",
    "# plt.legend(loc = 'lower left')\n",
    "# plt.show()\n",
    "\n",
    "# last_epoch_attention_scores = all_attention_scores[-1]\n",
    "# top_scores, top_indices = torch.topk(last_epoch_attention_scores, k=10)\n",
    "\n",
    "# # Display the top 10 attention scores and the corresponding feature\n",
    "# for i in range(10):\n",
    "#     print(f\"{i+1}. {features[int(top_indices[i])]}: {top_scores[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
