{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding #pip install random-fourier-features-pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and being used\n"
     ]
    }
   ],
   "source": [
    "# Run regardless if you do or do not have GPU so all tensors are moved to right location later on\n",
    "if torch.cuda.is_available():\n",
    "    device_in_use = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\")\n",
    "else:\n",
    "    device_in_use = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data section\n",
    "1. Create three seperate csv (datasets) from the Obfuscated-MalMen2022_edited.csv (edited the Category column removing the hashes with the Malware type) \n",
    "2. Save datasets into the /datasets directory \n",
    "\n",
    "(Note) Skip this if you already have the train,test, and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../datasets/malware/Obfuscated-MalMem2022_edited.csv')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df:\n",
    "    print(df[x].value_counts())\n",
    "    print(\"\\n\")\n",
    "# Note Features such as:\n",
    "# pslist.nprocs64bit, handles.nport, \n",
    "# psview.not_in_eprocess_pool, modules.nmodules, \n",
    "# svcscan.interactive_process_services, \n",
    "# callbacks.nanonymous, callbacks.ngeneric\n",
    "# Do not seem to be significant or helpful to the \n",
    "# overall model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encode all non-numerical features\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "df['Class'] = le.fit_transform(df['Class'])\n",
    "\n",
    "#Split based of the number of samples in the dataset: total(58596) train(37501)->64% test(11720)->20% val(9375)->16%\n",
    "# df_train, df_temp = train_test_split(df, train_size=37501, random_state=42)\n",
    "# df_val, df_test = train_test_split(df_temp, train_size=3375, random_state=42)\n",
    "\n",
    "df_train, df_temp = train_test_split(df, train_size=0.64, random_state=42)\n",
    "df_val, df_test = train_test_split(df_temp, train_size=0.16, random_state=42)\n",
    "\n",
    "print(f\"df_train.shape[0]:{df_train.shape[0]}\")\n",
    "print(f\"df_test.shape[0]:{df_test.shape[0]}\")\n",
    "print(f\"df_val.shape[0]:{df_val.shape[0]}\")\n",
    "\n",
    "assert(df_train.shape[0] == 37501)\n",
    "assert(df_val.shape[0] == 3375)\n",
    "assert(df_test.shape[0] == 17720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../../datasets/malware/Obfuscated-MalMem2022_train.csv')\n",
    "df_test.to_csv('../../datasets/malware/Obfuscated-MalMem2022_test.csv')\n",
    "df_val.to_csv('../../datasets/malware/Obfuscated-MalMem2022_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data\n",
    "1. Standardize or perform quantile transformations to numerica/continuous features.\n",
    "2. Wrap with Dataset and Dataloader.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note) For the next cell, you don't need to re-allocate the datasets since this is done from the Data Preprocessing section, however you may skip the Data Preprocessing Section from now on if you have the train,test, and val csv. In the case where you have the datasets and you lost your progress, then you may uncomment and run the following cell to get the train, test, and val datasets allocated to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../datasets/malware/Obfuscated-MalMem2022_train.csv')\n",
    "df_test = pd.read_csv('../../datasets/malware/Obfuscated-MalMem2022_test.csv')\n",
    "df_val = pd.read_csv('../../datasets/malware/Obfuscated-MalMem2022_val.csv') #READ FROM RIGHT SPOT\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.columns)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Category']\n",
    "cont_columns = list(df_train.drop(['Category','Class'],axis=1))\n",
    "target = ['Class']\n",
    "\n",
    "yourlist = cat_columns + cont_columns + target\n",
    "yourlist.sort()\n",
    "oglist = list(df_train.columns)\n",
    "oglist.sort()\n",
    "assert(yourlist == oglist), \"You may of spelled feature name wrong or you forgot to put on of them in the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get class counts and store in a list below\n",
    "\n",
    "for x in cat_columns:\n",
    "    print(max(len(df_train[x].value_counts()), len(df_val[x].value_counts()), len(df_test[x].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the number of classes in your classification target\n",
    "target_classes = [max(len(df_train[target].value_counts()), len(df_val[target].value_counts()),len(df_test[target].value_counts()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler and fit it to the cont features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[cont_columns])\n",
    "\n",
    "# Transform the training, test, and validation datasets\n",
    "df_train[cont_columns] = scaler.transform(df_train[cont_columns])\n",
    "df_test[cont_columns] = scaler.transform(df_test[cont_columns])\n",
    "df_val[cont_columns] = scaler.transform(df_val[cont_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTaskDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cat_columns, num_columns,task1_column):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.task1_labels = df[task1_column].astype(np.float32).values\n",
    "\n",
    "        self.cate = df[cat_columns].astype(np.int64).values\n",
    "        self.num = df[num_columns].astype(np.float32).values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve features and labels from the dataframe using column names\n",
    "        cat_features = self.cate[idx]\n",
    "        num_features = self.num[idx]\n",
    "        labels_task1 = self.task1_labels[idx]\n",
    "\n",
    "        return cat_features, num_features, labels_task1\n",
    "\n",
    "#Wrapping in Dataset\n",
    "train_dataset = SingleTaskDataset(df_train, cat_columns, cont_columns, target[0])\n",
    "val_dataset = SingleTaskDataset(df_val, cat_columns, cont_columns, target[0])\n",
    "test_dataset = SingleTaskDataset(df_test, cat_columns, cont_columns, target[0])\n",
    "\n",
    "#This is a hyperparameter that is not tuned. Maybe mess with what makes sense here\n",
    "#Also try looking to see what other papers have done\n",
    "batch_size = 256\n",
    "\n",
    "# Wrapping with DataLoader for easy batch extraction\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL AND HELPERS\n",
    "\n",
    "1. All you should have to do is interact with Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each task loss is scaled by its own learnable parameter, then regularization is applied \n",
    "class UncertaintyLoss(nn.Module):\n",
    "    def __init__(self, num_tasks):\n",
    "        super(UncertaintyLoss, self).__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        self.loss_fns = [nn.CrossEntropyLoss() for x in range(num_tasks)] \n",
    "\n",
    "    def forward(self, predictions, labels_task1):\n",
    "\n",
    "        #task 1\n",
    "        target = labels_task1.long()\n",
    "        prediction = predictions[0]\n",
    "        loss_fn = self.loss_fns[0]\n",
    "\n",
    "        task_loss = loss_fn(prediction, target)\n",
    "        \n",
    "        return task_loss\n",
    "    \n",
    "#All layers of the model\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3) #(batch_size, head_dim, #query_embeddings, #key_embeddings)\n",
    "\n",
    "        # Calculate simplified attention scores\n",
    "        avg_attention = attention.mean(dim=0)  # Average across batches\n",
    "        # print(\"batch average\", avg_attention.shape)\n",
    "        avg_attention = avg_attention.mean(dim=0).squeeze(dim=0)\n",
    "        # print(\"head average\", avg_attention.shape)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim) #(batch_size, n_features, embed_size)\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out, avg_attention\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion, pre_norm_on):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.pre_norm_on = pre_norm_on\n",
    "        if self.pre_norm_on:\n",
    "            self.pre_norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        if self.pre_norm_on:\n",
    "            query = self.pre_norm(query)\n",
    "            key = self.pre_norm(key)\n",
    "            value = self.pre_norm(value)\n",
    "            \n",
    "        attention, avg_attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out, avg_attention\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, pre_norm_on):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout, forward_expansion, pre_norm_on)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key):\n",
    "        out, avg_attention = self.transformer_block(value, key, x)\n",
    "\n",
    "        return out, avg_attention\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_size,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 decoder_dropout,\n",
    "                 pre_norm_on\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "                [\n",
    "                    DecoderBlock(\n",
    "                        embed_size,\n",
    "                        heads,\n",
    "                        dropout=decoder_dropout,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        pre_norm_on=pre_norm_on\n",
    "                    )\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            )\n",
    "        self.avg_attention = None\n",
    "\n",
    "    def forward(self, class_embed, context):\n",
    "        for layer in self.layers:\n",
    "            # x is the classification embedding (CLS Token)\n",
    "            # context are the feature embeddings that will be used as key and value\n",
    "            x, self.avg_attention = layer(class_embed, context, context)\n",
    "  \n",
    "        return x \n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, sigma, embed_size, input_size, embedding_dropout, n_cont, cat_feat, num_target_labels, rff_on):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.rff_on = rff_on\n",
    "\n",
    "        if self.rff_on:\n",
    "            self.rffs = nn.ModuleList([GaussianEncoding(sigma=sigma, input_size=input_size, encoded_size=embed_size//2) for _ in range(n_cont)])\n",
    "            self.dropout = nn.Dropout(embedding_dropout)\n",
    "            self.mlp_in = embed_size\n",
    "        else:\n",
    "            self.mlp_in = input_size\n",
    "\n",
    "        self.cont_embeddings = nn.ModuleList([nn.Linear(in_features=self.mlp_in, out_features=embed_size) for _ in range(n_cont)])\n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([nn.Embedding(num_classes, embed_size) for num_classes in cat_feat])\n",
    "\n",
    "        # Classifcation Embeddings for each target label\n",
    "        self.target_label_embeddings = nn.ModuleList([nn.Embedding(1, embed_size) for _ in range(num_target_labels)])\n",
    "\n",
    "\n",
    "    def forward(self, cat_x, cont_x):\n",
    "        x = cont_x.unsqueeze(2) #(batch_size, n_features) -> (batch_size, n_features, 1)\n",
    "        rff_vectors = []\n",
    "        if self.rff_on:\n",
    "            for i, r in enumerate(self.rffs):\n",
    "                input = x[:,i,:]\n",
    "                out = r(input)\n",
    "                rff_vectors.append(out)\n",
    "        \n",
    "            x = torch.stack(rff_vectors, dim=1)\n",
    "        \n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.cont_embeddings):\n",
    "            goin_in = x[:,i,:]\n",
    "            goin_out = e(goin_in)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        #embedding cat features\n",
    "        cat_x = cat_x.unsqueeze(2)\n",
    "        for i, e in enumerate(self.cat_embeddings):\n",
    "\n",
    "            goin_in = cat_x[:,i,:]\n",
    "  \n",
    "            goin_out = e(goin_in)\n",
    "            goin_out=goin_out.squeeze(1)\n",
    "            embeddings.append(goin_out)\n",
    "\n",
    "        target_label_embeddings_ = []\n",
    "        for e in self.target_label_embeddings:\n",
    "            input = torch.tensor([0], device=x.device)\n",
    "            temp = e(input)\n",
    "            temp = temp.repeat(x.size(0), 1)\n",
    "            tmep = temp.unsqueeze(1)\n",
    "            target_label_embeddings_.append(temp)\n",
    "\n",
    "        class_embeddings = torch.stack(target_label_embeddings_, dim=1)\n",
    "\n",
    "        context = torch.stack(embeddings, dim=1)\n",
    "\n",
    "        return class_embeddings, context\n",
    "\n",
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, embed_size, dropout, mlp_scale_classification, num_target_classes):\n",
    "        super(classificationHead, self).__init__()\n",
    "        \n",
    "        #flattening the embeddings out so each sample in batch is represented with a 460 dimensional vector\n",
    "        self.input = embed_size\n",
    "        self.lin1 = nn.Linear(self.input, mlp_scale_classification*self.input)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(mlp_scale_classification*self.input, mlp_scale_classification*self.input)\n",
    "        self.lin3 = nn.Linear(mlp_scale_classification*self.input, self.input)\n",
    "        self.lin4 = nn.Linear(self.input, num_target_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self): #he_initialization.\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin3.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= torch.reshape(x, (-1, self.input))\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin4(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 rff_on = False,\n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 embedding_dropout = 0,\n",
    "                 n_cont = 0,\n",
    "                 cat_feat:list = [],\n",
    "                 num_layers=1,\n",
    "                 heads=1,\n",
    "                 forward_expansion=4, # Determines how wide the MLP is in the encoder. Its a scaling factor. \n",
    "                 decoder_dropout=0,\n",
    "                 classification_dropout = 0,\n",
    "                 pre_norm_on = False,\n",
    "                 mlp_scale_classification = 4,\n",
    "                 targets_classes : list=  [3,8]\n",
    "                 ):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.embeddings = Embeddings(rff_on=rff_on, sigma=sigma, embed_size=embed_size, input_size=input_size, \n",
    "                                     embedding_dropout=embedding_dropout,n_cont=n_cont, cat_feat=cat_feat, num_target_labels=len(targets_classes))\n",
    "        self.decoder = Decoder(embed_size=embed_size, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, \n",
    "                               decoder_dropout=decoder_dropout, pre_norm_on=pre_norm_on)\n",
    "        self.classifying_heads = nn.ModuleList([classificationHead(embed_size=embed_size, dropout=classification_dropout, \n",
    "                                                                   mlp_scale_classification=mlp_scale_classification, \n",
    "                                                                   num_target_classes=x) for x in targets_classes])\n",
    "        \n",
    "    def forward(self, cat_x, cont_x):\n",
    "        class_embed, context = self.embeddings(cat_x, cont_x)\n",
    "\n",
    "        x = self.decoder(class_embed, context)\n",
    "        \n",
    "        probability_dist_raw = []\n",
    "        for i, e in enumerate(self.classifying_heads):\n",
    "            input = x[:, i,:]\n",
    "            output = e(input)\n",
    "            probability_dist_raw.append(output)\n",
    "        \n",
    "        return probability_dist_raw\n",
    "\n",
    "# Training and Testing Loops\n",
    "def train(dataloader, model, loss_function, optimizer, device_in_use):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    total_correct_1 = 0\n",
    "    total_samples_1 = 0\n",
    "    all_targets_1 = []\n",
    "    all_predictions_1 = []\n",
    "\n",
    "    total_correct_2 = 0\n",
    "    total_samples_2 = 0\n",
    "    all_targets_2 = []\n",
    "    all_predictions_2 = []\n",
    "\n",
    "    for (cat_x, cont_x,labels_task1) in dataloader:\n",
    "        cat_x,cont_x,labels_task1 = cat_x.to(device_in_use),cont_x.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "\n",
    "        task_predictions = model(cat_x, cont_x) #contains a list of the tensor outputs for each task\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #computing accuracy for first target\n",
    "        y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "        _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "        total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "        total_samples_1 += labels_task1.size(0)\n",
    "        all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "        all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss/len(dataloader)\n",
    "    accuracy_1 = total_correct_1 / total_samples_1\n",
    "    # accuracy_2 = total_correct_2 / total_samples_2\n",
    "\n",
    "    # # precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    # f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "    return avg_loss, accuracy_1\n",
    "\n",
    "def test(dataloader, model, loss_function, device_in_use):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_correct_1 = 0\n",
    "  total_samples_1 = 0\n",
    "  all_targets_1 = []\n",
    "  all_predictions_1 = []\n",
    "\n",
    "  total_correct_2 = 0\n",
    "  total_samples_2 = 0\n",
    "  all_targets_2 = []\n",
    "  all_predictions_2 = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for (cat_x, cont_x,labels_task1) in dataloader:\n",
    "        cat_x,cont_x,labels_task1 = cat_x.to(device_in_use),cont_x.to(device_in_use),labels_task1.to(device_in_use)\n",
    "\n",
    "\n",
    "        task_predictions = model(cat_x, cont_x) #contains a list of the tensor outputs for each task\n",
    "\n",
    "        loss = loss_function(task_predictions, labels_task1)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #computing accuracy for first target\n",
    "        y_pred_softmax_1 = torch.softmax(task_predictions[0], dim=1)\n",
    "        _, y_pred_labels_1 = torch.max(y_pred_softmax_1, dim=1)\n",
    "        total_correct_1 += (y_pred_labels_1 == labels_task1).sum().item()\n",
    "        total_samples_1 += labels_task1.size(0)\n",
    "        all_targets_1.extend(labels_task1.cpu().numpy())\n",
    "        all_predictions_1.extend(y_pred_labels_1.cpu().numpy())\n",
    "\n",
    "\n",
    "  avg = total_loss/len(dataloader)\n",
    "  accuracy_1 = total_correct_1 / total_samples_1\n",
    "  # accuracy_2 = total_correct_2 / total_samples_2\n",
    "  # recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "  f1_1 = f1_score(all_targets_1, all_predictions_1, average='weighted')\n",
    "  # f1_2 = f1_score(all_targets_2, all_predictions_2, average=\"weighted\")\n",
    "\n",
    "  return avg, accuracy_1, all_predictions_1, all_targets_1, f1_1\n",
    "\n",
    "def format_metric(value): # Used to format the metrics output\n",
    "    return f\"{value:.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN EXPERIMENTS\n",
    "\n",
    "1. Using Optuna to optimize CAT-Transformers hyperparameters for your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_metric = float('-inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if metric > self.best_metric:\n",
    "            self.best_metric = metric\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Function to log results to a text file\n",
    "def log_to_file(filename, text):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(text + '\\n')\n",
    "\n",
    "def objective(trial):\n",
    "    trial_number = trial.number\n",
    "\n",
    "    # Define hyperparameters to search over\n",
    "    sigma = trial.suggest_categorical('sigma', [.001, 0.1, 1, 2, 3, 5, 10])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
    "    # Ensure that embed_size is divisible by num_layers\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [50, 60, 70, 80, 90, 100, 120, 140, 160])\n",
    "    heads = trial.suggest_categorical(\"heads\", [1, 5, 10])\n",
    "    forward_expansion = trial.suggest_int('forward_expansion', 1, 8)\n",
    "    prenorm_on = trial.suggest_categorical('prenorm_on', [True, False])\n",
    "    mlp_scale_classification = trial.suggest_int('mlp_scale_classification', 1, 8)\n",
    "    embedding_dropout = trial.suggest_categorical('embedding_dropout', [0, .1, .2, .5])\n",
    "    decoder_dropout = trial.suggest_categorical('decoder_dropout', [0,.1,.2,.5])\n",
    "    classification_dropout = trial.suggest_categorical('class_drop', [0,.1,.2,.5])\n",
    "\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [0.0001, 0.001, 0.01])\n",
    "\n",
    "    num_epochs = 75\n",
    "\n",
    "    # Create your model with the sampled hyperparameters\n",
    "    model = Classifier(\n",
    "        targets_classes=target_classes,\n",
    "        rff_on=True, #LEAVING ON\n",
    "        n_cont=len(cont_columns),\n",
    "        cat_feat=cat_feat,\n",
    "        sigma=sigma,\n",
    "        embed_size=embed_size,\n",
    "        num_layers=num_layers,\n",
    "        heads=heads,\n",
    "        forward_expansion=forward_expansion,\n",
    "        pre_norm_on=prenorm_on,\n",
    "        mlp_scale_classification=mlp_scale_classification,\n",
    "        embedding_dropout=embedding_dropout,\n",
    "        decoder_dropout=decoder_dropout,\n",
    "        classification_dropout=classification_dropout\n",
    "    ).to(device_in_use)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_function = UncertaintyLoss(1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=3)  # Adjust patience as needed\n",
    "\n",
    "    # Training loop with a large number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(train_dataloader, model, loss_function, optimizer, device_in_use)\n",
    "        \n",
    "        # Validation loop\n",
    "        val_loss, val_accuracy, _, _, _ = test(val_dataloader, model, loss_function, device_in_use)\n",
    "        \n",
    "        # Check if we should early stop based on validation accuracy\n",
    "        if early_stopping(val_accuracy):\n",
    "            break\n",
    "\n",
    "    \n",
    "    # Log the final test accuracy for this trial to a shared log file\n",
    "    final_log = f\"Trial {trial_number} completed. Validation Accuracy = {val_accuracy:.4f}\"\n",
    "    log_to_file('all_trials_log.txt', final_log)\n",
    "\n",
    "    # Return the test accuracy as the objective to optimize\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of optimization trials\n",
    "num_trials = 50\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')  # Maximize validation accuracy\n",
    "\n",
    "# Start the optimization process\n",
    "study.optimize(objective, n_trials=num_trials, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and the validation accuracy at the point of early stopping\n",
    "best_params = study.best_params\n",
    "best_val_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Validation Accuracy (at Early Stopping):\", best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing against the test dataset\n",
    "model = Classifier(targets_classes=target_classes,\n",
    "                    rff_on=True,\n",
    "                    n_cont=len(cont_columns),\n",
    "                    cat_feat=cat_feat, \n",
    "                   sigma=best_params['sigma'],\n",
    "                   embed_size=best_params['embed_size'],\n",
    "                   num_layers=best_params['num_layers'],\n",
    "                   heads=best_params['heads'],\n",
    "                   forward_expansion=best_params['forward_expansion'],\n",
    "                   pre_norm_on=best_params['prenorm_on'],\n",
    "                   mlp_scale_classification=best_params['mlp_scale_classification'],\n",
    "                   embedding_dropout=best_params['embedding_dropout'],\n",
    "                   decoder_dropout=best_params['decoder_dropout'],\n",
    "                   classification_dropout=best_params['class_drop']\n",
    "                   ).to(device_in_use) # Instantiate the model\n",
    "loss_functions = UncertaintyLoss(1)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = best_params['learning_rate']) # Maybe try messing around with optimizers. try other torch optimizers with different configurations.\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "epochs = 75 #Set the number of epochs\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies_1 = [] \n",
    "train_accuracies_2 = []\n",
    "train_recalls = [] \n",
    "train_f1_scores = [] \n",
    "test_losses = []\n",
    "test_accuracies_1 = []\n",
    "test_accuracies_2 = []\n",
    "test_recalls = []  \n",
    "test_f1_scores = [] \n",
    "all_attention_scores = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  train_loss, train_accuracy_1 = train(train_dataloader, model, loss_functions, optimizer, device_in_use=device_in_use)\n",
    "  test_loss, test_accuracy_1, all_predictions_1, all_targets_1, f1_1 = test(test_dataloader, model, loss_functions, device_in_use=device_in_use)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accuracies_1.append(train_accuracy_1)\n",
    "  # train_accuracies_2.append(train_accuracy_2)\n",
    "  # train_recalls.append(train_recall) \n",
    "  # train_f1_scores.append(train_f1)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies_1.append(test_accuracy_1)\n",
    "  # test_accuracies_2.append(test_accuracy_2)\n",
    "  # test_recalls.append(test_recall)\n",
    "  # test_f1_scores.append(test_f1)\n",
    "  # Formatting for easier reading\n",
    "  epoch_str = f\"Epoch [{t+1:2}/{epochs}]\"\n",
    "  train_metrics = f\"Train: Loss {format_metric(train_loss)}, Accuracy {format_metric(train_accuracy_1)}\"\n",
    "  test_metrics = f\"Test: Loss {format_metric(test_loss)}, Accuracy {format_metric(test_accuracy_1)}, F1 {format_metric(f1_1)}\"\n",
    "  print(f\"{epoch_str:20} | {train_metrics:65} | {test_metrics}\")\n",
    "\n",
    "  if early_stopping(test_accuracy_1):\n",
    "    break\n",
    "\n",
    "# Save the model after pre-training\n",
    "torch.save(model.state_dict(), 'final_model_trained.pth')\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), [l for l in test_losses], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accuracies_1, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accuracies_1, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Display confusion matrix for the first task (Traffic Type) on test data\n",
    "conf_matrix_1 = confusion_matrix(all_targets_1, all_predictions_1)\n",
    "print(\"Confusion Matrix for income\")\n",
    "print(conf_matrix_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAT-Former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
